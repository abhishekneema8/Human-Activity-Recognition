{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 564) (2947, 564)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_train and y_train from csv files\n",
    "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_train = train.ActivityName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_test and y_test from test csv file\n",
    "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_test = test.ActivityName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and y_train : ((7352, 561),(7352,))\n",
      "X_test  and y_test  : ((2947, 561),(2947,))\n"
     ]
    }
   ],
   "source": [
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic function to run any model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n",
    "                 print_cm=True, cm_cmap=plt.cm.Greens):\n",
    "    \n",
    "    \n",
    "    # to store results at various phases\n",
    "    results = dict()\n",
    "    \n",
    "    # time at which model starts training \n",
    "    train_start_time = datetime.now()\n",
    "    print('training the model..')\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Done \\n \\n')\n",
    "    train_end_time = datetime.now()\n",
    "    results['training_time'] =  train_end_time - train_start_time\n",
    "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
    "    \n",
    "    \n",
    "    # predict test data\n",
    "    print('Predicting test data')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_end_time = datetime.now()\n",
    "    print('Done \\n \\n')\n",
    "    results['testing_time'] = test_end_time - test_start_time\n",
    "    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n",
    "    results['predicted'] = y_pred\n",
    "   \n",
    "\n",
    "    # calculate overall accuracty of the model\n",
    "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    # store accuracy in results\n",
    "    results['accuracy'] = accuracy\n",
    "    print('---------------------')\n",
    "    print('|      Accuracy      |')\n",
    "    print('---------------------')\n",
    "    print('\\n    {}\\n\\n'.format(accuracy))\n",
    "    \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    results['confusion_matrix'] = cm\n",
    "    if print_cm: \n",
    "        print('--------------------')\n",
    "        print('| Confusion Matrix |')\n",
    "        print('--------------------')\n",
    "        print('\\n {}'.format(cm))\n",
    "        \n",
    "    # plot confusin matrix\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(b=False)\n",
    "    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "    plt.show()\n",
    "    \n",
    "    # get classification report\n",
    "    print('-------------------------')\n",
    "    print('| Classifiction Report |')\n",
    "    print('-------------------------')\n",
    "    classification_report = metrics.classification_report(y_test, y_pred)\n",
    "    # store report in results\n",
    "    results['classification_report'] = classification_report\n",
    "    print(classification_report)\n",
    "    \n",
    "    # add the trained  model to the results\n",
    "    results['model'] = model\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to print the grid search attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_attributes(model):\n",
    "    # Estimator that gave highest score among all the estimators formed in GridSearch\n",
    "    print('--------------------------')\n",
    "    print('|      Best Estimator     |')\n",
    "    print('--------------------------')\n",
    "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
    "\n",
    "\n",
    "    # parameters that gave best results while performing grid search\n",
    "    print('--------------------------')\n",
    "    print('|     Best parameters     |')\n",
    "    print('--------------------------')\n",
    "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
    "\n",
    "\n",
    "    #  number of cross validation splits\n",
    "    print('---------------------------------')\n",
    "    print('|   No of CrossValidation sets   |')\n",
    "    print('--------------------------------')\n",
    "    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n",
    "\n",
    "\n",
    "    # Average cross validated score of the best estimator, from the Grid Search \n",
    "    print('--------------------------')\n",
    "    print('|        Best Score       |')\n",
    "    print('--------------------------')\n",
    "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  1.7min finished\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:01:58.943516\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.007999\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.9626739056667798\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[537   0   0   0   0   0]\n",
      " [  1 428  58   0   0   4]\n",
      " [  0  12 519   1   0   0]\n",
      " [  0   0   0 495   1   0]\n",
      " [  0   0   0   3 409   8]\n",
      " [  0   0   0  22   0 449]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.97      0.87      0.92       491\n",
      "          STANDING       0.90      0.98      0.94       532\n",
      "           WALKING       0.95      1.00      0.97       496\n",
      "WALKING_DOWNSTAIRS       1.00      0.97      0.99       420\n",
      "  WALKING_UPSTAIRS       0.97      0.95      0.96       471\n",
      "\n",
      "          accuracy                           0.96      2947\n",
      "         macro avg       0.97      0.96      0.96      2947\n",
      "      weighted avg       0.96      0.96      0.96      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# start Grid search\n",
    "parameters = {'C':[0.01, 0.1, 1, 10, 20, 30], 'penalty':['l2','l1']}\n",
    "log_reg = linear_model.LogisticRegression()\n",
    "log_reg_grid = GridSearchCV(log_reg, param_grid=parameters, cv=3, verbose=1, n_jobs=-1)\n",
    "log_reg_grid_results =  perform_model(log_reg_grid, X_train, y_train, X_test, y_test, class_labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAYING',\n",
       " 'SITTING',\n",
       " 'STANDING',\n",
       " 'WALKING',\n",
       " 'WALKING_DOWNSTAIRS',\n",
       " 'WALKING_UPSTAIRS']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 20, 30],\n",
       "                         'penalty': ['l2', 'l1']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_time': datetime.timedelta(seconds=118, microseconds=943516), 'testing_time': datetime.timedelta(microseconds=7999), 'predicted': array(['STANDING', 'STANDING', 'STANDING', ..., 'WALKING_UPSTAIRS',\n",
      "       'WALKING_UPSTAIRS', 'WALKING_UPSTAIRS'], dtype=object), 'accuracy': 0.9626739056667798, 'confusion_matrix': array([[537,   0,   0,   0,   0,   0],\n",
      "       [  1, 428,  58,   0,   0,   4],\n",
      "       [  0,  12, 519,   1,   0,   0],\n",
      "       [  0,   0,   0, 495,   1,   0],\n",
      "       [  0,   0,   0,   3, 409,   8],\n",
      "       [  0,   0,   0,  22,   0, 449]], dtype=int64), 'classification_report': '                    precision    recall  f1-score   support\\n\\n            LAYING       1.00      1.00      1.00       537\\n           SITTING       0.97      0.87      0.92       491\\n          STANDING       0.90      0.98      0.94       532\\n           WALKING       0.95      1.00      0.97       496\\nWALKING_DOWNSTAIRS       1.00      0.97      0.99       420\\n  WALKING_UPSTAIRS       0.97      0.95      0.96       471\\n\\n          accuracy                           0.96      2947\\n         macro avg       0.97      0.96      0.96      2947\\n      weighted avg       0.96      0.96      0.96      2947\\n', 'model': GridSearchCV(cv=3, error_score='raise-deprecating',\n",
      "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                          fit_intercept=True,\n",
      "                                          intercept_scaling=1, l1_ratio=None,\n",
      "                                          max_iter=100, multi_class='warn',\n",
      "                                          n_jobs=None, penalty='l2',\n",
      "                                          random_state=None, solver='warn',\n",
      "                                          tol=0.0001, verbose=0,\n",
      "                                          warm_start=False),\n",
      "             iid='warn', n_jobs=-1,\n",
      "             param_grid={'C': [0.01, 0.1, 1, 10, 20, 30],\n",
      "                         'penalty': ['l2', 'l1']},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=1)}\n"
     ]
    }
   ],
   "source": [
    "print(log_reg_grid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAIvCAYAAACIrfpYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdedxWc/7H8dfnLiUqUaHuSotEpT2lkjBCKVvZGir7MGMfxjIY2/wMJsaWZow1W0gpUpZQpJ2oKCPaLEWmFNXd5/fHOfc9V7d7U9d1n/s65/3scR5d55zvdc7ne9333f3p8/2ec8zdEREREYmLnKgDEBEREUknJTciIiISK0puREREJFaU3IiIiEisKLkRERGRWFFyIyIiIrFSOeoAREREpHxZnR2djVsyd4K1m1519yMzd4KSKbkRERFJmo1boMvumTv+a8vrZO7gpVNyIyIikkRmUUeQMZpzIyIiIrGiyo2IiEjSGLEub8S4ayIiIpJEqtyIiIgkkebciIiIiGQHVW5ERESSKL6FGyU3IiIiyWMalhIRERHJFqrciIiIJI0uBRcRERHJHqrciIiIJJHm3IiIiIhkB1VuREREkii+hRtVbkRERCReVLkRERFJGgNy4lu6UeVGREREYkWVGxERkSSKb+FGyY2IiEgi6VJwERERkeygyo2IiEgSxbdwo8qNiIiIxIsqNyIiIkmjS8FFREREsocqNyIiIkkU38KNKjciIiISL0puREREEseC+9xkaint7GZLzGyemc01s5nhtt3MbJKZLQr/3jXcbmb2DzNbbGYfmlmH0o6v5EZERESicIi7t3P3TuH6n4DX3b058Hq4DnAU0DxczgEeKO3ASm5ERESSJv9qqUwt2+YY4NHw9aPAsSnbH/PANKCWmdUr6UBKbkRERJLIMriUzoGJZjbLzM4Jt+3h7isBwr93D7fnAktT3rss3FYsXS0lIiIi6VYnfy5NaIS7j0hZ7+7uK8xsd2CSmS0s4VhFpUte0smV3IiIiCRRZh+cuSplLs0vuPuK8O9vzGw0cADwtZnVc/eV4bDTN2HzZUDDlLc3AFaUdHINS4mIiEi5MbOdzaxG/mugN/ARMBYYHDYbDIwJX48FTg+vmuoK/JA/fFUcVW5ERESSKLqb+O0BjLagclQZeNLdJ5jZDOBZMzsT+BIYGLZ/GegDLAbWA0NLO4GSGxERESk37v4foG0R21cDhxWx3YELfs05lNyIiIgkjR6cKSIiIpI9VLkRERFJovgWblS5ERERkXhR5UZERCSJMnufm0gpuREREUmiGI/dxLhrIiIikkSq3IiIiCSNWayHpVS5ERERkVhR5UZERCSJ4lu4UeVGRCoGM6tmZi+Z2Q9mNmo7jjPIzCamM7aomNlBZvZJ1HGIZBslNyLyq5jZqWY208zWmdlKM3vFzHqk4dADCB6oV9vdB5bWuDjuPtLde6chnowyMzezvUtq4+7vuHuL8opJEiZ/3k0mlogpuRGRMjOzS4G7gFsJEpFGwP3AMWk4/F7Ap+6+OQ3HynpmpmkDIttIyY2IlImZ7QLcCFzg7i+4+4/uvsndX3L3P4ZtqprZXWa2IlzuMrOq4b5eZrbMzC4zs2/Cqs/QcN9fgOuAk8KK0JlmdoOZPZFy/sZhtaNyuD7EzP5jZmvN7HMzG5SyfUrK+7qZ2YxwuGuGmXVL2TfZzG4ys6nhcSaaWZ1i+p8f/xUp8R9rZn3M7FMz+87Mrk5pf4CZvWdma8K295pZlXDf22GzD8L+npRy/CvN7Cvg4fxt4XuahefoEK7XN7NVZtZru76wklw5GVwiVgFCEJEscSCwIzC6hDbXAF2BdkBb4ADg2pT9ewK7ALnAmcB9Zraru19PUA16xt2ru/tDJQViZjsD/wCOcvcaQDdgbhHtdgPGh21rA38HxptZ7ZRmpwJDgd2BKsDlJZx6T4LPIJcgGfsn8FugI3AQcJ2ZNQ3b5gGXAHUIPrvDgPMB3L1n2KZt2N9nUo6/G0EV65zUE7v7Z8CVwEgz2wl4GHjE3SeXEK9I0QwNS4mIECQHq0oZNhoE3Oju37j7t8BfgNNS9m8K929y95eBdcC2zinZArQ2s2ruvtLdPy6iTV9gkbs/7u6b3f0pYCHQL6XNw+7+qbtvAJ4lSMyKswm4xd03AU8TJC53u/va8PwfA20A3H2Wu08Lz7sEeBA4uAx9ut7dfw7j2Yq7/xNYBLwP1CNIJkWkECU3IlJWq4E6pcwFqQ98kbL+Rbit4BiFkqP1QPVfG4i7/wicBJwHrDSz8Wa2bxniyY8pN2X9q18Rz2p3zwtf5ycfX6fs35D/fjPbx8zGmdlXZvZfgspUkUNeKb51959KafNPoDVwj7v/XEpbkeJZBpeIKbkRkbJ6D/gJOLaENisIhlTyNQq3bYsfgZ1S1vdM3enur7r74QQVjIUEv/RLiyc/puXbGNOv8QBBXM3dvSZwNaX/s+8l7TSz6gQTuh8CbgiH3USkECU3IlIm7v4DwTyT+8KJtDuZ2Q5mdpSZ/S1s9hRwrZnVDSfmXgc8UdwxSzEX6GlmjcLJzFfl7zCzPcysfzj35meC4a28Io7xMrBPePl6ZTM7CWgJjNvGmH6NGsB/gXVhVel3hfZ/DTT9xbtKdjcwy93PIphLNHy7o5TkyrHMLVF3LeoARCR7uPvfgUsJJgl/CywFfg+8GDa5GZgJfAjMA2aH27blXJOAZ8JjzWLrhCQHuIygMvMdwVyW84s4xmrg6LDtauAK4Gh3X7UtMf1KlxNMVl5LUFV6ptD+G4BHw6upTiztYGZ2DHAkwVAcBF+HDvlXiYnI/5h7iVVQERERiRnbvZpzUon3kNw+9340y907Ze4EJVPlRkRERGJFd8AUERFJmgpyVVOmqHIjIiIisaLKjYiISOIYlsE7CUc9m1fJjaSNVclxdoz3t1SHfVpHHYKIJMwXS75k1apVac9ElNyIlMWOlaHL7lFHkVFTJ0wpvZGISBp179Ij6hCyjpIbERGRBKoAz7fMGE0oFhERkVhR5UZERCRhDMjJYOmmqGehlCdVbkRERCRWVLkRERFJGsvs1VJRU+VGREREYkWVGxERkQRS5UZEREQkS6hyIyIikjiZffxC1JTciIiIJFCMcxsNS4mIiEi8qHIjIiKSMIYmFIuIiIhkDVVuREREkkY38RMRERHJHqrciIiIJJChyo2IiIhIVlDlRkREJIE050ZEREQkSyi5kQrt88ff48MRrzFn+KvMuG88ADcOvpwPHpzEnOGv8ur/jaRe7T0AuHzgecwZ/ipzhr/KvBGvsXnCF+xao1aU4W+XiRMm0qZlO1q12J/bb7sj6nAyQn2MjyT0M259NMvcEjVz96hjkJiwmlWcLrun9ZifP/4enS7ow+r/fl+wrcZO1Vm7fh0Afzj2DFru1Zzf3X3VVu87uutvuOT4sznsipPSGs+GCZ+m9XjFycvLY//92jJ+wkvkNsilR9eDePSJR9iv5X7lcv7yoD7GRxL6GWUfu3fpwayZs9OaMlSuV91rnNE6nYfcyppb35/l7p0ydoJSqHIjWSc/sQHYecdqFJWgn3LIsTz15pjyDCutZkyfSbNmTWnStAlVqlRh4IkDGDd2XNRhpZX6GB9J6GcS+hgnSm6kQnN3Jv7fk8y872XO7jOoYPvNQ6/gy5HTGXTocVz36Nbl4WpVd+TITr14fsrL5R1u2qxYsYIGDRsUrOc2yGX5ipURRpR+6mN8JKGfceyjmWVsiZqSmyxgZutK2He3mS03sxwz29HMFprZ/in7rzCz4WbW2Mw+Crf1MjM3s34p7caZWa/wdWUzu9XMFpnZ3HC5JoNdLFb3S46j4/lHcdQ1p3FB/8EctH8XAK59+G80GnQAI98Yze+PGbrVe/p1PZypH8/g+7Vrogg5LYqqRlWEfzDSSX2MjyT0Mwl9jBMlN1nMzHKA44ClQE93/wm4GLjfArnAucBVRbx9GVBcwnIzUB/Y393bAQcBO6Q7/rJYufprAL5ds5rRUydwQIt2W+1/8o0XOaHHUVttO7nXMVk9JAWQm5vLsqXLCtaXL1tO/Xp7RhhR+qmP8ZGEfsauj6bKjVRchwAfAQ8ApwC4+wRgJXA6MAy4wd2/L+K9HwA/mNnhqRvNbCfgbOAPYbKEu6919xsy1Yni7LRjNapX27ngde+OPfloySfsndukoE3/A3uzcOlnBes1d6rBwW26Mua9V8s73LTq1Lkjixd/xpLPl7Bx40ZGPfscffv1jTqstFIf4yMJ/UxCH+NEN/HLbqcATwFjgFvNbAd330RQvZkOLHL3x0t4/83hMill297Al+6+NkMxl9keteoy+oZ/AVC5UiWefPNFXp05meeuG0GLBk3Z4s4XXy/jvJQrpY7rcSQTZ73F+p82RBV2WlSuXJlhd99Jvz7HkJeXx+Ahp9OyVcuow0or9TE+ktDPOPaxAhRYMkaXgmcBM1vn7tULbasCLAFauPtaM3sBeMjdx4f7HwPGufuz4XrjcL11OLfmcnc/2szeAq4FrgTuAL4DHnX39uH7hgIXAbWBbu6+tFAc5wDnALBjpY70yOIybRmU16XgIiL5MnIpeP3qXuusNuk85FZW3/RepJeCq3KTvY4EdgHmheObOwHrgfHh/i3hUppbCObebA7XFwONzKxGOBz1MPBwOBm5UuE3u/sIYASE97kREZEKz4j3hGjNuclepwBnuXtjd28MNAF6h3NmyszdJwK7Am3D9fXAQ8C9ZrYjgJlVAqqkMXYREZGMUXKTHXYys2Upy9XAEfyvSoO7/whMAfoVd5AS3AI0SFm/hmBS8kdmNgd4B3gUWLGtHRARkYolzldLaVgqC7h7UUnorUW0Oz7l9ZBC+5YArcPXk4HJKfvGElQp89c3AX8KFxERiZ2KkYRkiio3IiIiEiuq3IiIiCSNaUKxiIiISNZQ5UZERCSBYly4UeVGRERE4kWVGxERkYTRTfxEREREsogqNyIiIgkU58qNkhsREZEEyolxcqNhKREREYkVVW5ERESSxnQpuIiIiEjWUOVGREQkYUwPzhQRERHJHqrciIiIJJChyo2IiIhIVlDlRkREJIE050ZEREQkS6hyIyIikkBxrtwouREREUmgGOc2GpYSERGR8mdmlcxsjpmNC9ebmNn7ZrbIzJ4xsyrh9qrh+uJwf+PSjq3kRkREJGHMgmGpTC1ldBGwIGX9NmCYuzcHvgfODLefCXzv7nsDw8J2JdKwlKRNh31aM3XClKjDyKi9buoddQjl4oMrnoo6hIyrVbV21CFImrh71CFkVBy7Z2YNgL7ALcClFmREhwKnhk0eBW4AHgCOCV8DPAfca2bmJXzhldyIiIgkTsYfv1DHzGamrI9w9xEp63cBVwA1wvXawBp33xyuLwNyw9e5wFIAd99sZj+E7VcVd3IlNyIiIpJuq9y9U1E7zOxo4Bt3n2VmvfI3F9HUy7CvSEpuREREEijCS8G7A/3NrA+wI1CToJJTy8wqh9WbBsCKsP0yoCGwzMwqA7sA35V0Ak0oFhERkXLj7le5ewN3bwycDLzh7oOAN4EBYbPBwJjw9dhwnXD/GyXNtwFVbkRERBKpAt7n5krgaTO7GZgDPBRufwh43MwWE1RsTi7tQEpuREREJBLuPhmYHL7+D3BAEW1+Agb+muMquREREUkgPX5BREREYiP/Jn5xpQnFIiIiEiuq3IiIiCSQKjciIiIiWUKVGxERkQSKceFGlRsRERGJF1VuREREEifjD86MlCo3IiIiEiuq3IiIiCSQKjciIiIiWUKVGxERkYSJ+x2KldyIiIgkUIxzGw1LiYiISLyociMiIpJAcR6WUuVGss65Z51Ho3p70bFtp6hDSZscy+G1c//NE6feBsD9x1/H1N8/yVvnP8Zdx1xF5ZxKAJzf7RReP+9hXj/vYd46/zFWXPcWtarViDL0X+2HNT9w1qBz6dH+EA7qcCgz35/F99+t4aSjT6Vbm56cdPSprPl+TdRhps3ECRNp07IdrVrsz+233RF1OBkT937+9NNPHHTgwXTp0JWObTtx019ujjokKYGSG8k6p53+W8aMfzHqMNLq7K4DWbTqi4L15+dNpPu9p3Lw/aezY+WqDOrQD4D7332Kw4YP5bDhQ7nltQd574u5rNmwNqqwt8mf/3gDhxzeiylz3uT1aRNo3mJv7r3zPnr06s67H75Nj17duffO+6MOMy3y8vK4+MJLGTNuNHPmzWLUM6NYMH9B1GGlXRL6WbVqVV6ZNJ73Z09j2sz3mPTqa0yfNj3qsLZPMKs4M0vElNxI1unRswe77bZb1GGkTb2adTm8+YGMnP1SwbbXF00reD1n+Xzq19z9F+87bv/fMHrea+USY7qs/e9apk2dzqmDTwagSpUq7FJrF14dP4kTBw0A4MRBA5gwbmKUYabNjOkzadasKU2aNqFKlSoMPHEA48aOizqstEtCP82M6tWrA7Bp0yY2bdpUIX6JS9GU3IhE7KYjL+TGSQ+wxf0X+yrnVGJA2yN4Y/G0rbZX26Eqh+zdhXELJpdTlOnxxedfUrvOblx87mUcfuBRXHb+Faz/cT3ffrOKPertAcAe9fZg1berIo40PVasWEGDhg0K1nMb5LJ8xcoII8qMpPQzLy+PLh0PZK/6TTjsN4dyQJfOUYe0HYLHL2RqiZqSmwrKzK4xs4/N7EMzm2tmXcxsspl1MrP3w21fmtm34et5ZrYmfP2VmS0PX881sypmti48bmMzczP7Q8q57jWzISnrl5rZwvCYH5jZ381shwg+htg7fJ9urPpxDR+u/KTI/bf1vYxpX3zA+19+uNX23vt0Z8aX87JuSGpz3mbmzf2IwWefxqT3XqHaTtW4JyZDUEXxIhLWivAPf7olpZ+VKlXi/VnvsWjJJ8ycMZOPP/o46pCkGLpaqgIyswOBo4EO7v6zmdUBquTvd/cuYbshQCd3/32h998ArHP3O1K2pTb5BrjIzB50942F3nse0Bvo6u5rzKwKcClQDdiUtk4KAAc03J8jWnTnsOZd2bFyFapX3Zn7jv8zF7xwE5cdPJTaO9fi8meu+cX7jm39G0Z/lF1DUgD169ejXm49OnRuD8DRx/Xh3jsfoO7udfh65dfsUW8Pvl75NXXq1ok40vTIzc1l2dJlBevLly2nfr09I4woM5LSz3y1atXioIMPYtLE12jVulXU4WybijE1JmNUuamY6gGr3P1nAHdf5e4r0nj8b4HXgcFF7LsG+J27rwnPvdHd/8/d/5vG80voltcfpP3fj6fzXQM597kbmPr5LC544SYGdTiaQ/Y+gPOeu+EX/yuuUXVnDmzcjgkL34ko6m23+567U79BPRZ/+hkAUyZPZZ99m9O7z+E8O/I5AJ4d+RxH9D08yjDTplPnjixe/BlLPl/Cxo0bGfXsc/Tt1zfqsNIuCf389ttvWbMmuIpvw4YNvPn6m+zTYp+Io9p2BrEellLlpmKaCFxnZp8CrwHPuPtbaT7H/wGvmNm/8zeYWQ2gurt/nuZzpdXpgwbzzlvvsGrVaprt1Zw/X38tQ84oKk/LXn87+nKWrfma8Wc9CMD4BW/x97ceAaDPfj1567PprN/0U4QRbrtb7riRC864kE0bN9GoSSPuGn4HW7Y45572O5567BlyG9RnxBPDow4zLSpXrsywu++kX59jyMvLY/CQ02nZqmXUYaVdEvr51cqvOfuMc9iSl8cW38LxA46nT9+jog5LimFFjZVK9MysEnAQcAhwLvAnYAhwubvPDNsMoezDUuvcvbqZNQbGuXtrM3sMmAR0AWYCLwBL3H238D1HALcBtYBT3f3dIuI8BzgHoGGjhh0//c/CNH0CFdNeN/WOOoRy8cEVT0UdQsbVqlo76hAkTeL+e6x7l4OYPWt2WsshOzfe1ff786HpPORWZp31wix3j+xmZBqWqqDcPc/dJ7v79cDvgRMycJpbgSsJvw/CoacfzaxJuP6qu7cDPiJlzk+hOEe4eyd371Q3JvMkREQkuym5qYDMrIWZNU/Z1A74orj228rdFwLzCSYv5/sr8ICZ1QpjMWDHdJ9bRESipTk3Ut6qA/eECcZmYDHB0M9zGTjXLcCclPUHgJ2A983sZ2AdMLVQGxERkQpLyU0F5O6zgG5F7OpVqN0jwCNFvP+GIrZVD/9eArRO2f4BKRU8Dwav7wgXERGJqQpQYMkYDUuJiIhIrKhyIyIikjQVZG5MpqhyIyIiIrGiyo2IiEjC5N+hOK6U3IiIiCRQnJMbDUuJiIhIrKhyIyIikkCq3IiIiIhkCVVuREREksZ0Ez8RERGRrKHKjYiISAJpzo2IiIhIllDlRkREJGEMPX5BREREJGuociMiIpJAca7cKLkRERFJoBjnNhqWEhERkXhR5UZERCRpLN7DUqrciIiISKyociMiIpJEqtyIiIiIZAdVbkRERBJIc25EREREsoQqNyK/wn+ueTnqEMpF9QFtog4h4za8MD/qECRN4lyBgMxMjTEgJ8Yfmyo3IiIiEiuq3IiIiCROvB+cqeRGREQkaQxyYpzcaFhKREREYkWVGxERkYQx4j0RW5UbERERiRVVbkRERBIoztWNOPdNREREEkiVGxERkQTS1VIiIiIiWUKVGxERkYSJ+9VSSm5EREQSxzQsJSIiIpItVLkRERFJGov3sJQqNyIiIhIrqtyIiIgkjBHv6kac+yYiIiIJpMqNiIhIAulqKREREZEsocqNiIhIAulqKZEKZuKEibRp2Y5WLfbn9tvuiDqctPjd2RfQOLcZndt1Ldj2wnOj6dS2CzWq1mL2rNkRRrd9Ph8xhQ/vnsCcYS8z486xAPxtyFUsuO91Prj7FV646kF22blmQfs/nXA+i4ZPZuH9r9O7fc+owk6Lc886j0b19qJj205Rh5JRcfyZLCwJfYwLJTeSdfLy8rj4wksZM240c+bNYtQzo1gwf0HUYW23Qaefyovjnt9qW8tWLXny2SfoflD3iKJKn0OuPYX2l/Sh82X9AZg0dwqt/9CbthcdxafLP+eqE84HYL+Ge3PyQf1o9fveHHnDYO4/9yZycrL3n6rTTv8tY8a/GHUYGRXXn8lUceujEcy5ydQStez9F0MSa8b0mTRr1pQmTZtQpUoVBp44gHFjx0Ud1nbrcVB3dt1116227btfC/Zp0TyiiDJr0tx3yNuSB8C0T+fQoM6eABxzQG+efuclNm7eyJJvlrH4qy84oHm7KEPdLj169mC33XaLOoyMiuvPZKo49tEyuERNyY1knRUrVtCgYYOC9dwGuSxfsTLCiKQ0jjPxL48z886XOLv3Kb/Yf8ZhA3ll1mQAcmvvwdJVKwr2LVu1ktzae5RXqLINkvAzmYQ+xokmFJcTM7sGOBXIA7YA3wO7AtWBusDnYdPz3f1dM/sAmO/up6Qc4xHgcKCpu/9sZnWAme7e2MwaAwuAhcCOwFrgPnd/NHzvEKCTu//ezG4ArgAau/s34f517l49fL0HMAzoGsa5Efibu4/OwEfzq7n7L7bFeWJcHHT/0wms/O4b6u5Sm0l/eYKFyz7jnfnTAbh64AVs3pLHyLeCoZuivpZFfc2l4kjCz2T8+lgxho8yRZWbcmBmBwJHAx3cvQ3wG2CQu7cDzgLecfd24fKume1H8LXpaWY7FzpcHnBGMaf6zN3bu/t+wMnAJWY2tJi2q4DLiojVgBeBt929qbt3DI/VoHDbqOTm5rJs6bKC9eXLllO/3p4RRiSlWfndNwB8+8NqRk97lQP2aQvA6YecwNGdDmPQnRcVtF226isa1qlfsN6gTj1WhO+XiikJP5NJ6GOcKLkpH/WAVe7+M4C7r3L3FSW0PxV4HJgI9C+07y6CpKXEqpu7/we4FLiwmCb/Bk4ys8KTAQ4FNrr78JRjfeHu95R0vvLUqXNHFi/+jCWfL2Hjxo2MevY5+vbrG3VYUoydqlajerWdC173bn8QH33xKUe0P5grTziP/recxYaNPxW0Hzt9Eicf1I8qlavQePcGNK/XmOmL5kYVvpRBEn4m49ZHs+gmFJvZjmY23cw+MLOPzewv4fYmZva+mS0ys2fMrEq4vWq4vjjc37i0/mlYqnxMBK4zs0+B14Bn3P2tEtqfRDD81AL4PfBUyr4vgSnAacBLpZx3NrBvMfvWESQ4FwHXp2xvFb6vwqpcuTLD7r6Tfn2OIS8vj8FDTqdlq5ZRh7Xdhvz2DN55ewqrV61mnyb7cc11V7Hrrrty+SVXsOrbVZxwzIm0abs/Y8ZXiNHBMtujVh1GXzUCgMqVKvHk22N4dc5bLBo+mao7VGHSX54AgknFv3vgGuYvXcSzU8cx/95JbN6ymQsevI4tW7ZE2YXtcvqgwbzz1jusWrWaZns158/XX8uQMwZHHVZaxfVnMlUS+liOfgYOdfd1ZrYDMMXMXiH4D/kwd3/azIYDZwIPhH9/7+57m9nJwG0EvyeLZRrLLh9mVgk4CDgEOBf4k7s/Yma9gMvd/eiwXWfgLnfvHr7nC2B/d/8+nHMzDpgLjAV6AdNT5tyMc/fWKefcFVjh7tWKmHOzDvhXeKw2YbvqZnYh0MTdLwmPcR/Qg6Ca07mIfp0DnAPQsFHDjp/+Z2G6PrIKKW/L5qhDKBfVB7SJOoSM2/DC/KhDECmT7l16MGvm7LROkKm9z+5+1D0D03nIrYw88v5Z7l7qzZ3MbCeC/7D/DhgP7Onum8PpHDe4+xFm9mr4+r1w1OIroK6XkMBoWKqcuHueu0929+sJqjEnFNP0FGBfM1sCfAbULNzW3RcTJCUnlnLa9gSTjIuLaQ3wJHB+yuaPgQ4pbS4ADiOY9FzUMUa4eyd371S3bp1SwhERkYSoY2YzU5ZzUneaWSUzmwt8A0wi+H23xt3z/we5DMgNX+cCSwHC/T8AtUs6uYalyoGZtQC2uPuicFM7gopM4XY5wECgjbsvD7cdAlxLUGVJdQtBllvcORsDdwClzZX5OzCD/30vvAHcama/c/cHwm07lXIMERHJMhm+WmpVSZUbd88D2plZLWA0sF9RzcK/iwq0xGEnVW7KR3XgUTObb2YfAi2BG4po1xNYnp/YhN4GWppZvdSG7v4xv5wb08zM5pjZAh5Fq30AACAASURBVOBZ4B53f7ikwNx9FcE3VtVw3YFjgYPN7HMzmw48ClxZtq6KiIiUTTiCMJng1iO1Ui6WaQDkX3izDGgIEO7fBfiupOOqclMO3H0W0K2YfZMJvrD5r7sW2p9HcLUVwJBC+45Peb0EqFZCDI8Aj4Svbyi071KCiVz56ysJLv8WEZEYivJOwmZWF9jk7mvMrBrB7VFuA94EBgBPA4OBMeFbxobr74X73yhpvg0ouREREUmkCG/iV49gNKMSwQjSs+4+zszmA0+b2c3AHOChsP1DwONmtpigYlPqf76LTW7M7B5KGNNy9+LunyIiIiJSJHf/kOCCl8Lb/wMcUMT2nwjmo5ZZSZWbmb/mQCIiIpIt4v34hWKTm/xnEuUzs53d/cfMhyQiIiKy7Uq9WsrMDgzHwRaE623N7P6MRyYiIiIZYRY8+DNTS9TKcin4XcARwGoAd/+A4JJlERERkQqnTFdLufvSQplYXmbCERERkfKQyDk3KZaaWTfAwyd0XkgJt/QXERERiVJZhqXOAy4geLbDcoJHB1yQyaBEREQksyyDS9RKrdyEt+cfVA6xiIiIiGy3slwt1dTMXjKzb83sGzMbY2ZNyyM4ERERST8jmHOTqSVqZRmWepLgIYz1gPrAKOCpTAYlIiIimZX05Mbc/XF33xwuT1DKo8ZFREREolLSs6V2C1++aWZ/InhKpwMnAePLITYRERHJiIpxs71MKWlC8SyCZCa/9+em7HPgpkwFJSIiIrKtSnq2VJPyDERERETKh1G2eSnZqkx3KDaz1kBLYMf8be7+WKaCEhEREdlWpSY3ZnY90IsguXkZOAqYAii5ERERyUbhgzPjqixVqQHAYcBX7j4UaAtUzWhUIiIiItuoLMNSG9x9i5ltNrOawDeAbuInIiKSxSrC/WgypSzJzUwzqwX8k+AKqnXA9IxGJSIiIrKNyvJsqfPDl8PNbAJQ090/zGxYIiIikin5j1+Iq5Ju4tehpH3uPjszIYmIiEimxXlCcUmVmztL2OfAoWmORaTCq5RTprsnZL0NL8yPOoSMqza0XdQhZNyGh+dGHYJIJEq6id8h5RmIiIiIlBcjh/hWbuJ8g0IRERFJoGTU2EVERGQrcZ5zo8qNiIiIxEpZHr9gwCCgqbvfaGaNgD3dXfe6ERERyUJm8b4UvCyVm/uBA4FTwvW1wH0Zi0hERERkO5Rlzk0Xd+9gZnMA3P17M6uS4bhEREQkgyzGV0uVJbnZZGaVCO5tg5nVBbZkNCoRERHJqKRPKP4HMBrY3cxuAaYAt2Y0KhEREZFtVJZnS400s1nAYQSPozjW3RdkPDIRERHJCMNiPaG4LFdLNQLWAy+lbnP3LzMZmIiIiMi2KMucm/EE820M2BFoAnwCtMpgXCIiIpJBFuNb3ZVlWGr/1PXwaeHnZiwiERERke3wqx+/4O6zzaxzJoIRERGR8pH0OTeXpqzmAB2AbzMWkYiIiMh2KEvlpkbK680Ec3Cez0w4IiIiUh7ifJ+bEpOb8OZ91d39j+UUj4iIiMh2KTa5MbPK7r45nEAsIiIiMWHhn7gqqXIznWB+zVwzGwuMAn7M3+nuL2Q4NhEREcmEmD8VvCxzbnYDVgOH8r/73Tig5EZEREQqnJKSm93DK6U+4n9JTT7PaFQiIiKSUXGeUFzS7QkrAdXDpUbK6/xFJDITJ0ykTct2tGqxP7ffdkfU4WSE+ph9ciyH2Te9yEuXPgjAIft1ZdaNo5l36zgeOec2KuVUAuDgfQ9gzfBZzLlpDHNuGsOfj7kgyrC327lnnUejenvRsW2nqEPJqLh9v8ZZSZWble5+Y7lFIlJGeXl5XHzhpYyf8BK5DXLp0fUgju7Xl/1a7hd1aGmjPmani44YzIIVn1GzWnXMjEfPuY3DbhvMoq+W8JfjL2Rwj+P499vPAfDOpzPp9/d43Oz9tNN/y3nnn8tZQ8+OOpSMidv3qwE5MX78Qkk9i2+9SrLajOkzadasKU2aNqFKlSoMPHEA48aOizqstFIfs0/urnvQt20v/jV5FAC1q9fi580bWfTVEgAmffQuJ3Q+IsIIM6dHzx7stttuUYeRUXH7fo27kpKbw8otCpFfYcWKFTRo2KBgPbdBLstXrIwwovRTH7PPXYOu4Ypn/sYW3wLAqrXfs0OlynRs0hqAAZ2PoOFuexa0P3Dvdsy9eSwvX/YvWubuHUnMUnZx+34FwyxzS9SKTW7c/bvyDCRpzGyYmV2csv6qmf0rZf1OM7vUzCqb2Soz+2uh9082s06FtvUys3Ep6zeHx62a2t7MlpjZ8yntBpjZIynrR5rZdDNbaGZzzewZM2uU1g9gO7j/cj57RfhhSif1Mbv0bdeLb9auZvaSj7fafvL9lzDs1Kt5//rnWPvTj2zekgfA7CUfs9clh9Du2v7cM+lxXrzo/ijCll8hTt+vSfCrH5wpafMuMBC4y8xygDpAzZT93YCLgd7AJ8CJZna1F/UTVgQzuwboDvRx95+L+CHsZGat3P3jQu9rDdwD9Hf3BeG2/kBj4Mtf18XMyM3NZdnSZQXry5ctp369PUt4R/ZRH7NL9+Yd6d/+MPq0OZgdd6hKzWrVefzc2zntwT/S85ZTATi8dXf22bMxAGt/KrhlGK98+Bb3V7qe2tV3ZfW676MIX8ogTt+v+eKcnMV3NlHFN5UggQFoRXDJ/Voz29XMqgL7AXOAU4C7CRKLrmU5sJldBvQB+rn7hmKa3QFcXcT2K4Fb8xMbAHcf6+5vl+Xc5aFT544sXvwZSz5fwsaNGxn17HP07dc36rDSSn3MLlePupOGF/ekyWWHcvL9l/DGgmmc9uAfqVsjmIdSpfIOXNn3HIa/8TQAe+xSp+C9nZu2IScnR4lNBRen79ckUOUmIu6+wsw2h8M93YD3gFzgQOAH4EOCy/EPA84FahEkOu+VcujuQAugo7uvK6Hds8D5ZlZ4sL8VQeJTJmZ2DnAOQMNGDcv6tu1SuXJlht19J/36HENeXh6Dh5xOy1Yty+Xc5UV9jIc/9j2Lo9sdQo4ZD7zxFG8umAbAgM5H8rtDT2Hzljw2bPyJk++7JOJIt8/pgwbzzlvvsGrVaprt1Zw/X38tQ84YHHVYaRXH79ecGF83ZGUc5ZAMMLORwEvAUcDfCZKbbgTJTW1gFnCsuw8ys9rAXKCxu+eZ2WTgcnefmXK8XsDtwK7An9z9uZR9Be3NbAnQCehPkAy9Ahzt7kPMbDYw1N0/CM/5OrATMMLdS0x6Onbq4FPfn7Kdn4pI+ag2tF3UIWTchofnRh2CpEH3Lj2YNXN2WjORhi0b+EVPXpjOQ27lj+2vnOXukd34SMNS0XqXIJnZn2BYahpB5aYbwbDVKcBvwmRkFkHCc0gpx/yaYEhqmJmV1vZxoCeQOln4Y4JniuHuq929HTAC3bhRRESyhJKbaE0Fjga+c/e88Aq1WgQJzgdAD6CRuzd298bABQQJT4nc/VPgeOAJMyv2v6fuvgkYRjBxOd/fgGvMLPXOVDv9ql6JiEjFFj44M1NL1JTcRGsewVVS0wpt+4HgQaVvuPvPKfvGAP3DCccA481sWbiMSj2wu88AhgJjzaxZCTE8RMrcK3efB1wEPBZeCj6VYHLzk9vUQxERkXKmCcURcvc8tr78G3cfkrL6SKF93wF1w9VexRx2ckr7ifxvyKlXyvbGKa9/BuoXOs94YHwp4YuISNYyLMYTilW5ERERkVhR5UZERCRhjOAp9nEV356JiIhIIqlyIyIikkB6/IKIiIhIllDlRkREJIHifLWUkhsREZHEqRg328sUDUuJiIhIrKhyIyIikjBGvIelVLkRERGRWFHlRkREJIE050ZEREQkS6hyIyIikjQGpscviIiIiGQHVW5EREQSx2J9tZSSGxERkYQJngoe3+RGw1IiIiISK6rciIiIJJCeCi4iIiKSJVS5ERERSaCcGE8oVuVGREREYkWVGxERkYQx4j3nRsmNiCTS+n/PiTqEjNv3jn5Rh1Au5l82JuoQMso96gjSy8waAo8BewJbgBHufreZ7QY8AzQGlgAnuvv3FmRhdwN9gPXAEHefXdI5NCwlIiKSOIZZTsaWUmwGLnP3/YCuwAVm1hL4E/C6uzcHXg/XAY4CmofLOcADpZ1AyY2IiIiUG3dfmV95cfe1wAIgFzgGeDRs9ihwbPj6GOAxD0wDaplZvZLOoWEpERGRBMrw1VJ1zGxmyvoIdx9RuJGZNQbaA+8De7j7SggSIDPbPWyWCyxNeduycNvK4k6u5EZERCRhzDI+oXiVu3cqOQarDjwPXOzu/y0hnqJ2lDgTScNSIiIiUq7MbAeCxGaku78Qbv46f7gp/PubcPsyoGHK2xsAK0o6vpIbERGRBLIM/inxvEGJ5iFggbv/PWXXWGBw+HowMCZl++kW6Ar8kD98VRwNS4mIiEh56g6cBswzs7nhtquB/wOeNbMzgS+BgeG+lwkuA19McCn40NJOoORGREQkcSyym/i5+xSKnkcDcFgR7R244NecQ8NSIiIiEiuq3IiIiCSQHpwpIiIikiVUuREREUmY4MGZ8a1vxLdnIiIikkiq3IiIiCRO6fejyWZKbkRERBIoqkvBy4OGpURERCRWVLkRERFJoDgPS6lyIyIiIrGiyo2IiEgCac6NiIiISJZQ5UZERCRhDD1+QaTCmThhIm1atqNVi/25/bY7og4nI9TH+MjLy6Nrp24cf8yAqEPZbjmWw/ghw3nohFsAaLDLnrx42r28efaj3Nv/WnbICf7PXL/G7jx18p2MHzKcV4b+k15ND4gy7LS456576dS2M53aHcDg3w7lp59+ijokKYaSG8k6eXl5XHzhpYwZN5o582Yx6plRLJi/IOqw0kp9jJf7/nE/++7XIuow0mJop+NZvPrLgvU/9Tqbh2Y+zyH/HMwPP63jpDZHAfD7boMYv3AyfR85jz+MvZmbe18UVchpsWL5Ch64bzjvTHubmXOnsyUvj1HPPBd1WNvODMvgEjUlN5J1ZkyfSbNmTWnStAlVqlRh4IkDGDd2XNRhpZX6GB/Lli1nwisTGHLG4KhD2W571qjDoU278PQHLxds69aoPS8vfAuA5z+aSO99uhfsq151ZwBqVt2Zr9etLt9gM2Dz5s1s2LCBzZs3s379eurVrxd1SFIMJTeSdVasWEGDhg0K1nMb5LJ8xcoII0o/9TE+rrjsCm7+683k5GT/P7fXHXYBf508AncHYNdqNfnvz+vI8y0ArFz7LXtUrwPAsCmPcmyrw3jv/Kd5eOCtXD/pnsjiTof6ufW56JIL2bdpS5o13JuaNXfhN4cfFnVY28XIydgStegjEPmV8v9hTVURyqDppD7Gw8vjX6Fu3bp06Ng+6lC226HNurL6x+/56OtFBduKugmcE3xd+7c8lOfmTeTA+09m6KirGXb0VVl907jvv/+ecS+N5+NF81j85SLWr/+Rp0Y+HXVY20XDUtvAzIaZ2cUp66+a2b9S1u80s0vNrLKZrTKzvxZ6/2Qz61RoWy8zG5eyfnN43Kqp7c1siZk9n9JugJk9krJ+pJlNN7OFZjbXzJ4xs0Yl9OURM/vczD4ws0/N7DEzy03Zv0u47bNweczMdgn3jTazY1PafmJm16asP29mx4d9czPrl7JvnJn1Cl8fbWZzwhjmm9m5ZnZNGP9cM8tLeX1h+J67zWy5pTzX3syGmNm94esbwv1zw2OektKuq5m9H+5bYGY3FPf5lLfc3FyWLV1WsL582XLq19szwojST32Mh2nvTmP8uJfZd++WnD5oCG+9+RZnnH5m1GFtk065rfhN825MOW8k9/S/lm57teO6w86nZtXqVAr/ialXoy7fhMNPJ7U5ivELJwMwe8V8qlbegd122iWq8Lfbm69PpnHjvahbty477LAD/Y/tz/vvvR91WFKMTFZu3gW6AYS/XOsArVL2dwOmAr2BT4AT7Veke2Z2DdAdONbdfy6iSScza1V4o5m1Bu4BBrv7vu7eDhgJNC7llH9097ZAC2AO8KaZVQn3PQT8x92buXsz4HMgP5FL/RxqA+uAA1OOe2DYBmAZcE0RMe8AjAD6hTG0Bya7+y3u3i7sw4b81+7+j/AzPw5YCvQsoV/DwvcfAzwYngvgUeCccF9r4NlSPp9y06lzRxYv/owlny9h48aNjHr2Ofr26xt1WGmlPsbDjbf8hcVLPmXh4vk8NvIRDj7kYP792ENRh7VN/vb2Qxx4/8n0GD6IP4y9mXe/mMvF4/7Ke1/Opc++BwNwQuveTFwU/HO24r/f0H2vDgA0q92IqpWqsHr9msji314NGzZgxvQZrF+/Hndn8huTabFv9k4SN/KfC56ZP1HLZHIzlfCXOkFS8xGw1sx2NbOqwH4EScIpwN3Al0DXshzYzC4D+hD8st9QTLM7gKuL2H4lcKu7F1yW4e5j3f3tspzbA8OAr4CjzGxvoCNwU0qzGwmSq2Zs/Tl0A8YBdS3QhCAp+Src/wHwg5kdXui0NQjuSbQ6jOFnd/+klFAPIfjMHyD4jEvr1yJgPbBruGl3YGW4L8/d5xf1PjM7x8xmmtnMb79dVdpp0qJy5coMu/tO+vU5hnatO3DCgBNo2apluZy7vKiPki3+b/I/ObPTACaf8xi1qtXk2Q9fAeDmN4Zzcts+vDJ0BPf0u4bLX/5bxJFun85dOnPs8cfS/YAedG7fhS1bnDPOHhp1WFKMjN3Ez91XmNnmcLinG/AekEtQqfgB+BCoBBwGnAvUIvgl/F4ph+5OUD3p6O7rSmj3LHB+mHykakWQ+Gyv2cC+gANz3T0vf4e755nZ3PBcrwKtwypPN+AtoClBcteeIPlJdXO4TEo53ndmNhb4wsxeJ0iQnnIPZ/EV7RTgKWAMcKuZ7eDum4prbGYdgEXu/k24aRjwiZlNBiYAj7r7L27q4O4jCKpKdOzU4ZeTKDLkyD5HcmSfI8vrdJFQH+Ol58E96XlwSUXU7DFt6QdMW/oBAEt/WMmxj1/wizaLV3/BgJHZffl3Yddefw3XXv+L4nqWMnIqwNyYTMn0hOL8qkV+cvNeyvq7wNHAm+6+HngeOM7MKpVyzMUEFbXepbTLA24HriqugZnVDueUfGpml5ehP1u9PeXvon6pG0Gh52fgY6ADQWXqfX75ORRw93fC2A4qtP0sgkRwOnA58O8S+lWFoLL1orv/NzxncZ/XJWb2SdjmhpTz3Qh0AiYCpxIkOCIiIhVeppOb/Pkm+xMMkUwjqNzkz7c5BfiNmS0BZgG1CYZTSvI1wS/uYWZWWtvHCeabpE4Wzk80cPfV4ZySEUD1Mvcq0B5YEB6vfaFJuzlA23A/BJ9DT6CGu39P8DnkJzeFKzcAt1DE3Bt3nxcOiR0OnFBCbEcCuwDzws+2B8UPTQ1z9xbAScBjZrZjyvk+c/cHCJKqtuGcIRERiQHNudl2UwmqM9+F8za+Ixh+OpBgfkkPoJG7N3b3xsAFlG1+yKfA8cATZtauhHabCIZXLk7Z/DfgGjPbL2XbTmXtUDhX5kKgHjDB3RcTzB26NqXZtcDscB8En8O5BH2GYEiuK0HS9XERcU8kmPvSNjxn9fyrpkLtgC9KCPMU4KyUz7UJ0NvMiu2nu78AzAQGh+fsmzLBuzlBJSx7ZwOKiEhiZDq5mUdwldS0Qtt+AA4F3ih0pdMYoH844RhgvJktC5dRqQd29xnAUGBsOHG3OA+RMrfI3ecBFxFUKRaa2VSC+S9PltKX283sA+BToDNwiLtvDPedCexjZovN7DNgn3BbvncJ5tm8F8awGfgGmFnCvJlbgPw7nBlwRXgZ+VzgL8CQot4UJjBHAONT+vwjMAXoV9R7UtwIXBpWnk4jmHMzl6ACNih1XpGIiGQ3i/F9bqyoG2mJbIuOnTr41PenRB2GSJkk4d++/e7sH3UI5WL+ZWOiDiGjenTpyexZs9OaMTRvs7f/Y3zmHlbbp9Fxs9y9U+ktMyNjV0uJiIhIxRTc5ya+DylQcpPCzO4juNQ81d3u/nAU8YiIiGRGxRg+yhQlNync/Zc3axAREZGsouRGREQkgXIqwCXbmRLfATcRERFJJFVuREREksaI9ZwbVW5EREQkVlS5ERERSZjgUnBVbkRERESygio3IiIiCRTnOTdKbkRERBLHYn2H4vj2TERERBJJlRsREZEEyonxsJQqNyIiIhIrqtyIiIgkjC4FFxEREckiqtyIiIgkUJwvBVflRkRERGJFlRsREZHEMc25EREREckWqtyIiIgkUJzn3Ci5ERERSRgDcmI8eKPkRkQSadOWjVGHkHELL38p6hDKRZ2re0YdQkZtWP5J1CFkHSU3IiIiSWPxHpaKb01KREREEkmVGxERkcTRpeAiIiIiWUOVGxERkQTSnBsRERGRLKHKjYiISAJpzo2IiIhIllDlRkREJGGMeFdulNyIiIgkkSYUi4iIiGQHVW5EREQSRzfxExEREckaqtyIiIgkkG7iJyIiIpIlVLkRERFJIM25EREREckSqtyIiIgkkCo3IiIiIllClRsREZGEMXS1lEiFM3HCRNq0bEerFvtz+213RB1ORqiP2WnZ0mUc3bs/ndt0oUu7A3ngnuEA3HzDLXTr2IMenXtybJ/jWbliZcSRplecvpY5lsPUC0cyasiwrbbf0f+PfHXj2wXrDWrtwcvnDGfqhSOZdvFT9G7RvbxD3Q6W0T9RU3IjWScvL4+LL7yUMeNGM2feLEY9M4oF8xdEHVZaqY/Zq3Llytx8203M+PB9XntnIv8c/hALFyzkwkv/wLuzpjBlxtsc2ecIbrvl9qhDTZu4fS3P73EKn3zz+Vbb2ufuxy7Vamy17cpDz+SFDyfR/R+DGPLk1Qw79sryDFNKoORGss6M6TNp1qwpTZo2oUqVKgw8cQDjxo6LOqy0Uh+z15719qRd+7YA1KhRgxb77sOK5SupWbNmQZsf16+P1ZBAnL6W9XfZnSP37c6jM14s2JZjOdzS9yKuffnurdo6UKNqdQBq7lidlWu/Lc9Qt1ucKzeacyNZZ8WKFTRo2KBgPbdBLtOnz4wwovRTH+PhiyVf8uEHH9LpgI4A3HjdzTw98mlq1qzJuIljI44ufeL0tfxbv8u49uV/UKPqzgXbzut2IuPnv83Xa1dv1faWSQ8y9sz7OK/7iey0QzX6/ev88g5XiqHKjWQdd//Ftjj9LxjUxzhYt24dp508mL/ecWtB1ea6G69l/mcfMfCUgYx44J8RR5g+cflaHrlvD75d9x1zly8s2LZnjTocu/9vGP7uM79oP7DdkTwx6yVa3NqXEx6+iH+ddGP29NuCr1GmlqhlRXJjZsPM7OKU9VfN7F8p63ea2aVmVtnMVpnZXwu9f7KZdSq0rZeZjUtZvzk8btXU9ma2xMyeT2k3wMweSVk/0symm9lCM5trZs+YWaMS+rJVLGbW2Mw+SonpBzObY2YLzOz6cPtOZjbSzOaZ2UdmNsXM9grPN9fMvjKz5SnrVcysrpltMrNzC51/iZnVCV/nhe0/MrOXzKxWuD3HzP4Rbp9nZjPMrEkpX6Zyk5uby7KlywrWly9bTv16e0YYUfqpj9lt06ZNnHbSYE48eQD9j+33i/0DTxrA2NEvRRBZZsTla9m1cVv6tOzJx1eO5ZFTb+HgZp2ZcemzNKvTgA//OJqPrxzLTjvsyAd/HA3A4M79eeHD1wCY/uU8qlauQp2dakXZBQllRXIDvAt0g+AXL1AHaJWyvxswFegNfAKcaL8idTSza4DuwLHu/nMRTTqZWavCG82sNXAPMNjd93X3dsBIoHFZz12Ed9y9PdAJ+K2ZdQQuAr529/3dvTVwJvCVu7cLzzkcGJa/7u4bgYHANOCUEs61IWzfGvgOuCDcfhJQH2jj7vsDxwFrtqNPadWpc0cWL/6MJZ8vYePGjYx69jn69usbdVhppT5mL3fn9+deSIt99+H3F19QsP2zRZ8VvH5l3Cs0b9E8ivAyIi5fyxsm3EeLW/vS6rb+DHnyGt76bAYN/3IozW4+kla39afVbf1Zv+kn2t5+HABL/7+9+46XpCzTPv67yEOOKsswDkGJS0YliIR9JUhQdCXoCygr6EpU1F1QQPeD8gqIrLisKAjIEkVXMig5DcIMWURGCRIUiZIUHa73j6eaaQ4nzDl0d03Xub58+jNdVd1Vd50ZTt/9hPt59g9suuL6AKz0lsnMN/e8/OnFZ+q8hVHJmJv63QC05uStBtwNLC1pMeAlYBXgNuAk4DjgM8B7gJtGOrGkzwPbAFvafnmIlx0NHAx8bMD+LwFft/3atADbHelIt/2ipKnACsDSwENtx+6bhVPsAnweOEPSMrYfHeH1NwFrVM+XBh63/Wp1vUeGfFcN5pprLo497hi222YHZsyYwe577Maqq61ad1gdlXvsX1NuvJmz/udsVlt9VTZefxMADv3aVzjtlB8x/TfTmWOOOVh20rIce/wxNUfaOU39uxzJwRd+m+98+Mvss/GuGLP3OYfXHVJUNFhf6exI0oPAJsDWlPpDy1A+kJ8DvgFsCfwWWBH4OLC67f2q914NHGT71rbzbQr8FHgSWNf2n9uOvfb66rrvBq4GtgPWAra1vYekacAnbN8xivt4XSySJgMX2l69iukg29tKWgKYCnwAmBu4vLq/K4BTbd/fds7DgRdsH11tLwtcafsdkr4OPGn7W20/x/VsPynpBdsLSpoTOAs4yfalkiYC11Naa64ATrd92xD3sxewF8Cyk5Zd9ze/+/VgL4uY7bwyY7BG2maZZ8556w6hJ5Y8eJO6Q+iql0+9lxl/eLGjzSGrr72qz7nqjE6e8nVWW2ztqbbXG+q4pJOBbYEnqt4DJC0OnE3p/XgQ+KjtZ6qemOMoDREvAXvYnjbc9fulWwpK682G1eOm6tHavpHyQ7rK9kvAecCHqg/t4UynJErvH+F1M4Cjd4dcnAAAIABJREFUgH8f6gWSlqjGr/xG0kHDnGuwbLJ933sl3UZJZo60fY/t24HlqxgWB26RtMow19gZOKd6fhZDd01NkHQ78FR13p/Day01K1Hu91XgCklbDHoz9om217O93lJLLTlMSBERMfvoZqfULOVhpwBbDdj3b8AVtt9B+WL9b9X+rYF3VI+9gBNGOnk/JTetcTf/SOmWmgJswMzxNrsA/1S1TEwFlgA2G+Gcf6RkgsdKGum1P6K0HLUPFr4HWAfA9lPV+JcTgQWHOc9TwGJt24tTWo9arrO9tu11bf93a6ftF2z/xPa/AqdXcQ9lF2CP6mdxPrCmpME6+F+uYn47MA8zx9xg+6+2L7H9BeDrwAeHuV5ERMQss30tZaxnux2AU6vnpzLzc2cH4DQXU4BFJS093Pn7Kbm5gdI687TtGbafBhalJDh3ABsDk2xPtj2Z8kE93GBaAGz/BtgROF3SWsO87m+UcT8HtO3+JnDIgFaU+Ue45NWUgcKt1HZ34Krh3iBpo2p8EZLmAValbQzOgNeuBCxge5m2n8U3KK05g7L9HLAfcJCkuSWtI+kfqvPNQRmLM+j1IiKiP3W55WZJSbe2PfaahZDeavtxgOrPt1T7lwF+3/a6R6p9Q+qn5OYuyiypKQP2PQdsThlj0t6J/jNge0mtTueLJD1SPc5tP7HtW4BPAOdLWmGYGE6ibRC27bsoM5lOq6aC30AZ3DxcR+aJwPPAHZLuoLTyjLQQywrANZLuogycvpXS9TaYXShjidqdxwiJXjWm5g5KEvQW4IJqivqdwN+B40eIMSIiouXJ1pCF6nHimzjXYP1cww4Y7pfZUtieASw8YN8ebZunDDj2NLBUtbnpEKe9uu31lzOzy2nTtv2T257/lTJFuv06FwEXjRB+++tfAfYZ4tjV7TG17T8NOG2Ycx4+2PO2fXdSWnsG3s+CA17XXpDj0qGuFxER/W8UFVN65Y+Slrb9eNXt9ES1/xFg2bbXTQQeG+5E/dRyExEREc11PmWoBtWfP2vbv5uK9wDPtbqvhtI3LTf9RtJ3KYUB2x1n+4d1xBMREdGuzmJ7ks6k9JIsKekR4DDgSOAcSXsCD1OK0QJcTJlEM50yFfwTI50/yU2X2P7syK+KiIgYf2wPNQ70DWVHXAryjeozNclNRETEOCPqbbnptoy5iYiIiEZJy01ERMS4o9lxtlTHJLmJiIgYl5qb3KRbKiIiIholLTcRERHjjWbLIn4dk5abiIiIaJS03ERERIxDmQoeERER0SfSchMRETEOpeUmIiIiok+k5SYiImKcUcOL+KXlJiIiIholLTcRERHjUJPH3CS5iYiIGIeanNykWyoiIiIaJS03ERER41AGFEdERET0ibTcREREjENNHnOT5CY6ZtrU256cMNcCD/XwkksCT/bwenUZD/eZe2yG3GN3vL3H1+t7SW6iY2wv1cvrSbrV9nq9vGYdxsN95h6bIffYP1LELyIiIqKPpOUmIiJiHGrymJu03EQ/O7HuAHpkPNxn7rEZco8xW5DtumOIiIiIHlpznTV8yfUXdu38yyzw9ql1jk1Kt1RERMQ41NxOqXRLRURERMOk5SYiImIcylTwiIiIEUhaTE3+xIy+keQm+pKkZSRNqh6NaIGUNKekBdu23yNpk+qxUJ2xdYqkHSR9tm37Zkm/qx4fqTO2TpE0UdLGbdufk3Ro9Vixztg6qbqflavn80q6Cvgt8EdJ/1RvdJ0h6e2SFmnb3kzScdXf6Tx1xtYZ6uKjXkluoi9I+ndJh7btugm4ELgc+EI9UXXc/wP+tW37TMq9fQX4ci0Rdd4XgfPbtucF1gc2BT5TR0BdcBSwaNv23sCLgIGv1hJRd+wE3Fc93736cyngfcDXa4mo884BFgCQtBZwLvAwsCbwXzXGFSNoxDfeGBf+GXhv2/ZTtteWNCdwDfCNesLqqC0oH/Qtz9rermrmv66mmDptHtu/b9u+3vZTwFOSFqgrqA5byXb7HNuXbB8DIKkpf48Ar3hmLZEtgbNszwDubUprKjDB9mPV848DJ9s+RtIcwO01xtUR9bevdE9abqJv2H6xbfO4at8MYEI9EXXcHLb/3rb9JYDqA2TBwd/SdxZr37C9T9tmT9cm66L5Bmxv0fZ8iV4G0mV/lbS6pKWAzSitqC3z1xRTp7V//m8OXAFg+9V6wolZleQm+sWCkuZubdg+BUpfP7BwXUF12DztY2tsXw5Q9fkP/MDsVzdL+tTAnZL2Bn5ZQzzd8Lykd7Y2bD8NUI1PeaG2qDpvf+DHwK+BY20/ACBpG+C2OgProCslnSPpOEpifiWApKWBV2qN7E3r5nib+tuEmtJ0GM33Y+B7kvax/RJA1Y1xfHWsCb4PnC3p07YfhjKgETihOtYEBwL/K2lXYFq1b13K2JsP1hZVZx0GXCjpCF5/jwdTEoJGsH0zsPIg+y8GLu59RF1xAGVs0dLAxrb/Vu1/G3BIbVF1gNTsqeBJbqJffAU4AnhY0kOUrwbLAidVx/qe7W9Jegm4vm38yQvAkbZPqDG0jrH9BLChpM2B1ardF9m+ssawOsr2pZJ2pAye3q/afTewo+2764us86oxb4vZfrLangfYAzjQ9ip1xtYJVZfwWYMcuhPYucfhxChkbanoK5ImAK3ptNNtv1xnPN1STQmX7efrjiViMJJ2Br5HmQl2P3A48CPgFuA/bE8b+t39QdLCwGeBZSiz/H4O7AMcBNxue4caw3tT1lp3TV9+wyVdO/9bJyyTtaUiRiJpk0F2r99qVrV9bW8j6jxJuw2y77Xntk/raUBdIOl5ypTogeaizKTq+99Jkn7I4PcIpTFgz17G00VfBta1PV3SOpTyDDvb/mnNcXXSj4BnKPf2L5TSDPMAO9ju+9lSTdb3v0hi3Bislo0p9SYmAnP2NpyuWH+QfQK2o3xz7PvkxvbrihFWA6j/lVILpikfioMttTyJMn6jCf9OW16xPR3A9jRJDzQssQFY3vY/Akj6AfAkMKkpLaqaDQb+dkuSm+gLtrdr364qwB4CPE5pJu57tvdtPa9q23yMMh18CmW8UWNIWpTyYb8bcAawflXvpu/ZPq/1XNLylIHEmwBHUsaINcVbJH2ubXvB9m3b36ohpk5rDSDG9owqgWtEYtN0SW6ir0jagjKA2MDXbf+85pA6qip+tgfweeBm4CO27xv2TX1E0pKUe9sJOBlY2/Zz9UbVeZJWoSTfa1MqFn96QA2jJvg+sNAw202wpqQ/V88FTKi2Reli7OsyFGm5iaiZpA9QPiyeAw6xfUPNIXVctebS/pRCYVvZfqjmkLrhIeBPwA+Bl4A9B4wr6vtv+5LOBdYDjqZMfZ8BLNw2Puzp+qLrHNtNWkpiULab1I04riS5iX5xAfAI8BTwpYH1GWxvX0dQHfYd4AlgY+CCtntsfUtco67AOugoZg62bdq3/Jb1Kfd4EKWVqv0fq4Hl6wiq0yT953DHbe833PF+IGnx4Y43JVFtoiQ30S82qzuAHliu7gC6zfbhdcfQbbYn1x1Dj0ytO4AemEpJSAfrv2lMotpESW6iL9i+pu4Yuq2h3VCvM06+7a8z3PEm1H8BsH3qYPslzUeZ4df3bDf6C0cqFEfUTNJdDF07hCZ02QxTA6YRgxcr4+Hb/jHDHDNlAcZGqSoVvx/YhbJC+HXAubUG1SWSVqBUJ97F9up1xxODS3IT/WLbugPogcXb1q5ppKG+7TfMlrYHXVRRUqNaAqrimrsCH6AsfLoRsFxr/bemqBbK3Ilyr2sA36AkcjGbyqrg0S++BDxj+6HBHnUH1yE31x1AL0jaXdI0SS9Wj1sHq87cx35WrbH0OpLWAK6qIZ6ukPQIpXbPDcCqtj8MvNykxEbSpyRdCVwDLEmpUvy47a/avqve6N4sdfW/uiW5iX7xIDC1Wk26qer/jdBlVRJzAGUW0T9QKi9/Edi/QQnOVOASSfO3dkjalLJS9qfqCqoLzqP8/e0EbFct9tq0xQq/S6kqvavtL9u+k+bdYyNl4czoG5KWAb5F+QZ1AvBq65jtn9QVV6dU34SHrPPSkBowUyjrDz04YP9k4Czb76khrI6TdAiwFbA1ZQzKsZRVwW+tNbAOqyppb0bpotkGWBjYE7jY9gt1xtYJkpYCPkK5v7cC5wB72F621sA6YK111/KVN3avBuoS870lC2dGzArbj0q6iLIUwXbMTG4M9H1yQ/mGuCDNbsFZeGBiA2D7wWoF5kawfYSklymtOAI2b63D1BSS9rF9PHAlcKWkuSkJ3S7Af1G+hPS7Z2yfAJwgaSJlIPETku4Ffmr74HrDi6EkuYm+IGk1SmvNY8C7bD9ec0jd8Ljtr9UdRJe9PMZjfUPSBcysjbIUMB34VluF4iYUnAT4JHB8a6MaDH8BpQDlhNqi6qxfAusA2H6EUnX6aEkrURKdviWa/S0qyU30ix8DB9i+rH1nq6aG7SZMO51cdwA9sIqkOwfZL5pTEO3oIZ6PG7YbkagyxOd/td5b45ef6GdJbqJfrGX7r9DomhqP1B1AD6xSdwDdNlzBSUlnU2beNMEabYtKtmtSXaalBqx8/jr9Pg4uRfwiamb7r+OgpkbTVo1+gwZN2x+rDeoOoIPusr123UF02XgYB9dISW6iL1QziR6mjLv5gu3nJT3QoMQGYOJwyxM0ZGmCB3j9VFq1bdv2Cr2PKmJIDR8H19ycLclN9IvzgA9SamrMkPQzmldvojW7pskGTg2dA/goZQXt23ofTucNs7aUgLl7GUuXNaEreCTN/fSn2TeX5Cb6gu39JR3AzJoaRwELS/ooDampATzV9OUJbD8FIGkO4P8CXwBuBz5g+1d1xtZBw60t9eueRdF9f5L0Dtv3V/VuTgY+TCm4uUdDFgjdQdLcrWVRqllS2wAPNaG2VpMluYm+4VJxssk1NQZdj6hJqr+3TwIHAtcDO9j+bb1RdZbtzYY6Vt1/U+wPnFI934Wy5tJywNrAccB76wmro06nFCW8X9KKwE3A/wDbSlrf9r/XGt2b1ty2myQ30ZcG1NTo818wr/nsMF0aNOSb8AOUgdPfpoyhWlPSmq2DTfw23FbFd1dK8cm31htRx/y9baHXbYHTqpa5X0j6Zo1xddJitu+vnu8OnGl732rtsKlAU373NE6Sm2iCz1BW6e13RzOz+Bu8cUzR5r0Npyt+QbmvNatHu6ZUmgZA0rspCc2HgMWBz1K64Zri1Wq17GeALSiVw1uaUsSv/f/BzSnd4dh+RdKrg7+lXyhTwSNmc035P/RLwO9b1Zcl7c7MMQyH1xdW59jeY6hjkhrRoiHpCMog6YeBM4GvAbc2cDzVocCtlOnS59u+B0DS+4Df1RlYB90p6WhKZfQVgcsBJC1aa1QxoqwKHk3QlFlT/w20ChVuQmmNOhV4Djixxri6RtIikj4p6RdAE7rdAPYC/kgpW3B61VXTlH+jr7F9IfB2YBXb7aud30qZ1dgEnwKeBCYB728rPbEq47T6dL9Iy030BUnPM/gHhGhOE/ictp+unu8EnGj7POA8SbfXGFdHVesObU/pslkHWIgyzf/aOuPqoLcxs4L2tyVdBUyQNJftxhRqrBLw1vPBXtL3f5+2X5Z0GbACbQP+bd8I3FhbYDGiJDfRF2wvVHcMPTBn2wfgFpQWgJZG/L8q6X+ATSjN+60VpafbvrrOuDpsX+AGyqywuSiDbecHHpV0he1d6wyugwYbP9QaTzWR0l3V1yQdCnycMnj4m5K+Yfv7NYfVEWXhzKb06L9RI35hRjTEmcA1kp6kFPS7DqCagvpcnYF10OqUAaj3Ar+2PUNS07psJlKmQq8M3En5hn8y0KrT1Ai2t2vflrQxcAjwOLBPLUF13k6Ude1ekrQEcCnQiOSm6ZLcRMwmbB8h6QpgaeDyqq4PlLFx+9YXWefYXlPSypQuqV9IegJYSNLbbP+h5vA6wvZBANV04fWADSmtOBtQktTT6ouu8yRtAXyF0mrzdds/rzmkTvpLa5yN7aeq4pMNkpabiOgB21MG2febOmLpBknvqe7xUOBQSetRxqb8UtIjtjesN8KOmgAsDCxSPR4D7qo1og6S9AFKS81zwCG2b6g5pG5YQdL51XMN2Mb29vWE1RnNTW1AM78cRkR0l6Rptt9QqLAqdLeJ7WtqCKujJJ0IrAY8D9wMTAGm2H6m1sA6rKrz8ghwB4MM9u/3D354bVr7kPr53+s6667ta6dc3bXzLzTPolNtD1xLrmfSchMRtau64Pr2g2KAScC8wP3Ao5QE4NlaI+qOxowfGko/Jy+zIkX8IiI6Y/n2Zv2BmvBt3/ZWVUvUapTxNp8HVpf0NHCT7cNqDbBzFgNutP1E3YF0i6S7eH2rlCl1b64Cjrb9l1oCixEluYmIXvoTw6+a3QhVS9Tdkp6ljEl5jjIl/F1AU5KbjwPflfQSZer7jcANrUrFDbHtIPsWp6wz9R1Kkb8+JZo86ibJTUT00gvjoKl/P0qLzUbA3ygf/DdRpoM3ZkCx7Y8ASJpMud8Ngb0lTQJusb1NfdF1hu2HBtn9EHCbpNt6HU/MuiQ3EdFLz7RP+5a0G2X9rIeAw9sqNPezycCPgQNb64Q1me0HJc1HmR02AWg9b7q+nxbe3HabJDcR0VuLUpWxr8r3H0mp4bMWZf2sj9QXWmfY/lzdMfSCpIMptXuWAu6jzAo7HtjL9ow6Y+sUSW+Y2UcZa/RxGrC8RJMluYmIXppjPKyfNU7sBrwAXEgZb3Oz7aZU0m4ZOD7MwFPA1TRiMdvmtt0kuYmIXpqr6etnjRe2V5a0OGWszabAv0lakFL35kbbP6wzvk6wPUvT3SXtbvvUbscTsy6/TCKil8bD+lnjRtUKd6GkS4F1KYui7k1ZbqLvk5tR2B/or+RGqXMTEdER42H9rPFC0vbMnBW2GnAPpXvq89Wf40lzs4QukbQVZYHZOYEf2D6yk+dPchMRPdX09bPGkT0oScwXgam2X6k3nFplHaNRkDQn8F3g/1AqeN8i6Xzbv+rUNZLcRETEqNneEUDScsD7JRm41/bv6o2sFn3XclNK+NUW9ruA6a1/K5LOAnYAktxERER9JC0EnEQZa3MH5fNyTUlTgT1t/7nO+Hqs71ZEnzb1tssmzLXAkl28xHySbm3bPtF2a4bZMsDv2449Ary7kxdPchMREWPxHco37Z1tvwqvre7+FUq9m91qjK0jJE0EJtu+vtr+HLBgdfgM29MBbO9TU4hjZnurGi8/WJNRR7v2+r7CYkRE1GIj24e3Ehsoa2rZ/hqluF8THEUpPNmyN/Ai5YP4q7VE1AyPAMu2bU8EHuvkBdJyExERY9F340zGYCXbF7Ztv2T7GABJ19UUUxPcAryjGq/1KLAzsGsnL5CWm4iIGIsbJB2qAcVSJH2FshRDE8w3YHuLtudL9DKQJqmKeO4DXAbcC5zT6dXk03ITERFjsS9lQPH0aukMA+sA04A96wysg56X9M5WqYLW0iGSVqYsPRFjZPti4OJunV8za2hFRESMjqQVgFUp3VT32P5tzSF1TFVo7j+BIyhJG5TZYQcD+9u+pK7YYnhJbiIiYkwkzQVsDaxc7boXuLTqdmgESatTChWuVu26GzjK9t31RRUjSXITERGjJukfgKuAx4HbKC03awNvAzaz3dHZLxGjkeQmIiJGTdIpwO22vz1g/37AurZ3ryWwDpL0Q4auv2LbTRlb1DhJbiIiYtQk/dr2ykMcu8/2Sr2OqdMkfXiQ3ZOAA4A5bU/scUgxizJbKiIixuLlYY691LMousj2ea3nkpanDCTeBDiSMlMsZlNJbiIiYiwWkbTjIPsFLNzrYLpF0irAIZTxREcBn27SgOmmSrdURESMWjUeZUi2P9GrWLpF0rnAesDRwDnAjPbjrbo3MftJchMREV0jaXfbp9Ydx1hIepCZA4rN65ecsO3lex5UzJIkNxER0TWSptlep+44YnzJmJuIiOimvl1gU9KwSZntacMdj/okuYmIiG7q5+6BY4Y5ZmDzXgUSo5PkJiIiuqlvW26ALW2/MtgBScv1OpiYdXPUHUBERDTaDXUH8Cb8TNI8A3dKWoOy9ETMptJyExERoyZpIjDZ9vXV9ueABavDZ9ieDmB7n5pC7ISpwCWStrP9EoCkTYHTgb6f6t5kabmJiIixOApYtG17b+BFyliUr9YSUYfZ/jJwJXCZpAWr5RhOAz5o++f1RhfDSctNRESMxUq2L2zbfsn2MQCSrqsppo6zfYSklymtOAI2b7VKxewryU1ERIzFfAO2t2h7vkQvA+kWSRcws3jfUsB04FtSGSNte/v6oovhJLmJiIixeF7SO23/BmYuRSBpZeCFWiPrnKOHeB6zuSQ3ERExFocBF0o6AmgVs1uXsnL2/rVF1UG2rxnqmKSzgSGPR72y/EJERIyJpNWBLwKrVbvuBo6yfXd9UfWGpIdtT6o7jhhckpuIiIhRSnIze0u3VEREjJqkHzL00gq2vWcv4+mGYdaWEjB3L2OJ0UlyExERY3HhIPsmAQcAc/Y4lm4Zbm2pX/csihi1dEtFRMSbIml5ykDiTYBjgZOGWpOpKSTNbftvdccRg0uF4oiIGBNJq0g6HbgAuB5Y1fYJTU1sVGwu6QfAI3XHE0NLchMREaMm6VzgYuAmYFPgfGBhSYtLWrzO2DpN0rslHQc8RLnP64CV640qhpNuqYiIGDVJDzJzQHGrim+LbS/f86A6rKrh81HgYeBM4KfArbaXqzWwGFGSm4iIiEFI+hNwH/Bt4ELbf5H0uyYkbk2X2VIRETFqw0yTBsD2tOGO94m3Ae8HdgG+LekqYIKkuWz/vd7QYjhJbiIiYiyGmyZtYPNeBdJF+wI3AJ+kfF5uC8wPPCrpCtu71hlcDC3JTUREjMWWQ82KktSUMSkTgeMog4fvBG4ETqbU8tmsxrhiBBlzExERoybpEmCHgQmOpDWA821PriWwLpA0D7AesCGwQfV4zvYqtQYWQ8pU8IiIGIupwCWS5m/tkLQpZXr4p+oKqksmAAsDi1SPx4AptUYUw0rLTUREjImkQ4CtgK2BLSnViXe0fWutgXWIpBMpK54/D9xMSWim2H6m1sBiRBlzExERY2L7CEkvU1pxBGxue3rNYXXSJGBe4H7gUUpV4mdrjShmSVpuIiJi1CRdwMzifRsB04E/tI7b3r6m0DpKkiitNxtWj9WBp4GbbB9WZ2wxtCQ3ERExapLeN9xx29f0KpZekDSRksRtSJkSvoTtReuNKoaS5CYiIjpK0tm2d6o7jjdL0n6UZGYj4G+Umjc3VX/eZfvVGsOLYWTMTUREdNoGdQfQIZOBHwMH2n685lhiFNJyExERHSXpYduT6o4jxq+03ERExKgNs7aUgLl7GUvEQGm5iYiIUasWkRyS7SxPELVJchMRER0laW7bf6s7jhi/svxCRES8aSo2l/QDSrG7iNokuYmIiDGT9G5JxwEPAecD11FW0Y6oTbqlIiJi1CQdAXwUeBg4E/gpcKvt5WoNLILMloqIiLHZC7gPOAG40PZfJOXbcswW0i0VERFj8TbgCGB7YLqkHwETJOVLc9QuyU1ERIzFvsCTwCeBFYGfATcCj0o6o87AIpLcRETEWEwEjgOeAC4F1gFOBtartiNqkwHFERExZpLmoSQ0G1LWlNoAeM72KrUGFuNa+kYjIuLNmAAsDCxSPR4D7qo1ohj30nITERGjJulEYDXgeeBmYAowxfYztQYWQcbcRETE2EwC5gX+ADxKqUr8bK0RRVTSchMREWMiSZTWmw2rx+rA08BNtg+rM7YY35LcRETEmyJpIrARJcHZFljC9qL1RhXjWZKbiIgYNUn7UZKZjYC/ATcAN1V/3mX71RrDi3Eus6UiImIsJgM/Bg60/XjNsUS8TlpuIiIiolEyWyoiIiIaJclNRERENEqSm4joOkkzJN0u6W5J50qa/02c6xRJH6me/0DSqsO8dlNJG47hGg9KWnJW9w94zQujvNbhkg4abYwRMbQkNxHRCy/bXsv26sArwKfbD0qacywntf0vtn81zEs2pczoiYhxJMlNRPTadcCKVavKVZLOAO6SNKekoyTdIulOSXtDKRQn6XhJv5J0EfCW1okkXS1pver5VpKmSbpD0hWSJlOSqAOrVqP3SlpK0nnVNW6RtFH13iUkXS7pNknfAzTSTUj6X0lTJd0jaa8Bx46pYrlC0lLVvhUkXVq95zpJK3fihxkRb5Sp4BHRM5LmArYGLq12vQtY3fYDVYLwnO31Jc0L3CDpcmBtYCXgH4G3Ar8CTh5w3qWA7wObVOda3PbTkv4beMH20dXrzgCOtX29pEnAZcAqwGHA9ba/JukDwOuSlSF8srrGBOAWSefZfgpYAJhm+/OSDq3OvQ9wIvBp2/dLejfwX8DmY/gxRsQIktxERC9MkHR79fw64CRKd9EvbT9Q7X8/sEZrPA1lhel3AJsAZ9qeATwm6cpBzv8e4NrWuWw/PUQc/wSsWlYNAGBhSQtV19ixeu9FkmZl8cf9JH2oer5sFetTwKvA2dX+04GfSFqwut9z26497yxcIyLGIMlNRPTCy7bXat9Rfci/2L4L2Nf2ZQNetw0wUkEuzcJroHTFb2D75UFimeWiX5I2pSRKG9h+SdLVwHxDvNzVdZ8d+DOIiO7ImJuImF1cBnxG0twAkt4paQHgWmDnakzO0sBmg7z3JuB9kpar3rt4tf95YKG2111O6SKiel0r2bgW+Fi1b2tgsRFiXQR4pkpsVqa0HLXMAbRan3aldHf9GXhA0j9X15CkNUe4RkSMUZKbiJhd/IAynmaapLuB71Fal38K3A/cBZwAXDPwjbb/RBkn8xNJdzCzW+gC4EOtAcXAfsB61YDlXzFz1tZXgU0kTaN0jz08QqyXAnNJuhP4D2BK27EXgdUkTaWMqflatf9jwJ6ias42AAAAU0lEQVRVfPcAO8zCzyQixiDLL0RERESjpOUmIiIiGiXJTURERDRKkpuIiIholCQ3ERER0ShJbiIiIqJRktxEREREoyS5iYiIiEZJchMRERGN8v8B0e0CG65UHSoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(log_reg_grid_results['confusion_matrix'], classes=labels, cmap=plt.cm.Greens, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tLogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 10, 'penalty': 'l2'}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 3\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9449129488574538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# observe the attributes of the model \n",
    "print_grid_search_attributes(log_reg_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear SVC with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   41.1s finished\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:00:52.454592\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:00.013981\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.9647098744485918\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[537   0   0   0   0   0]\n",
      " [  2 422  62   0   0   5]\n",
      " [  0  11 520   1   0   0]\n",
      " [  0   0   0 496   0   0]\n",
      " [  0   0   0   2 413   5]\n",
      " [  0   0   0  15   1 455]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.97      0.86      0.91       491\n",
      "          STANDING       0.89      0.98      0.93       532\n",
      "           WALKING       0.96      1.00      0.98       496\n",
      "WALKING_DOWNSTAIRS       1.00      0.98      0.99       420\n",
      "  WALKING_UPSTAIRS       0.98      0.97      0.97       471\n",
      "\n",
      "          accuracy                           0.96      2947\n",
      "         macro avg       0.97      0.96      0.96      2947\n",
      "      weighted avg       0.97      0.96      0.96      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.125, 0.5, 1, 2, 8, 16]}\n",
    "lr_svc = LinearSVC(tol=0.00005)\n",
    "lr_svc_grid = GridSearchCV(lr_svc, param_grid=parameters, n_jobs=-1, verbose=1)\n",
    "lr_svc_grid_results = perform_model(lr_svc_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tLinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=5e-05,\n",
      "          verbose=0)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 2}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 3\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9460010881392819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_attributes(lr_svc_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kernel SVM with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done \n",
      " \n",
      "\n",
      "training_time(HH:MM:SS.ms) - 0:04:38.882727\n",
      "\n",
      "\n",
      "Predicting test data\n",
      "Done \n",
      " \n",
      "\n",
      "testing time(HH:MM:SS:ms) - 0:00:06.041544\n",
      "\n",
      "\n",
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "\n",
      "    0.9626739056667798\n",
      "\n",
      "\n",
      "--------------------\n",
      "| Confusion Matrix |\n",
      "--------------------\n",
      "\n",
      " [[537   0   0   0   0   0]\n",
      " [  0 441  48   0   0   2]\n",
      " [  0  12 520   0   0   0]\n",
      " [  0   0   0 489   2   5]\n",
      " [  0   0   0   4 397  19]\n",
      " [  0   0   0  17   1 453]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "| Classifiction Report |\n",
      "-------------------------\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "           SITTING       0.97      0.90      0.93       491\n",
      "          STANDING       0.92      0.98      0.95       532\n",
      "           WALKING       0.96      0.99      0.97       496\n",
      "WALKING_DOWNSTAIRS       0.99      0.95      0.97       420\n",
      "  WALKING_UPSTAIRS       0.95      0.96      0.95       471\n",
      "\n",
      "          accuracy                           0.96      2947\n",
      "         macro avg       0.96      0.96      0.96      2947\n",
      "      weighted avg       0.96      0.96      0.96      2947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {'C':[2,8,16],\\\n",
    "              'gamma': [ 0.0078125, 0.125, 2]}\n",
    "rbf_svm = SVC(kernel='rbf')\n",
    "rbf_svm_grid = GridSearchCV(rbf_svm,param_grid=parameters, n_jobs=-1)\n",
    "rbf_svm_grid_results = perform_model(rbf_svm_grid, X_train, y_train, X_test, y_test, class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tSVC(C=16, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.0078125, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 16, 'gamma': 0.0078125}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal numbre of cross validation sets: 3\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.9440968443960827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_attributes(rbf_svm_grid_results['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done with running Models all are same as functions are made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now run simple deep learning moels like mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils \n",
    "from keras.datasets import mnist \n",
    "import seaborn as sns\n",
    "from keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 564) (2947, 564)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape, test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAccmeanX</th>\n",
       "      <th>tBodyAccmeanY</th>\n",
       "      <th>tBodyAccmeanZ</th>\n",
       "      <th>tBodyAccstdX</th>\n",
       "      <th>tBodyAccstdY</th>\n",
       "      <th>tBodyAccstdZ</th>\n",
       "      <th>tBodyAccmadX</th>\n",
       "      <th>tBodyAccmadY</th>\n",
       "      <th>tBodyAccmadZ</th>\n",
       "      <th>tBodyAccmaxX</th>\n",
       "      <th>...</th>\n",
       "      <th>angletBodyAccMeangravity</th>\n",
       "      <th>angletBodyAccJerkMeangravityMean</th>\n",
       "      <th>angletBodyGyroMeangravityMean</th>\n",
       "      <th>angletBodyGyroJerkMeangravityMean</th>\n",
       "      <th>angleXgravityMean</th>\n",
       "      <th>angleYgravityMean</th>\n",
       "      <th>angleZgravityMean</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277199</td>\n",
       "      <td>-0.010098</td>\n",
       "      <td>-0.105137</td>\n",
       "      <td>-0.997335</td>\n",
       "      <td>-0.990487</td>\n",
       "      <td>-0.995420</td>\n",
       "      <td>-0.997627</td>\n",
       "      <td>-0.990218</td>\n",
       "      <td>-0.995549</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>-0.143439</td>\n",
       "      <td>0.275041</td>\n",
       "      <td>-0.368224</td>\n",
       "      <td>-0.849632</td>\n",
       "      <td>0.184823</td>\n",
       "      <td>-0.042126</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.279454</td>\n",
       "      <td>-0.019641</td>\n",
       "      <td>-0.110022</td>\n",
       "      <td>-0.996921</td>\n",
       "      <td>-0.967186</td>\n",
       "      <td>-0.983118</td>\n",
       "      <td>-0.997003</td>\n",
       "      <td>-0.966097</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.940987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212754</td>\n",
       "      <td>-0.230622</td>\n",
       "      <td>0.014637</td>\n",
       "      <td>-0.189512</td>\n",
       "      <td>-0.852150</td>\n",
       "      <td>0.182170</td>\n",
       "      <td>-0.043010</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277432</td>\n",
       "      <td>-0.030488</td>\n",
       "      <td>-0.125360</td>\n",
       "      <td>-0.996559</td>\n",
       "      <td>-0.966728</td>\n",
       "      <td>-0.981585</td>\n",
       "      <td>-0.996485</td>\n",
       "      <td>-0.966313</td>\n",
       "      <td>-0.982982</td>\n",
       "      <td>-0.940987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.593996</td>\n",
       "      <td>-0.561871</td>\n",
       "      <td>0.467383</td>\n",
       "      <td>-0.851017</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>-0.041976</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.277293</td>\n",
       "      <td>-0.021751</td>\n",
       "      <td>-0.120751</td>\n",
       "      <td>-0.997328</td>\n",
       "      <td>-0.961245</td>\n",
       "      <td>-0.983672</td>\n",
       "      <td>-0.997596</td>\n",
       "      <td>-0.957236</td>\n",
       "      <td>-0.984379</td>\n",
       "      <td>-0.940598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.080936</td>\n",
       "      <td>-0.234313</td>\n",
       "      <td>0.117797</td>\n",
       "      <td>-0.847971</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>-0.037364</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.280586</td>\n",
       "      <td>-0.009960</td>\n",
       "      <td>-0.106065</td>\n",
       "      <td>-0.994803</td>\n",
       "      <td>-0.972758</td>\n",
       "      <td>-0.986244</td>\n",
       "      <td>-0.995405</td>\n",
       "      <td>-0.973663</td>\n",
       "      <td>-0.985642</td>\n",
       "      <td>-0.940028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020590</td>\n",
       "      <td>-0.127730</td>\n",
       "      <td>-0.482871</td>\n",
       "      <td>-0.070670</td>\n",
       "      <td>-0.848294</td>\n",
       "      <td>0.190310</td>\n",
       "      <td>-0.034417</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAccmeanX  tBodyAccmeanY  tBodyAccmeanZ  tBodyAccstdX  tBodyAccstdY  \\\n",
       "0       0.288585      -0.020294      -0.132905     -0.995279     -0.983111   \n",
       "1       0.278419      -0.016411      -0.123520     -0.998245     -0.975300   \n",
       "2       0.279653      -0.019467      -0.113462     -0.995380     -0.967187   \n",
       "3       0.279174      -0.026201      -0.123283     -0.996091     -0.983403   \n",
       "4       0.276629      -0.016570      -0.115362     -0.998139     -0.980817   \n",
       "5       0.277199      -0.010098      -0.105137     -0.997335     -0.990487   \n",
       "6       0.279454      -0.019641      -0.110022     -0.996921     -0.967186   \n",
       "7       0.277432      -0.030488      -0.125360     -0.996559     -0.966728   \n",
       "8       0.277293      -0.021751      -0.120751     -0.997328     -0.961245   \n",
       "9       0.280586      -0.009960      -0.106065     -0.994803     -0.972758   \n",
       "\n",
       "   tBodyAccstdZ  tBodyAccmadX  tBodyAccmadY  tBodyAccmadZ  tBodyAccmaxX  ...  \\\n",
       "0     -0.913526     -0.995112     -0.983185     -0.923527     -0.934724  ...   \n",
       "1     -0.960322     -0.998807     -0.974914     -0.957686     -0.943068  ...   \n",
       "2     -0.978944     -0.996520     -0.963668     -0.977469     -0.938692  ...   \n",
       "3     -0.990675     -0.997099     -0.982750     -0.989302     -0.938692  ...   \n",
       "4     -0.990482     -0.998321     -0.979672     -0.990441     -0.942469  ...   \n",
       "5     -0.995420     -0.997627     -0.990218     -0.995549     -0.942469  ...   \n",
       "6     -0.983118     -0.997003     -0.966097     -0.983116     -0.940987  ...   \n",
       "7     -0.981585     -0.996485     -0.966313     -0.982982     -0.940987  ...   \n",
       "8     -0.983672     -0.997596     -0.957236     -0.984379     -0.940598  ...   \n",
       "9     -0.986244     -0.995405     -0.973663     -0.985642     -0.940028  ...   \n",
       "\n",
       "   angletBodyAccMeangravity  angletBodyAccJerkMeangravityMean  \\\n",
       "0                 -0.112754                          0.030400   \n",
       "1                  0.053477                         -0.007435   \n",
       "2                 -0.118559                          0.177899   \n",
       "3                 -0.036788                         -0.012892   \n",
       "4                  0.123320                          0.122542   \n",
       "5                  0.082632                         -0.143439   \n",
       "6                 -0.212754                         -0.230622   \n",
       "7                 -0.020888                          0.593996   \n",
       "8                  0.012954                          0.080936   \n",
       "9                 -0.020590                         -0.127730   \n",
       "\n",
       "   angletBodyGyroMeangravityMean  angletBodyGyroJerkMeangravityMean  \\\n",
       "0                      -0.464761                          -0.018446   \n",
       "1                      -0.732626                           0.703511   \n",
       "2                       0.100699                           0.808529   \n",
       "3                       0.640011                          -0.485366   \n",
       "4                       0.693578                          -0.615971   \n",
       "5                       0.275041                          -0.368224   \n",
       "6                       0.014637                          -0.189512   \n",
       "7                      -0.561871                           0.467383   \n",
       "8                      -0.234313                           0.117797   \n",
       "9                      -0.482871                          -0.070670   \n",
       "\n",
       "   angleXgravityMean  angleYgravityMean  angleZgravityMean  subject  Activity  \\\n",
       "0          -0.841247           0.179941          -0.058627        1         5   \n",
       "1          -0.844788           0.180289          -0.054317        1         5   \n",
       "2          -0.848933           0.180637          -0.049118        1         5   \n",
       "3          -0.848649           0.181935          -0.047663        1         5   \n",
       "4          -0.847865           0.185151          -0.043892        1         5   \n",
       "5          -0.849632           0.184823          -0.042126        1         5   \n",
       "6          -0.852150           0.182170          -0.043010        1         5   \n",
       "7          -0.851017           0.183779          -0.041976        1         5   \n",
       "8          -0.847971           0.188982          -0.037364        1         5   \n",
       "9          -0.848294           0.190310          -0.034417        1         5   \n",
       "\n",
       "   ActivityName  \n",
       "0      STANDING  \n",
       "1      STANDING  \n",
       "2      STANDING  \n",
       "3      STANDING  \n",
       "4      STANDING  \n",
       "5      STANDING  \n",
       "6      STANDING  \n",
       "7      STANDING  \n",
       "8      STANDING  \n",
       "9      STANDING  \n",
       "\n",
       "[10 rows x 564 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAccmeanX</th>\n",
       "      <th>tBodyAccmeanY</th>\n",
       "      <th>tBodyAccmeanZ</th>\n",
       "      <th>tBodyAccstdX</th>\n",
       "      <th>tBodyAccstdY</th>\n",
       "      <th>tBodyAccstdZ</th>\n",
       "      <th>tBodyAccmadX</th>\n",
       "      <th>tBodyAccmadY</th>\n",
       "      <th>tBodyAccmadZ</th>\n",
       "      <th>tBodyAccmaxX</th>\n",
       "      <th>...</th>\n",
       "      <th>angletBodyAccMeangravity</th>\n",
       "      <th>angletBodyAccJerkMeangravityMean</th>\n",
       "      <th>angletBodyGyroMeangravityMean</th>\n",
       "      <th>angletBodyGyroJerkMeangravityMean</th>\n",
       "      <th>angleXgravityMean</th>\n",
       "      <th>angleYgravityMean</th>\n",
       "      <th>angleZgravityMean</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAccmeanX  tBodyAccmeanY  tBodyAccmeanZ  tBodyAccstdX  tBodyAccstdY  \\\n",
       "0       0.257178      -0.023285      -0.014654     -0.938404     -0.920091   \n",
       "1       0.286027      -0.013163      -0.119083     -0.975415     -0.967458   \n",
       "2       0.275485      -0.026050      -0.118152     -0.993819     -0.969926   \n",
       "\n",
       "   tBodyAccstdZ  tBodyAccmadX  tBodyAccmadY  tBodyAccmadZ  tBodyAccmaxX  ...  \\\n",
       "0     -0.667683     -0.952501     -0.925249     -0.674302     -0.894088  ...   \n",
       "1     -0.944958     -0.986799     -0.968401     -0.945823     -0.894088  ...   \n",
       "2     -0.962748     -0.994403     -0.970735     -0.963483     -0.939260  ...   \n",
       "\n",
       "   angletBodyAccMeangravity  angletBodyAccJerkMeangravityMean  \\\n",
       "0                  0.006462                          0.162920   \n",
       "1                 -0.083495                          0.017500   \n",
       "2                 -0.034956                          0.202302   \n",
       "\n",
       "   angletBodyGyroMeangravityMean  angletBodyGyroJerkMeangravityMean  \\\n",
       "0                      -0.825886                           0.271151   \n",
       "1                      -0.434375                           0.920593   \n",
       "2                       0.064103                           0.145068   \n",
       "\n",
       "   angleXgravityMean  angleYgravityMean  angleZgravityMean  subject  Activity  \\\n",
       "0          -0.720009           0.276801          -0.057978        2         5   \n",
       "1          -0.698091           0.281343          -0.083898        2         5   \n",
       "2          -0.702771           0.280083          -0.079346        2         5   \n",
       "\n",
       "   ActivityName  \n",
       "0      STANDING  \n",
       "1      STANDING  \n",
       "2      STANDING  \n",
       "\n",
       "[3 rows x 564 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Activity']=train.Activity-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAccmeanX</th>\n",
       "      <th>tBodyAccmeanY</th>\n",
       "      <th>tBodyAccmeanZ</th>\n",
       "      <th>tBodyAccstdX</th>\n",
       "      <th>tBodyAccstdY</th>\n",
       "      <th>tBodyAccstdZ</th>\n",
       "      <th>tBodyAccmadX</th>\n",
       "      <th>tBodyAccmadY</th>\n",
       "      <th>tBodyAccmadZ</th>\n",
       "      <th>tBodyAccmaxX</th>\n",
       "      <th>...</th>\n",
       "      <th>angletBodyAccMeangravity</th>\n",
       "      <th>angletBodyAccJerkMeangravityMean</th>\n",
       "      <th>angletBodyGyroMeangravityMean</th>\n",
       "      <th>angletBodyGyroJerkMeangravityMean</th>\n",
       "      <th>angleXgravityMean</th>\n",
       "      <th>angleYgravityMean</th>\n",
       "      <th>angleZgravityMean</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277199</td>\n",
       "      <td>-0.010098</td>\n",
       "      <td>-0.105137</td>\n",
       "      <td>-0.997335</td>\n",
       "      <td>-0.990487</td>\n",
       "      <td>-0.995420</td>\n",
       "      <td>-0.997627</td>\n",
       "      <td>-0.990218</td>\n",
       "      <td>-0.995549</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>-0.143439</td>\n",
       "      <td>0.275041</td>\n",
       "      <td>-0.368224</td>\n",
       "      <td>-0.849632</td>\n",
       "      <td>0.184823</td>\n",
       "      <td>-0.042126</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.279454</td>\n",
       "      <td>-0.019641</td>\n",
       "      <td>-0.110022</td>\n",
       "      <td>-0.996921</td>\n",
       "      <td>-0.967186</td>\n",
       "      <td>-0.983118</td>\n",
       "      <td>-0.997003</td>\n",
       "      <td>-0.966097</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>-0.940987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212754</td>\n",
       "      <td>-0.230622</td>\n",
       "      <td>0.014637</td>\n",
       "      <td>-0.189512</td>\n",
       "      <td>-0.852150</td>\n",
       "      <td>0.182170</td>\n",
       "      <td>-0.043010</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277432</td>\n",
       "      <td>-0.030488</td>\n",
       "      <td>-0.125360</td>\n",
       "      <td>-0.996559</td>\n",
       "      <td>-0.966728</td>\n",
       "      <td>-0.981585</td>\n",
       "      <td>-0.996485</td>\n",
       "      <td>-0.966313</td>\n",
       "      <td>-0.982982</td>\n",
       "      <td>-0.940987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.593996</td>\n",
       "      <td>-0.561871</td>\n",
       "      <td>0.467383</td>\n",
       "      <td>-0.851017</td>\n",
       "      <td>0.183779</td>\n",
       "      <td>-0.041976</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.277293</td>\n",
       "      <td>-0.021751</td>\n",
       "      <td>-0.120751</td>\n",
       "      <td>-0.997328</td>\n",
       "      <td>-0.961245</td>\n",
       "      <td>-0.983672</td>\n",
       "      <td>-0.997596</td>\n",
       "      <td>-0.957236</td>\n",
       "      <td>-0.984379</td>\n",
       "      <td>-0.940598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.080936</td>\n",
       "      <td>-0.234313</td>\n",
       "      <td>0.117797</td>\n",
       "      <td>-0.847971</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>-0.037364</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.280586</td>\n",
       "      <td>-0.009960</td>\n",
       "      <td>-0.106065</td>\n",
       "      <td>-0.994803</td>\n",
       "      <td>-0.972758</td>\n",
       "      <td>-0.986244</td>\n",
       "      <td>-0.995405</td>\n",
       "      <td>-0.973663</td>\n",
       "      <td>-0.985642</td>\n",
       "      <td>-0.940028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020590</td>\n",
       "      <td>-0.127730</td>\n",
       "      <td>-0.482871</td>\n",
       "      <td>-0.070670</td>\n",
       "      <td>-0.848294</td>\n",
       "      <td>0.190310</td>\n",
       "      <td>-0.034417</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAccmeanX  tBodyAccmeanY  tBodyAccmeanZ  tBodyAccstdX  tBodyAccstdY  \\\n",
       "0       0.288585      -0.020294      -0.132905     -0.995279     -0.983111   \n",
       "1       0.278419      -0.016411      -0.123520     -0.998245     -0.975300   \n",
       "2       0.279653      -0.019467      -0.113462     -0.995380     -0.967187   \n",
       "3       0.279174      -0.026201      -0.123283     -0.996091     -0.983403   \n",
       "4       0.276629      -0.016570      -0.115362     -0.998139     -0.980817   \n",
       "5       0.277199      -0.010098      -0.105137     -0.997335     -0.990487   \n",
       "6       0.279454      -0.019641      -0.110022     -0.996921     -0.967186   \n",
       "7       0.277432      -0.030488      -0.125360     -0.996559     -0.966728   \n",
       "8       0.277293      -0.021751      -0.120751     -0.997328     -0.961245   \n",
       "9       0.280586      -0.009960      -0.106065     -0.994803     -0.972758   \n",
       "\n",
       "   tBodyAccstdZ  tBodyAccmadX  tBodyAccmadY  tBodyAccmadZ  tBodyAccmaxX  ...  \\\n",
       "0     -0.913526     -0.995112     -0.983185     -0.923527     -0.934724  ...   \n",
       "1     -0.960322     -0.998807     -0.974914     -0.957686     -0.943068  ...   \n",
       "2     -0.978944     -0.996520     -0.963668     -0.977469     -0.938692  ...   \n",
       "3     -0.990675     -0.997099     -0.982750     -0.989302     -0.938692  ...   \n",
       "4     -0.990482     -0.998321     -0.979672     -0.990441     -0.942469  ...   \n",
       "5     -0.995420     -0.997627     -0.990218     -0.995549     -0.942469  ...   \n",
       "6     -0.983118     -0.997003     -0.966097     -0.983116     -0.940987  ...   \n",
       "7     -0.981585     -0.996485     -0.966313     -0.982982     -0.940987  ...   \n",
       "8     -0.983672     -0.997596     -0.957236     -0.984379     -0.940598  ...   \n",
       "9     -0.986244     -0.995405     -0.973663     -0.985642     -0.940028  ...   \n",
       "\n",
       "   angletBodyAccMeangravity  angletBodyAccJerkMeangravityMean  \\\n",
       "0                 -0.112754                          0.030400   \n",
       "1                  0.053477                         -0.007435   \n",
       "2                 -0.118559                          0.177899   \n",
       "3                 -0.036788                         -0.012892   \n",
       "4                  0.123320                          0.122542   \n",
       "5                  0.082632                         -0.143439   \n",
       "6                 -0.212754                         -0.230622   \n",
       "7                 -0.020888                          0.593996   \n",
       "8                  0.012954                          0.080936   \n",
       "9                 -0.020590                         -0.127730   \n",
       "\n",
       "   angletBodyGyroMeangravityMean  angletBodyGyroJerkMeangravityMean  \\\n",
       "0                      -0.464761                          -0.018446   \n",
       "1                      -0.732626                           0.703511   \n",
       "2                       0.100699                           0.808529   \n",
       "3                       0.640011                          -0.485366   \n",
       "4                       0.693578                          -0.615971   \n",
       "5                       0.275041                          -0.368224   \n",
       "6                       0.014637                          -0.189512   \n",
       "7                      -0.561871                           0.467383   \n",
       "8                      -0.234313                           0.117797   \n",
       "9                      -0.482871                          -0.070670   \n",
       "\n",
       "   angleXgravityMean  angleYgravityMean  angleZgravityMean  subject  Activity  \\\n",
       "0          -0.841247           0.179941          -0.058627        1         4   \n",
       "1          -0.844788           0.180289          -0.054317        1         4   \n",
       "2          -0.848933           0.180637          -0.049118        1         4   \n",
       "3          -0.848649           0.181935          -0.047663        1         4   \n",
       "4          -0.847865           0.185151          -0.043892        1         4   \n",
       "5          -0.849632           0.184823          -0.042126        1         4   \n",
       "6          -0.852150           0.182170          -0.043010        1         4   \n",
       "7          -0.851017           0.183779          -0.041976        1         4   \n",
       "8          -0.847971           0.188982          -0.037364        1         4   \n",
       "9          -0.848294           0.190310          -0.034417        1         4   \n",
       "\n",
       "   ActivityName  \n",
       "0      STANDING  \n",
       "1      STANDING  \n",
       "2      STANDING  \n",
       "3      STANDING  \n",
       "4      STANDING  \n",
       "5      STANDING  \n",
       "6      STANDING  \n",
       "7      STANDING  \n",
       "8      STANDING  \n",
       "9      STANDING  \n",
       "\n",
       "[10 rows x 564 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAccmeanX</th>\n",
       "      <th>tBodyAccmeanY</th>\n",
       "      <th>tBodyAccmeanZ</th>\n",
       "      <th>tBodyAccstdX</th>\n",
       "      <th>tBodyAccstdY</th>\n",
       "      <th>tBodyAccstdZ</th>\n",
       "      <th>tBodyAccmadX</th>\n",
       "      <th>tBodyAccmadY</th>\n",
       "      <th>tBodyAccmadZ</th>\n",
       "      <th>tBodyAccmaxX</th>\n",
       "      <th>...</th>\n",
       "      <th>angletBodyAccMeangravity</th>\n",
       "      <th>angletBodyAccJerkMeangravityMean</th>\n",
       "      <th>angletBodyGyroMeangravityMean</th>\n",
       "      <th>angletBodyGyroJerkMeangravityMean</th>\n",
       "      <th>angleXgravityMean</th>\n",
       "      <th>angleYgravityMean</th>\n",
       "      <th>angleZgravityMean</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>ActivityName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257178</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.014654</td>\n",
       "      <td>-0.938404</td>\n",
       "      <td>-0.920091</td>\n",
       "      <td>-0.667683</td>\n",
       "      <td>-0.952501</td>\n",
       "      <td>-0.925249</td>\n",
       "      <td>-0.674302</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.162920</td>\n",
       "      <td>-0.825886</td>\n",
       "      <td>0.271151</td>\n",
       "      <td>-0.720009</td>\n",
       "      <td>0.276801</td>\n",
       "      <td>-0.057978</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286027</td>\n",
       "      <td>-0.013163</td>\n",
       "      <td>-0.119083</td>\n",
       "      <td>-0.975415</td>\n",
       "      <td>-0.967458</td>\n",
       "      <td>-0.944958</td>\n",
       "      <td>-0.986799</td>\n",
       "      <td>-0.968401</td>\n",
       "      <td>-0.945823</td>\n",
       "      <td>-0.894088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083495</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>-0.434375</td>\n",
       "      <td>0.920593</td>\n",
       "      <td>-0.698091</td>\n",
       "      <td>0.281343</td>\n",
       "      <td>-0.083898</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.275485</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>-0.118152</td>\n",
       "      <td>-0.993819</td>\n",
       "      <td>-0.969926</td>\n",
       "      <td>-0.962748</td>\n",
       "      <td>-0.994403</td>\n",
       "      <td>-0.970735</td>\n",
       "      <td>-0.963483</td>\n",
       "      <td>-0.939260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034956</td>\n",
       "      <td>0.202302</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>-0.702771</td>\n",
       "      <td>0.280083</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAccmeanX  tBodyAccmeanY  tBodyAccmeanZ  tBodyAccstdX  tBodyAccstdY  \\\n",
       "0       0.257178      -0.023285      -0.014654     -0.938404     -0.920091   \n",
       "1       0.286027      -0.013163      -0.119083     -0.975415     -0.967458   \n",
       "2       0.275485      -0.026050      -0.118152     -0.993819     -0.969926   \n",
       "\n",
       "   tBodyAccstdZ  tBodyAccmadX  tBodyAccmadY  tBodyAccmadZ  tBodyAccmaxX  ...  \\\n",
       "0     -0.667683     -0.952501     -0.925249     -0.674302     -0.894088  ...   \n",
       "1     -0.944958     -0.986799     -0.968401     -0.945823     -0.894088  ...   \n",
       "2     -0.962748     -0.994403     -0.970735     -0.963483     -0.939260  ...   \n",
       "\n",
       "   angletBodyAccMeangravity  angletBodyAccJerkMeangravityMean  \\\n",
       "0                  0.006462                          0.162920   \n",
       "1                 -0.083495                          0.017500   \n",
       "2                 -0.034956                          0.202302   \n",
       "\n",
       "   angletBodyGyroMeangravityMean  angletBodyGyroJerkMeangravityMean  \\\n",
       "0                      -0.825886                           0.271151   \n",
       "1                      -0.434375                           0.920593   \n",
       "2                       0.064103                           0.145068   \n",
       "\n",
       "   angleXgravityMean  angleYgravityMean  angleZgravityMean  subject  Activity  \\\n",
       "0          -0.720009           0.276801          -0.057978        2         4   \n",
       "1          -0.698091           0.281343          -0.083898        2         4   \n",
       "2          -0.702771           0.280083          -0.079346        2         4   \n",
       "\n",
       "   ActivityName  \n",
       "0      STANDING  \n",
       "1      STANDING  \n",
       "2      STANDING  \n",
       "\n",
       "[3 rows x 564 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Activity']=test.Activity-1\n",
    "\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_train and y_train from csv files\n",
    "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_train = train.Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X_test and y_test from test csv file\n",
    "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_test = test.Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and y_train : ((7352, 561),(7352,))\n",
      "X_test  and y_test  : ((2947, 561),(2947,))\n"
     ]
    }
   ],
   "source": [
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.to_numpy()\n",
    "\n",
    "y_train=y_train.to_numpy()\n",
    "\n",
    "X_test=X_test.to_numpy()\n",
    "\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and y_train : ((7352, 561),(7352,))\n",
      "X_test  and y_test  : ((2947, 561),(2947,))\n"
     ]
    }
   ],
   "source": [
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train,6) \n",
    "Y_test = np_utils.to_categorical(y_test, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 6\n",
    "input_dim =561\n",
    "batch_size = 128 \n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      " - 1s - loss: 1.2772 - accuracy: 0.5613 - val_loss: 1.0235 - val_accuracy: 0.7133\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.8819 - accuracy: 0.7523 - val_loss: 0.8222 - val_accuracy: 0.7716\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.7286 - accuracy: 0.8033 - val_loss: 0.7110 - val_accuracy: 0.8527\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6396 - accuracy: 0.8375 - val_loss: 0.6377 - val_accuracy: 0.8473\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.5761 - accuracy: 0.8596 - val_loss: 0.5884 - val_accuracy: 0.8402\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5298 - accuracy: 0.8723 - val_loss: 0.5451 - val_accuracy: 0.8792\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4944 - accuracy: 0.8798 - val_loss: 0.5129 - val_accuracy: 0.8823\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.4641 - accuracy: 0.8886 - val_loss: 0.4931 - val_accuracy: 0.8850\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.4411 - accuracy: 0.8913 - val_loss: 0.4667 - val_accuracy: 0.8979\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.4208 - accuracy: 0.8936 - val_loss: 0.4476 - val_accuracy: 0.8975\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.4037 - accuracy: 0.8973 - val_loss: 0.4452 - val_accuracy: 0.8629\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.3889 - accuracy: 0.8992 - val_loss: 0.4191 - val_accuracy: 0.8931\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.3754 - accuracy: 0.9011 - val_loss: 0.4064 - val_accuracy: 0.9013\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.3640 - accuracy: 0.9018 - val_loss: 0.3963 - val_accuracy: 0.9026\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.3540 - accuracy: 0.9030 - val_loss: 0.3869 - val_accuracy: 0.9016\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.3437 - accuracy: 0.9049 - val_loss: 0.3786 - val_accuracy: 0.9050\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.3350 - accuracy: 0.9063 - val_loss: 0.3649 - val_accuracy: 0.9101\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.3272 - accuracy: 0.9095 - val_loss: 0.3603 - val_accuracy: 0.9046\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.3201 - accuracy: 0.9098 - val_loss: 0.3562 - val_accuracy: 0.8975\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.3127 - accuracy: 0.9124 - val_loss: 0.3504 - val_accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=2, validation_data=(X_test, Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3504004019739509\n",
      "Test accuracy: 0.898201584815979\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 1.3510 - accuracy: 0.4706 - val_loss: 1.0861 - val_accuracy: 0.5976\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.9049 - accuracy: 0.7246 - val_loss: 0.8715 - val_accuracy: 0.7011\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.7432 - accuracy: 0.7994 - val_loss: 0.7404 - val_accuracy: 0.8252\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.6467 - accuracy: 0.8432 - val_loss: 0.6661 - val_accuracy: 0.8235\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.5815 - accuracy: 0.8618 - val_loss: 0.6377 - val_accuracy: 0.8001\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.5343 - accuracy: 0.8732 - val_loss: 0.5622 - val_accuracy: 0.8721\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.4955 - accuracy: 0.8840 - val_loss: 0.5335 - val_accuracy: 0.8575\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.4667 - accuracy: 0.8866 - val_loss: 0.5040 - val_accuracy: 0.8714\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.4418 - accuracy: 0.8904 - val_loss: 0.4859 - val_accuracy: 0.8812\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.4213 - accuracy: 0.8949 - val_loss: 0.4619 - val_accuracy: 0.8782\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.4045 - accuracy: 0.8931 - val_loss: 0.4470 - val_accuracy: 0.8792\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.3884 - accuracy: 0.8998 - val_loss: 0.4367 - val_accuracy: 0.8690\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.3754 - accuracy: 0.8999 - val_loss: 0.4200 - val_accuracy: 0.8823\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.3632 - accuracy: 0.9022 - val_loss: 0.4072 - val_accuracy: 0.9030\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.3529 - accuracy: 0.9025 - val_loss: 0.3926 - val_accuracy: 0.9023\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.3433 - accuracy: 0.9057 - val_loss: 0.3964 - val_accuracy: 0.8761\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3344 - accuracy: 0.9072 - val_loss: 0.3782 - val_accuracy: 0.8962\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3269 - accuracy: 0.9101 - val_loss: 0.3669 - val_accuracy: 0.8982\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3194 - accuracy: 0.9095 - val_loss: 0.3647 - val_accuracy: 0.9108\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3122 - accuracy: 0.9123 - val_loss: 0.3522 - val_accuracy: 0.9033\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.3059 - accuracy: 0.9124 - val_loss: 0.3495 - val_accuracy: 0.9036\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2995 - accuracy: 0.9169 - val_loss: 0.3507 - val_accuracy: 0.8904\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2943 - accuracy: 0.9146 - val_loss: 0.3357 - val_accuracy: 0.9094\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.91 - 0s 40us/step - loss: 0.2893 - accuracy: 0.9169 - val_loss: 0.3309 - val_accuracy: 0.9097\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2839 - accuracy: 0.9178 - val_loss: 0.3284 - val_accuracy: 0.9057\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2793 - accuracy: 0.9193 - val_loss: 0.3172 - val_accuracy: 0.9169\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2754 - accuracy: 0.9195 - val_loss: 0.3177 - val_accuracy: 0.9169\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2706 - accuracy: 0.9219 - val_loss: 0.3125 - val_accuracy: 0.9091\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2673 - accuracy: 0.9229 - val_loss: 0.3094 - val_accuracy: 0.9097\n",
      "Epoch 30/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2632 - accuracy: 0.9225 - val_loss: 0.3056 - val_accuracy: 0.9189\n",
      "Epoch 31/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2597 - accuracy: 0.9248 - val_loss: 0.3020 - val_accuracy: 0.9186\n",
      "Epoch 32/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2561 - accuracy: 0.9259 - val_loss: 0.2969 - val_accuracy: 0.9213\n",
      "Epoch 33/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2527 - accuracy: 0.9272 - val_loss: 0.3008 - val_accuracy: 0.9077\n",
      "Epoch 34/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2493 - accuracy: 0.9266 - val_loss: 0.2907 - val_accuracy: 0.9189\n",
      "Epoch 35/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2462 - accuracy: 0.9267 - val_loss: 0.2851 - val_accuracy: 0.9274\n",
      "Epoch 36/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2439 - accuracy: 0.9295 - val_loss: 0.2872 - val_accuracy: 0.9158\n",
      "Epoch 37/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2407 - accuracy: 0.9297 - val_loss: 0.2930 - val_accuracy: 0.9040\n",
      "Epoch 38/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2378 - accuracy: 0.9295 - val_loss: 0.2812 - val_accuracy: 0.9243\n",
      "Epoch 39/50\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.2355 - accuracy: 0.9308 - val_loss: 0.2767 - val_accuracy: 0.9230\n",
      "Epoch 40/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2327 - accuracy: 0.9324 - val_loss: 0.2834 - val_accuracy: 0.9104\n",
      "Epoch 41/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2302 - accuracy: 0.9328 - val_loss: 0.2771 - val_accuracy: 0.9135\n",
      "Epoch 42/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2275 - accuracy: 0.9346 - val_loss: 0.2753 - val_accuracy: 0.9284\n",
      "Epoch 43/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2257 - accuracy: 0.9334 - val_loss: 0.2696 - val_accuracy: 0.9233\n",
      "Epoch 44/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2233 - accuracy: 0.9351 - val_loss: 0.2677 - val_accuracy: 0.9209\n",
      "Epoch 45/50\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2210 - accuracy: 0.9357 - val_loss: 0.2647 - val_accuracy: 0.9250\n",
      "Epoch 46/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2192 - accuracy: 0.9372 - val_loss: 0.2637 - val_accuracy: 0.9264\n",
      "Epoch 47/50\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2168 - accuracy: 0.9387 - val_loss: 0.2639 - val_accuracy: 0.9264\n",
      "Epoch 48/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2147 - accuracy: 0.9387 - val_loss: 0.2588 - val_accuracy: 0.9284\n",
      "Epoch 49/50\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.2132 - accuracy: 0.9397 - val_loss: 0.2578 - val_accuracy: 0.9284\n",
      "Epoch 50/50\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2115 - accuracy: 0.9408 - val_loss: 0.2551 - val_accuracy: 0.9301\n",
      "Test score: 0.25510007187516803\n",
      "Test accuracy: 0.9300984144210815\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=50, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/100\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 1.2886 - accuracy: 0.5000 - val_loss: 1.0360 - val_accuracy: 0.6390\n",
      "Epoch 2/100\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.9032 - accuracy: 0.7176 - val_loss: 0.8392 - val_accuracy: 0.7577\n",
      "Epoch 3/100\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.7466 - accuracy: 0.7956 - val_loss: 0.7257 - val_accuracy: 0.8076\n",
      "Epoch 4/100\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.6512 - accuracy: 0.8377 - val_loss: 0.6448 - val_accuracy: 0.8256\n",
      "Epoch 5/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.5840 - accuracy: 0.8636 - val_loss: 0.5878 - val_accuracy: 0.8704\n",
      "Epoch 6/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.5353 - accuracy: 0.8736 - val_loss: 0.5588 - val_accuracy: 0.8174\n",
      "Epoch 7/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.4993 - accuracy: 0.8802 - val_loss: 0.5171 - val_accuracy: 0.8734\n",
      "Epoch 8/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.4671 - accuracy: 0.8879 - val_loss: 0.4963 - val_accuracy: 0.8558\n",
      "Epoch 9/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.4429 - accuracy: 0.8897 - val_loss: 0.4746 - val_accuracy: 0.8738\n",
      "Epoch 10/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.4236 - accuracy: 0.8906 - val_loss: 0.4521 - val_accuracy: 0.8850\n",
      "Epoch 11/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.4049 - accuracy: 0.8974 - val_loss: 0.4375 - val_accuracy: 0.8823\n",
      "Epoch 12/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3890 - accuracy: 0.8995 - val_loss: 0.4213 - val_accuracy: 0.8880\n",
      "Epoch 13/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3756 - accuracy: 0.8989 - val_loss: 0.4088 - val_accuracy: 0.8877\n",
      "Epoch 14/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3635 - accuracy: 0.8984 - val_loss: 0.3942 - val_accuracy: 0.8948\n",
      "Epoch 15/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3526 - accuracy: 0.9027 - val_loss: 0.3914 - val_accuracy: 0.8918\n",
      "Epoch 16/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3433 - accuracy: 0.9056 - val_loss: 0.3795 - val_accuracy: 0.8935\n",
      "Epoch 17/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3349 - accuracy: 0.9044 - val_loss: 0.3664 - val_accuracy: 0.9002\n",
      "Epoch 18/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3272 - accuracy: 0.9072 - val_loss: 0.3592 - val_accuracy: 0.9009\n",
      "Epoch 19/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3191 - accuracy: 0.9076 - val_loss: 0.3505 - val_accuracy: 0.9074\n",
      "Epoch 20/100\n",
      "7352/7352 [==============================] - 0s 56us/step - loss: 0.3124 - accuracy: 0.9115 - val_loss: 0.3474 - val_accuracy: 0.9013\n",
      "Epoch 21/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.3059 - accuracy: 0.9131 - val_loss: 0.3450 - val_accuracy: 0.8924\n",
      "Epoch 22/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2998 - accuracy: 0.9138 - val_loss: 0.3343 - val_accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2944 - accuracy: 0.9161 - val_loss: 0.3383 - val_accuracy: 0.8904\n",
      "Epoch 24/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2892 - accuracy: 0.9162 - val_loss: 0.3245 - val_accuracy: 0.9063\n",
      "Epoch 25/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2839 - accuracy: 0.9163 - val_loss: 0.3215 - val_accuracy: 0.9060\n",
      "Epoch 26/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.2795 - accuracy: 0.9191 - val_loss: 0.3206 - val_accuracy: 0.9006\n",
      "Epoch 27/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2754 - accuracy: 0.9188 - val_loss: 0.3175 - val_accuracy: 0.8996\n",
      "Epoch 28/100\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2712 - accuracy: 0.9203 - val_loss: 0.3083 - val_accuracy: 0.9125\n",
      "Epoch 29/100\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2671 - accuracy: 0.9207 - val_loss: 0.3097 - val_accuracy: 0.9016\n",
      "Epoch 30/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2634 - accuracy: 0.9218 - val_loss: 0.3072 - val_accuracy: 0.9026\n",
      "Epoch 31/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2597 - accuracy: 0.9226 - val_loss: 0.2999 - val_accuracy: 0.9053\n",
      "Epoch 32/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2560 - accuracy: 0.9252 - val_loss: 0.2971 - val_accuracy: 0.9094\n",
      "Epoch 33/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2530 - accuracy: 0.9246 - val_loss: 0.2960 - val_accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2494 - accuracy: 0.9253 - val_loss: 0.2950 - val_accuracy: 0.9070\n",
      "Epoch 35/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.2469 - accuracy: 0.9287 - val_loss: 0.2844 - val_accuracy: 0.9189\n",
      "Epoch 36/100\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.2436 - accuracy: 0.9283 - val_loss: 0.2812 - val_accuracy: 0.9192\n",
      "Epoch 37/100\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2405 - accuracy: 0.9317 - val_loss: 0.2781 - val_accuracy: 0.9237\n",
      "Epoch 38/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2380 - accuracy: 0.9301 - val_loss: 0.2811 - val_accuracy: 0.9118\n",
      "Epoch 39/100\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2355 - accuracy: 0.9314 - val_loss: 0.2769 - val_accuracy: 0.9213\n",
      "Epoch 40/100\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2330 - accuracy: 0.9323 - val_loss: 0.2714 - val_accuracy: 0.9213\n",
      "Epoch 41/100\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2310 - accuracy: 0.9328 - val_loss: 0.2702 - val_accuracy: 0.9240\n",
      "Epoch 42/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.2278 - accuracy: 0.9346 - val_loss: 0.2675 - val_accuracy: 0.9226\n",
      "Epoch 43/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2254 - accuracy: 0.9361 - val_loss: 0.2663 - val_accuracy: 0.9223\n",
      "Epoch 44/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2240 - accuracy: 0.9353 - val_loss: 0.2643 - val_accuracy: 0.9230\n",
      "Epoch 45/100\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2216 - accuracy: 0.9357 - val_loss: 0.2599 - val_accuracy: 0.9277\n",
      "Epoch 46/100\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.2195 - accuracy: 0.9361 - val_loss: 0.2599 - val_accuracy: 0.9253\n",
      "Epoch 47/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2174 - accuracy: 0.9369 - val_loss: 0.2632 - val_accuracy: 0.9186\n",
      "Epoch 48/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2154 - accuracy: 0.9374 - val_loss: 0.2567 - val_accuracy: 0.9257\n",
      "Epoch 49/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2136 - accuracy: 0.9372 - val_loss: 0.2602 - val_accuracy: 0.9192\n",
      "Epoch 50/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2118 - accuracy: 0.9400 - val_loss: 0.2562 - val_accuracy: 0.9237\n",
      "Epoch 51/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2100 - accuracy: 0.9387 - val_loss: 0.2512 - val_accuracy: 0.9257\n",
      "Epoch 52/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2081 - accuracy: 0.9406 - val_loss: 0.2485 - val_accuracy: 0.9277\n",
      "Epoch 53/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2062 - accuracy: 0.9416 - val_loss: 0.2464 - val_accuracy: 0.9284\n",
      "Epoch 54/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.2047 - accuracy: 0.9414 - val_loss: 0.2476 - val_accuracy: 0.9274\n",
      "Epoch 55/100\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.2030 - accuracy: 0.9425 - val_loss: 0.2463 - val_accuracy: 0.9267\n",
      "Epoch 56/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2013 - accuracy: 0.9426 - val_loss: 0.2448 - val_accuracy: 0.9274\n",
      "Epoch 57/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.1999 - accuracy: 0.9427 - val_loss: 0.2433 - val_accuracy: 0.9291\n",
      "Epoch 58/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1981 - accuracy: 0.9436 - val_loss: 0.2452 - val_accuracy: 0.9287\n",
      "Epoch 59/100\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1974 - accuracy: 0.9441 - val_loss: 0.2400 - val_accuracy: 0.9315\n",
      "Epoch 60/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1954 - accuracy: 0.9445 - val_loss: 0.2383 - val_accuracy: 0.9287\n",
      "Epoch 61/100\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1945 - accuracy: 0.9441 - val_loss: 0.2389 - val_accuracy: 0.9281\n",
      "Epoch 62/100\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.1929 - accuracy: 0.9445 - val_loss: 0.2354 - val_accuracy: 0.9315\n",
      "Epoch 63/100\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1917 - accuracy: 0.9456 - val_loss: 0.2321 - val_accuracy: 0.9311\n",
      "Epoch 64/100\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.1899 - accuracy: 0.9445 - val_loss: 0.2362 - val_accuracy: 0.9284\n",
      "Epoch 65/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1887 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9321\n",
      "Epoch 66/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1872 - accuracy: 0.9468 - val_loss: 0.2370 - val_accuracy: 0.9264\n",
      "Epoch 67/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1863 - accuracy: 0.9465 - val_loss: 0.2316 - val_accuracy: 0.9294\n",
      "Epoch 68/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1852 - accuracy: 0.9465 - val_loss: 0.2319 - val_accuracy: 0.9304\n",
      "Epoch 69/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1839 - accuracy: 0.9483 - val_loss: 0.2263 - val_accuracy: 0.9332\n",
      "Epoch 70/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1826 - accuracy: 0.9472 - val_loss: 0.2265 - val_accuracy: 0.9332\n",
      "Epoch 71/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.1815 - accuracy: 0.9493 - val_loss: 0.2250 - val_accuracy: 0.9325\n",
      "Epoch 72/100\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.1803 - accuracy: 0.9489 - val_loss: 0.2259 - val_accuracy: 0.9318\n",
      "Epoch 73/100\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.1795 - accuracy: 0.9486 - val_loss: 0.2228 - val_accuracy: 0.9355\n",
      "Epoch 74/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1783 - accuracy: 0.9502 - val_loss: 0.2276 - val_accuracy: 0.9294\n",
      "Epoch 75/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1771 - accuracy: 0.9508 - val_loss: 0.2234 - val_accuracy: 0.9321\n",
      "Epoch 76/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1761 - accuracy: 0.9502 - val_loss: 0.2191 - val_accuracy: 0.9338\n",
      "Epoch 77/100\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1750 - accuracy: 0.9506 - val_loss: 0.2211 - val_accuracy: 0.9338\n",
      "Epoch 78/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1743 - accuracy: 0.9508 - val_loss: 0.2189 - val_accuracy: 0.9348\n",
      "Epoch 79/100\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1730 - accuracy: 0.9506 - val_loss: 0.2250 - val_accuracy: 0.9267\n",
      "Epoch 80/100\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1722 - accuracy: 0.9521 - val_loss: 0.2234 - val_accuracy: 0.9294\n",
      "Epoch 81/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1709 - accuracy: 0.9523 - val_loss: 0.2212 - val_accuracy: 0.9335\n",
      "Epoch 82/100\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1701 - accuracy: 0.9523 - val_loss: 0.2212 - val_accuracy: 0.9315\n",
      "Epoch 83/100\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1698 - accuracy: 0.9518 - val_loss: 0.2175 - val_accuracy: 0.9335\n",
      "Epoch 84/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1683 - accuracy: 0.9528 - val_loss: 0.2189 - val_accuracy: 0.9325\n",
      "Epoch 85/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1676 - accuracy: 0.9523 - val_loss: 0.2154 - val_accuracy: 0.9355\n",
      "Epoch 86/100\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1667 - accuracy: 0.9518 - val_loss: 0.2125 - val_accuracy: 0.9352\n",
      "Epoch 87/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1657 - accuracy: 0.9535 - val_loss: 0.2103 - val_accuracy: 0.9382\n",
      "Epoch 88/100\n",
      "7352/7352 [==============================] - 0s 55us/step - loss: 0.1648 - accuracy: 0.9533 - val_loss: 0.2126 - val_accuracy: 0.9369\n",
      "Epoch 89/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1639 - accuracy: 0.9535 - val_loss: 0.2132 - val_accuracy: 0.9348\n",
      "Epoch 90/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1632 - accuracy: 0.9538 - val_loss: 0.2121 - val_accuracy: 0.9362\n",
      "Epoch 91/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1626 - accuracy: 0.9542 - val_loss: 0.2102 - val_accuracy: 0.9362\n",
      "Epoch 92/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1620 - accuracy: 0.9547 - val_loss: 0.2073 - val_accuracy: 0.9376\n",
      "Epoch 93/100\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1610 - accuracy: 0.9539 - val_loss: 0.2110 - val_accuracy: 0.9359\n",
      "Epoch 94/100\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1601 - accuracy: 0.9547 - val_loss: 0.2051 - val_accuracy: 0.9410\n",
      "Epoch 95/100\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1590 - accuracy: 0.9553 - val_loss: 0.2043 - val_accuracy: 0.9396\n",
      "Epoch 96/100\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1588 - accuracy: 0.9558 - val_loss: 0.2036 - val_accuracy: 0.9410\n",
      "Epoch 97/100\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1581 - accuracy: 0.9573 - val_loss: 0.2071 - val_accuracy: 0.9372\n",
      "Epoch 98/100\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1571 - accuracy: 0.9559 - val_loss: 0.2040 - val_accuracy: 0.9382\n",
      "Epoch 99/100\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.1562 - accuracy: 0.9569 - val_loss: 0.2042 - val_accuracy: 0.9386\n",
      "Epoch 100/100\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.95 - 0s 39us/step - loss: 0.1559 - accuracy: 0.9569 - val_loss: 0.2034 - val_accuracy: 0.9379\n",
      "Test score: 0.2034424094373912\n",
      "Test accuracy: 0.9379029273986816\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=100, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/200\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.3062 - accuracy: 0.5291 - val_loss: 1.0360 - val_accuracy: 0.6868\n",
      "Epoch 2/200\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.8961 - accuracy: 0.7622 - val_loss: 0.8264 - val_accuracy: 0.7540\n",
      "Epoch 3/200\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.7348 - accuracy: 0.8209 - val_loss: 0.7050 - val_accuracy: 0.8446\n",
      "Epoch 4/200\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.6404 - accuracy: 0.8507 - val_loss: 0.6377 - val_accuracy: 0.8310\n",
      "Epoch 5/200\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.5772 - accuracy: 0.8619 - val_loss: 0.5840 - val_accuracy: 0.8490\n",
      "Epoch 6/200\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.5305 - accuracy: 0.8700 - val_loss: 0.5425 - val_accuracy: 0.8728\n",
      "Epoch 7/200\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.4946 - accuracy: 0.8739 - val_loss: 0.5105 - val_accuracy: 0.8795\n",
      "Epoch 8/200\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.4656 - accuracy: 0.8825 - val_loss: 0.4948 - val_accuracy: 0.8673\n",
      "Epoch 9/200\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.4424 - accuracy: 0.8857 - val_loss: 0.4667 - val_accuracy: 0.8782\n",
      "Epoch 10/200\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.4223 - accuracy: 0.8901 - val_loss: 0.4492 - val_accuracy: 0.8819\n",
      "Epoch 11/200\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.4055 - accuracy: 0.8923 - val_loss: 0.4317 - val_accuracy: 0.8860\n",
      "Epoch 12/200\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.3906 - accuracy: 0.8939 - val_loss: 0.4219 - val_accuracy: 0.8887\n",
      "Epoch 13/200\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.3778 - accuracy: 0.8970 - val_loss: 0.4043 - val_accuracy: 0.8948\n",
      "Epoch 14/200\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.89 - 0s 39us/step - loss: 0.3650 - accuracy: 0.9006 - val_loss: 0.3913 - val_accuracy: 0.8924\n",
      "Epoch 15/200\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.3551 - accuracy: 0.9003 - val_loss: 0.3814 - val_accuracy: 0.8948\n",
      "Epoch 16/200\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.3450 - accuracy: 0.9044 - val_loss: 0.3759 - val_accuracy: 0.8948\n",
      "Epoch 17/200\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.3367 - accuracy: 0.9045 - val_loss: 0.3682 - val_accuracy: 0.8890\n",
      "Epoch 18/200\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.3282 - accuracy: 0.9083 - val_loss: 0.3612 - val_accuracy: 0.8914\n",
      "Epoch 19/200\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.3210 - accuracy: 0.9083 - val_loss: 0.3551 - val_accuracy: 0.8921\n",
      "Epoch 20/200\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.3145 - accuracy: 0.9100 - val_loss: 0.3445 - val_accuracy: 0.9019\n",
      "Epoch 21/200\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.3080 - accuracy: 0.9108 - val_loss: 0.3371 - val_accuracy: 0.9050\n",
      "Epoch 22/200\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.3023 - accuracy: 0.9135 - val_loss: 0.3323 - val_accuracy: 0.9053\n",
      "Epoch 23/200\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.2960 - accuracy: 0.9157 - val_loss: 0.3269 - val_accuracy: 0.9077\n",
      "Epoch 24/200\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2912 - accuracy: 0.9151 - val_loss: 0.3245 - val_accuracy: 0.9046\n",
      "Epoch 25/200\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2862 - accuracy: 0.9163 - val_loss: 0.3297 - val_accuracy: 0.9053\n",
      "Epoch 26/200\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2822 - accuracy: 0.9163 - val_loss: 0.3131 - val_accuracy: 0.9182\n",
      "Epoch 27/200\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.2773 - accuracy: 0.9193 - val_loss: 0.3077 - val_accuracy: 0.9135\n",
      "Epoch 28/200\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2727 - accuracy: 0.9197 - val_loss: 0.3042 - val_accuracy: 0.9182\n",
      "Epoch 29/200\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2687 - accuracy: 0.9218 - val_loss: 0.3017 - val_accuracy: 0.9118\n",
      "Epoch 30/200\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.2652 - accuracy: 0.9218 - val_loss: 0.2994 - val_accuracy: 0.9118\n",
      "Epoch 31/200\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2609 - accuracy: 0.9245 - val_loss: 0.2962 - val_accuracy: 0.9230\n",
      "Epoch 32/200\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2583 - accuracy: 0.9242 - val_loss: 0.2919 - val_accuracy: 0.9148\n",
      "Epoch 33/200\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2544 - accuracy: 0.9257 - val_loss: 0.2851 - val_accuracy: 0.9213\n",
      "Epoch 34/200\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2513 - accuracy: 0.9286 - val_loss: 0.2854 - val_accuracy: 0.9186\n",
      "Epoch 35/200\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2487 - accuracy: 0.9282 - val_loss: 0.2831 - val_accuracy: 0.9233\n",
      "Epoch 36/200\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.2448 - accuracy: 0.9297 - val_loss: 0.2797 - val_accuracy: 0.9189\n",
      "Epoch 37/200\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.2427 - accuracy: 0.9295 - val_loss: 0.2783 - val_accuracy: 0.9206\n",
      "Epoch 38/200\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.2395 - accuracy: 0.9308 - val_loss: 0.2734 - val_accuracy: 0.9209\n",
      "Epoch 39/200\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.2374 - accuracy: 0.9306 - val_loss: 0.2713 - val_accuracy: 0.9270\n",
      "Epoch 40/200\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.2349 - accuracy: 0.9331 - val_loss: 0.2670 - val_accuracy: 0.9284\n",
      "Epoch 41/200\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2319 - accuracy: 0.9321 - val_loss: 0.2681 - val_accuracy: 0.9216\n",
      "Epoch 42/200\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.2293 - accuracy: 0.9342 - val_loss: 0.2642 - val_accuracy: 0.9291\n",
      "Epoch 43/200\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2273 - accuracy: 0.9354 - val_loss: 0.2618 - val_accuracy: 0.9301\n",
      "Epoch 44/200\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.2250 - accuracy: 0.9359 - val_loss: 0.2623 - val_accuracy: 0.9250\n",
      "Epoch 45/200\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2229 - accuracy: 0.9354 - val_loss: 0.2560 - val_accuracy: 0.9264\n",
      "Epoch 46/200\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2209 - accuracy: 0.9372 - val_loss: 0.2541 - val_accuracy: 0.9270\n",
      "Epoch 47/200\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2188 - accuracy: 0.9377 - val_loss: 0.2575 - val_accuracy: 0.9220\n",
      "Epoch 48/200\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2168 - accuracy: 0.9387 - val_loss: 0.2527 - val_accuracy: 0.9260\n",
      "Epoch 49/200\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.2149 - accuracy: 0.9387 - val_loss: 0.2517 - val_accuracy: 0.9274\n",
      "Epoch 50/200\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2126 - accuracy: 0.9388 - val_loss: 0.2497 - val_accuracy: 0.9267\n",
      "Epoch 51/200\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2111 - accuracy: 0.9393 - val_loss: 0.2491 - val_accuracy: 0.9264\n",
      "Epoch 52/200\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.2094 - accuracy: 0.9385 - val_loss: 0.2580 - val_accuracy: 0.9141\n",
      "Epoch 53/200\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.2077 - accuracy: 0.9388 - val_loss: 0.2410 - val_accuracy: 0.9335\n",
      "Epoch 54/200\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.2057 - accuracy: 0.9412 - val_loss: 0.2426 - val_accuracy: 0.9291\n",
      "Epoch 55/200\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.2038 - accuracy: 0.9431 - val_loss: 0.2449 - val_accuracy: 0.9267\n",
      "Epoch 56/200\n",
      "7352/7352 [==============================] - 0s 26us/step - loss: 0.2030 - accuracy: 0.9426 - val_loss: 0.2391 - val_accuracy: 0.9291\n",
      "Epoch 57/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.2011 - accuracy: 0.9437 - val_loss: 0.2385 - val_accuracy: 0.9301\n",
      "Epoch 58/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1993 - accuracy: 0.9438 - val_loss: 0.2358 - val_accuracy: 0.9325\n",
      "Epoch 59/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1979 - accuracy: 0.9461 - val_loss: 0.2338 - val_accuracy: 0.9321\n",
      "Epoch 60/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1968 - accuracy: 0.9448 - val_loss: 0.2365 - val_accuracy: 0.9274\n",
      "Epoch 61/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1951 - accuracy: 0.9453 - val_loss: 0.2328 - val_accuracy: 0.9345\n",
      "Epoch 62/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1939 - accuracy: 0.9453 - val_loss: 0.2306 - val_accuracy: 0.9355\n",
      "Epoch 63/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1925 - accuracy: 0.9455 - val_loss: 0.2308 - val_accuracy: 0.9362\n",
      "Epoch 64/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1911 - accuracy: 0.9460 - val_loss: 0.2282 - val_accuracy: 0.9355\n",
      "Epoch 65/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1899 - accuracy: 0.9461 - val_loss: 0.2273 - val_accuracy: 0.9352\n",
      "Epoch 66/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1887 - accuracy: 0.9464 - val_loss: 0.2295 - val_accuracy: 0.9325\n",
      "Epoch 67/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1867 - accuracy: 0.9476 - val_loss: 0.2245 - val_accuracy: 0.9355\n",
      "Epoch 68/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1866 - accuracy: 0.9483 - val_loss: 0.2254 - val_accuracy: 0.9348\n",
      "Epoch 69/200\n",
      "7352/7352 [==============================] - 0s 26us/step - loss: 0.1846 - accuracy: 0.9474 - val_loss: 0.2264 - val_accuracy: 0.9321\n",
      "Epoch 70/200\n",
      "7352/7352 [==============================] - 0s 26us/step - loss: 0.1836 - accuracy: 0.9490 - val_loss: 0.2293 - val_accuracy: 0.9260\n",
      "Epoch 71/200\n",
      "7352/7352 [==============================] - 0s 26us/step - loss: 0.1826 - accuracy: 0.9494 - val_loss: 0.2200 - val_accuracy: 0.9369\n",
      "Epoch 72/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1813 - accuracy: 0.9502 - val_loss: 0.2181 - val_accuracy: 0.9386\n",
      "Epoch 73/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1803 - accuracy: 0.9508 - val_loss: 0.2184 - val_accuracy: 0.9365\n",
      "Epoch 74/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1795 - accuracy: 0.9504 - val_loss: 0.2218 - val_accuracy: 0.9345\n",
      "Epoch 75/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1781 - accuracy: 0.9512 - val_loss: 0.2183 - val_accuracy: 0.9376\n",
      "Epoch 76/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1773 - accuracy: 0.9508 - val_loss: 0.2158 - val_accuracy: 0.9396\n",
      "Epoch 77/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1764 - accuracy: 0.9521 - val_loss: 0.2174 - val_accuracy: 0.9389\n",
      "Epoch 78/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1751 - accuracy: 0.9517 - val_loss: 0.2200 - val_accuracy: 0.9325\n",
      "Epoch 79/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1741 - accuracy: 0.9523 - val_loss: 0.2172 - val_accuracy: 0.9379\n",
      "Epoch 80/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1730 - accuracy: 0.9533 - val_loss: 0.2132 - val_accuracy: 0.9379\n",
      "Epoch 81/200\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1721 - accuracy: 0.9528 - val_loss: 0.2148 - val_accuracy: 0.9413\n",
      "Epoch 82/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1716 - accuracy: 0.9531 - val_loss: 0.2171 - val_accuracy: 0.9338\n",
      "Epoch 83/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1704 - accuracy: 0.9535 - val_loss: 0.2112 - val_accuracy: 0.9399\n",
      "Epoch 84/200\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.1693 - accuracy: 0.9538 - val_loss: 0.2100 - val_accuracy: 0.9399\n",
      "Epoch 85/200\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.1684 - accuracy: 0.9535 - val_loss: 0.2103 - val_accuracy: 0.9376\n",
      "Epoch 86/200\n",
      "7352/7352 [==============================] - 0s 27us/step - loss: 0.1672 - accuracy: 0.9536 - val_loss: 0.2185 - val_accuracy: 0.9301\n",
      "Epoch 87/200\n",
      "7352/7352 [==============================] - 0s 25us/step - loss: 0.1670 - accuracy: 0.9538 - val_loss: 0.2100 - val_accuracy: 0.9396\n",
      "Epoch 88/200\n",
      "7352/7352 [==============================] - 0s 26us/step - loss: 0.1659 - accuracy: 0.9548 - val_loss: 0.2064 - val_accuracy: 0.9437\n",
      "Epoch 89/200\n",
      "7352/7352 [==============================] - 0s 24us/step - loss: 0.1650 - accuracy: 0.9558 - val_loss: 0.2067 - val_accuracy: 0.9420\n",
      "Epoch 90/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1640 - accuracy: 0.9554 - val_loss: 0.2048 - val_accuracy: 0.9423\n",
      "Epoch 91/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1634 - accuracy: 0.9561 - val_loss: 0.2067 - val_accuracy: 0.9406\n",
      "Epoch 92/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1625 - accuracy: 0.9558 - val_loss: 0.2048 - val_accuracy: 0.9420\n",
      "Epoch 93/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1618 - accuracy: 0.9566 - val_loss: 0.2119 - val_accuracy: 0.9342\n",
      "Epoch 94/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1614 - accuracy: 0.9569 - val_loss: 0.2082 - val_accuracy: 0.9355\n",
      "Epoch 95/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1600 - accuracy: 0.9577 - val_loss: 0.2029 - val_accuracy: 0.9427\n",
      "Epoch 96/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1595 - accuracy: 0.9578 - val_loss: 0.2034 - val_accuracy: 0.9399\n",
      "Epoch 97/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1590 - accuracy: 0.9567 - val_loss: 0.2035 - val_accuracy: 0.9416\n",
      "Epoch 98/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1581 - accuracy: 0.9574 - val_loss: 0.2038 - val_accuracy: 0.9379\n",
      "Epoch 99/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1574 - accuracy: 0.9569 - val_loss: 0.2012 - val_accuracy: 0.9406\n",
      "Epoch 100/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1567 - accuracy: 0.9589 - val_loss: 0.1976 - val_accuracy: 0.9444\n",
      "Epoch 101/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1559 - accuracy: 0.9578 - val_loss: 0.1999 - val_accuracy: 0.9399\n",
      "Epoch 102/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1552 - accuracy: 0.9582 - val_loss: 0.2021 - val_accuracy: 0.9376\n",
      "Epoch 103/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1547 - accuracy: 0.9582 - val_loss: 0.1996 - val_accuracy: 0.9382\n",
      "Epoch 104/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1539 - accuracy: 0.9592 - val_loss: 0.1971 - val_accuracy: 0.9433\n",
      "Epoch 105/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1530 - accuracy: 0.9599 - val_loss: 0.1964 - val_accuracy: 0.9437\n",
      "Epoch 106/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1525 - accuracy: 0.9596 - val_loss: 0.1967 - val_accuracy: 0.9427\n",
      "Epoch 107/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1519 - accuracy: 0.9604 - val_loss: 0.1979 - val_accuracy: 0.9413\n",
      "Epoch 108/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1511 - accuracy: 0.9606 - val_loss: 0.1943 - val_accuracy: 0.9433\n",
      "Epoch 109/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1508 - accuracy: 0.9600 - val_loss: 0.1972 - val_accuracy: 0.9420\n",
      "Epoch 110/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1500 - accuracy: 0.9595 - val_loss: 0.1942 - val_accuracy: 0.9440\n",
      "Epoch 111/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1494 - accuracy: 0.9606 - val_loss: 0.1937 - val_accuracy: 0.9433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1486 - accuracy: 0.9606 - val_loss: 0.1944 - val_accuracy: 0.9450\n",
      "Epoch 113/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1481 - accuracy: 0.9616 - val_loss: 0.1975 - val_accuracy: 0.9382\n",
      "Epoch 114/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1477 - accuracy: 0.9607 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
      "Epoch 115/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1469 - accuracy: 0.9606 - val_loss: 0.1985 - val_accuracy: 0.9372\n",
      "Epoch 116/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1464 - accuracy: 0.9619 - val_loss: 0.1938 - val_accuracy: 0.9413\n",
      "Epoch 117/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1461 - accuracy: 0.9615 - val_loss: 0.1917 - val_accuracy: 0.9444\n",
      "Epoch 118/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1453 - accuracy: 0.9615 - val_loss: 0.1957 - val_accuracy: 0.9372\n",
      "Epoch 119/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1448 - accuracy: 0.9615 - val_loss: 0.1896 - val_accuracy: 0.9437\n",
      "Epoch 120/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1441 - accuracy: 0.9623 - val_loss: 0.1949 - val_accuracy: 0.9386\n",
      "Epoch 121/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1435 - accuracy: 0.9625 - val_loss: 0.1872 - val_accuracy: 0.9447\n",
      "Epoch 122/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1434 - accuracy: 0.9626 - val_loss: 0.1889 - val_accuracy: 0.9437\n",
      "Epoch 123/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1426 - accuracy: 0.9615 - val_loss: 0.1939 - val_accuracy: 0.9379\n",
      "Epoch 124/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1421 - accuracy: 0.9619 - val_loss: 0.1877 - val_accuracy: 0.9454\n",
      "Epoch 125/200\n",
      "7352/7352 [==============================] - 0s 22us/step - loss: 0.1418 - accuracy: 0.9627 - val_loss: 0.1887 - val_accuracy: 0.9430\n",
      "Epoch 126/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1411 - accuracy: 0.9629 - val_loss: 0.1863 - val_accuracy: 0.9457\n",
      "Epoch 127/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1406 - accuracy: 0.9626 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
      "Epoch 128/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1403 - accuracy: 0.9631 - val_loss: 0.1874 - val_accuracy: 0.9437\n",
      "Epoch 129/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1398 - accuracy: 0.9637 - val_loss: 0.1864 - val_accuracy: 0.9444\n",
      "Epoch 130/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1390 - accuracy: 0.9634 - val_loss: 0.1851 - val_accuracy: 0.9447\n",
      "Epoch 131/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1388 - accuracy: 0.9637 - val_loss: 0.1866 - val_accuracy: 0.9416\n",
      "Epoch 132/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1380 - accuracy: 0.9640 - val_loss: 0.1869 - val_accuracy: 0.9420\n",
      "Epoch 133/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1378 - accuracy: 0.9626 - val_loss: 0.1861 - val_accuracy: 0.9430\n",
      "Epoch 134/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1370 - accuracy: 0.9644 - val_loss: 0.1864 - val_accuracy: 0.9423\n",
      "Epoch 135/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1367 - accuracy: 0.9649 - val_loss: 0.1829 - val_accuracy: 0.9450\n",
      "Epoch 136/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1363 - accuracy: 0.9638 - val_loss: 0.1825 - val_accuracy: 0.9460\n",
      "Epoch 137/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1358 - accuracy: 0.9650 - val_loss: 0.1831 - val_accuracy: 0.9454\n",
      "Epoch 138/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1354 - accuracy: 0.9646 - val_loss: 0.1818 - val_accuracy: 0.9454\n",
      "Epoch 139/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1349 - accuracy: 0.9641 - val_loss: 0.1820 - val_accuracy: 0.9447\n",
      "Epoch 140/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1344 - accuracy: 0.9641 - val_loss: 0.1843 - val_accuracy: 0.9420\n",
      "Epoch 141/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1341 - accuracy: 0.9649 - val_loss: 0.1809 - val_accuracy: 0.9450\n",
      "Epoch 142/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1337 - accuracy: 0.9645 - val_loss: 0.1890 - val_accuracy: 0.9376\n",
      "Epoch 143/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1335 - accuracy: 0.9650 - val_loss: 0.1802 - val_accuracy: 0.9457\n",
      "Epoch 144/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1327 - accuracy: 0.9657 - val_loss: 0.1831 - val_accuracy: 0.9410\n",
      "Epoch 145/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1322 - accuracy: 0.9650 - val_loss: 0.1799 - val_accuracy: 0.9447\n",
      "Epoch 146/200\n",
      "7352/7352 [==============================] - 0s 23us/step - loss: 0.1318 - accuracy: 0.9650 - val_loss: 0.1799 - val_accuracy: 0.9454\n",
      "Epoch 147/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1315 - accuracy: 0.9650 - val_loss: 0.1786 - val_accuracy: 0.9464\n",
      "Epoch 148/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1308 - accuracy: 0.9659 - val_loss: 0.1784 - val_accuracy: 0.9457\n",
      "Epoch 149/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1308 - accuracy: 0.9656 - val_loss: 0.1785 - val_accuracy: 0.9464\n",
      "Epoch 150/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1304 - accuracy: 0.9664 - val_loss: 0.1784 - val_accuracy: 0.9471\n",
      "Epoch 151/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1298 - accuracy: 0.9664 - val_loss: 0.1785 - val_accuracy: 0.9457\n",
      "Epoch 152/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1293 - accuracy: 0.9656 - val_loss: 0.1800 - val_accuracy: 0.9433\n",
      "Epoch 153/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1291 - accuracy: 0.9660 - val_loss: 0.1790 - val_accuracy: 0.9444\n",
      "Epoch 154/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1286 - accuracy: 0.9660 - val_loss: 0.1788 - val_accuracy: 0.9447\n",
      "Epoch 155/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1285 - accuracy: 0.9646 - val_loss: 0.1771 - val_accuracy: 0.9457\n",
      "Epoch 156/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1284 - accuracy: 0.9659 - val_loss: 0.1759 - val_accuracy: 0.9464\n",
      "Epoch 157/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1275 - accuracy: 0.9667 - val_loss: 0.1778 - val_accuracy: 0.9444\n",
      "Epoch 158/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1274 - accuracy: 0.9672 - val_loss: 0.1769 - val_accuracy: 0.9454\n",
      "Epoch 159/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1270 - accuracy: 0.9665 - val_loss: 0.1739 - val_accuracy: 0.9484\n",
      "Epoch 160/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1265 - accuracy: 0.9669 - val_loss: 0.1777 - val_accuracy: 0.9440\n",
      "Epoch 161/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1263 - accuracy: 0.9663 - val_loss: 0.1741 - val_accuracy: 0.9471\n",
      "Epoch 162/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1259 - accuracy: 0.9665 - val_loss: 0.1762 - val_accuracy: 0.9460\n",
      "Epoch 163/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1256 - accuracy: 0.9664 - val_loss: 0.1750 - val_accuracy: 0.9460\n",
      "Epoch 164/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1250 - accuracy: 0.9674 - val_loss: 0.1733 - val_accuracy: 0.9477\n",
      "Epoch 165/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1248 - accuracy: 0.9665 - val_loss: 0.1726 - val_accuracy: 0.9477\n",
      "Epoch 166/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1244 - accuracy: 0.9668 - val_loss: 0.1762 - val_accuracy: 0.9444\n",
      "Epoch 167/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1239 - accuracy: 0.9678 - val_loss: 0.1755 - val_accuracy: 0.9454\n",
      "Epoch 168/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1240 - accuracy: 0.9675 - val_loss: 0.1751 - val_accuracy: 0.9457\n",
      "Epoch 169/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1233 - accuracy: 0.9674 - val_loss: 0.1790 - val_accuracy: 0.9416\n",
      "Epoch 170/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1231 - accuracy: 0.9679 - val_loss: 0.1792 - val_accuracy: 0.9406\n",
      "Epoch 171/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1227 - accuracy: 0.9683 - val_loss: 0.1707 - val_accuracy: 0.9498\n",
      "Epoch 172/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1228 - accuracy: 0.9680 - val_loss: 0.1709 - val_accuracy: 0.9477\n",
      "Epoch 173/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1221 - accuracy: 0.9687 - val_loss: 0.1752 - val_accuracy: 0.9433\n",
      "Epoch 174/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1218 - accuracy: 0.9680 - val_loss: 0.1719 - val_accuracy: 0.9474\n",
      "Epoch 175/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1214 - accuracy: 0.9690 - val_loss: 0.1747 - val_accuracy: 0.9454\n",
      "Epoch 176/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1213 - accuracy: 0.9683 - val_loss: 0.1765 - val_accuracy: 0.9420\n",
      "Epoch 177/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1208 - accuracy: 0.9678 - val_loss: 0.1740 - val_accuracy: 0.9440\n",
      "Epoch 178/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1205 - accuracy: 0.9676 - val_loss: 0.1736 - val_accuracy: 0.9440\n",
      "Epoch 179/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1203 - accuracy: 0.9683 - val_loss: 0.1713 - val_accuracy: 0.9471\n",
      "Epoch 180/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1198 - accuracy: 0.9695 - val_loss: 0.1802 - val_accuracy: 0.9399\n",
      "Epoch 181/200\n",
      "7352/7352 [==============================] - 0s 21us/step - loss: 0.1197 - accuracy: 0.9690 - val_loss: 0.1709 - val_accuracy: 0.9460\n",
      "Epoch 182/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1193 - accuracy: 0.9691 - val_loss: 0.1722 - val_accuracy: 0.9454\n",
      "Epoch 183/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1189 - accuracy: 0.9699 - val_loss: 0.1708 - val_accuracy: 0.9471\n",
      "Epoch 184/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1187 - accuracy: 0.9694 - val_loss: 0.1708 - val_accuracy: 0.9464\n",
      "Epoch 185/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1186 - accuracy: 0.9689 - val_loss: 0.1687 - val_accuracy: 0.9477\n",
      "Epoch 186/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1183 - accuracy: 0.9694 - val_loss: 0.1682 - val_accuracy: 0.9477\n",
      "Epoch 187/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1178 - accuracy: 0.9693 - val_loss: 0.1690 - val_accuracy: 0.9474\n",
      "Epoch 188/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1177 - accuracy: 0.9698 - val_loss: 0.1699 - val_accuracy: 0.9467\n",
      "Epoch 189/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1172 - accuracy: 0.9694 - val_loss: 0.1725 - val_accuracy: 0.9433\n",
      "Epoch 190/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1170 - accuracy: 0.9705 - val_loss: 0.1685 - val_accuracy: 0.9467\n",
      "Epoch 191/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1166 - accuracy: 0.9690 - val_loss: 0.1693 - val_accuracy: 0.9471\n",
      "Epoch 192/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1167 - accuracy: 0.9701 - val_loss: 0.1670 - val_accuracy: 0.9474\n",
      "Epoch 193/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1161 - accuracy: 0.9695 - val_loss: 0.1661 - val_accuracy: 0.9484\n",
      "Epoch 194/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1161 - accuracy: 0.9699 - val_loss: 0.1663 - val_accuracy: 0.9488\n",
      "Epoch 195/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1158 - accuracy: 0.9698 - val_loss: 0.1718 - val_accuracy: 0.9440\n",
      "Epoch 196/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1154 - accuracy: 0.9693 - val_loss: 0.1702 - val_accuracy: 0.9454\n",
      "Epoch 197/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1152 - accuracy: 0.9693 - val_loss: 0.1653 - val_accuracy: 0.9484\n",
      "Epoch 198/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1149 - accuracy: 0.9701 - val_loss: 0.1675 - val_accuracy: 0.9477\n",
      "Epoch 199/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1143 - accuracy: 0.9699 - val_loss: 0.1650 - val_accuracy: 0.9491\n",
      "Epoch 200/200\n",
      "7352/7352 [==============================] - 0s 20us/step - loss: 0.1143 - accuracy: 0.9713 - val_loss: 0.1709 - val_accuracy: 0.9437\n",
      "Test score: 0.1708766799691899\n",
      "Test accuracy: 0.9436715245246887\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=200, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/400\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.3057 - accuracy: 0.5139 - val_loss: 1.0413 - val_accuracy: 0.6759\n",
      "Epoch 2/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.8947 - accuracy: 0.7688 - val_loss: 0.8268 - val_accuracy: 0.8144\n",
      "Epoch 3/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.7339 - accuracy: 0.8298 - val_loss: 0.7101 - val_accuracy: 0.8297\n",
      "Epoch 4/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.6388 - accuracy: 0.8553 - val_loss: 0.6386 - val_accuracy: 0.8626\n",
      "Epoch 5/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.5739 - accuracy: 0.8607 - val_loss: 0.5851 - val_accuracy: 0.8571\n",
      "Epoch 6/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.5273 - accuracy: 0.8769 - val_loss: 0.5542 - val_accuracy: 0.8375\n",
      "Epoch 7/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.4906 - accuracy: 0.8811 - val_loss: 0.5100 - val_accuracy: 0.8724\n",
      "Epoch 8/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.4620 - accuracy: 0.8857 - val_loss: 0.4874 - val_accuracy: 0.8744\n",
      "Epoch 9/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.4385 - accuracy: 0.8866 - val_loss: 0.4752 - val_accuracy: 0.8785\n",
      "Epoch 10/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.4184 - accuracy: 0.8925 - val_loss: 0.4503 - val_accuracy: 0.8714\n",
      "Epoch 11/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.4014 - accuracy: 0.8928 - val_loss: 0.4314 - val_accuracy: 0.8816\n",
      "Epoch 12/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3867 - accuracy: 0.8953 - val_loss: 0.4241 - val_accuracy: 0.8890\n",
      "Epoch 13/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.3730 - accuracy: 0.8983 - val_loss: 0.4028 - val_accuracy: 0.8941\n",
      "Epoch 14/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.3618 - accuracy: 0.9006 - val_loss: 0.3985 - val_accuracy: 0.8829\n",
      "Epoch 15/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.3511 - accuracy: 0.9011 - val_loss: 0.3825 - val_accuracy: 0.8951\n",
      "Epoch 16/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.3414 - accuracy: 0.9057 - val_loss: 0.3798 - val_accuracy: 0.8860\n",
      "Epoch 17/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3333 - accuracy: 0.9053 - val_loss: 0.3708 - val_accuracy: 0.8880\n",
      "Epoch 18/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3251 - accuracy: 0.9071 - val_loss: 0.3620 - val_accuracy: 0.8968\n",
      "Epoch 19/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3181 - accuracy: 0.9082 - val_loss: 0.3577 - val_accuracy: 0.8975\n",
      "Epoch 20/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.3110 - accuracy: 0.9102 - val_loss: 0.3461 - val_accuracy: 0.9060\n",
      "Epoch 21/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.3048 - accuracy: 0.9100 - val_loss: 0.3479 - val_accuracy: 0.8907\n",
      "Epoch 22/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2984 - accuracy: 0.9132 - val_loss: 0.3346 - val_accuracy: 0.9043\n",
      "Epoch 23/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2941 - accuracy: 0.9131 - val_loss: 0.3391 - val_accuracy: 0.8918\n",
      "Epoch 24/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2884 - accuracy: 0.9158 - val_loss: 0.3297 - val_accuracy: 0.8972\n",
      "Epoch 25/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2835 - accuracy: 0.9155 - val_loss: 0.3277 - val_accuracy: 0.8958\n",
      "Epoch 26/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2787 - accuracy: 0.9172 - val_loss: 0.3110 - val_accuracy: 0.9141\n",
      "Epoch 27/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2748 - accuracy: 0.9165 - val_loss: 0.3126 - val_accuracy: 0.9060\n",
      "Epoch 28/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2703 - accuracy: 0.9203 - val_loss: 0.3100 - val_accuracy: 0.9077\n",
      "Epoch 29/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2662 - accuracy: 0.9221 - val_loss: 0.3086 - val_accuracy: 0.9046\n",
      "Epoch 30/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2624 - accuracy: 0.9222 - val_loss: 0.3028 - val_accuracy: 0.9084\n",
      "Epoch 31/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2589 - accuracy: 0.9249 - val_loss: 0.2940 - val_accuracy: 0.9199\n",
      "Epoch 32/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2557 - accuracy: 0.9238 - val_loss: 0.2993 - val_accuracy: 0.9067\n",
      "Epoch 33/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2517 - accuracy: 0.9274 - val_loss: 0.2924 - val_accuracy: 0.9148\n",
      "Epoch 34/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2488 - accuracy: 0.9260 - val_loss: 0.2886 - val_accuracy: 0.9240\n",
      "Epoch 35/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2458 - accuracy: 0.9268 - val_loss: 0.2834 - val_accuracy: 0.9250\n",
      "Epoch 36/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2431 - accuracy: 0.9298 - val_loss: 0.2787 - val_accuracy: 0.9220\n",
      "Epoch 37/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2400 - accuracy: 0.9297 - val_loss: 0.2831 - val_accuracy: 0.9165\n",
      "Epoch 38/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2373 - accuracy: 0.9298 - val_loss: 0.2800 - val_accuracy: 0.9135\n",
      "Epoch 39/400\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.2352 - accuracy: 0.9321 - val_loss: 0.2846 - val_accuracy: 0.9084\n",
      "Epoch 40/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2327 - accuracy: 0.9304 - val_loss: 0.2724 - val_accuracy: 0.9192\n",
      "Epoch 41/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2302 - accuracy: 0.9334 - val_loss: 0.2725 - val_accuracy: 0.9179\n",
      "Epoch 42/400\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.2276 - accuracy: 0.9332 - val_loss: 0.2683 - val_accuracy: 0.9209\n",
      "Epoch 43/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2251 - accuracy: 0.9329 - val_loss: 0.2636 - val_accuracy: 0.9291\n",
      "Epoch 44/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2230 - accuracy: 0.9350 - val_loss: 0.2620 - val_accuracy: 0.9243\n",
      "Epoch 45/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2207 - accuracy: 0.9370 - val_loss: 0.2604 - val_accuracy: 0.9267\n",
      "Epoch 46/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2191 - accuracy: 0.9363 - val_loss: 0.2568 - val_accuracy: 0.9260\n",
      "Epoch 47/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2166 - accuracy: 0.9376 - val_loss: 0.2532 - val_accuracy: 0.9315\n",
      "Epoch 48/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2150 - accuracy: 0.9387 - val_loss: 0.2585 - val_accuracy: 0.9216\n",
      "Epoch 49/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2132 - accuracy: 0.9372 - val_loss: 0.2530 - val_accuracy: 0.9298\n",
      "Epoch 50/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2116 - accuracy: 0.9392 - val_loss: 0.2518 - val_accuracy: 0.9264\n",
      "Epoch 51/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2098 - accuracy: 0.9388 - val_loss: 0.2504 - val_accuracy: 0.9291\n",
      "Epoch 52/400\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.2078 - accuracy: 0.9404 - val_loss: 0.2497 - val_accuracy: 0.9274\n",
      "Epoch 53/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2060 - accuracy: 0.9408 - val_loss: 0.2475 - val_accuracy: 0.9287\n",
      "Epoch 54/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2039 - accuracy: 0.9412 - val_loss: 0.2457 - val_accuracy: 0.9311\n",
      "Epoch 55/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2027 - accuracy: 0.9429 - val_loss: 0.2456 - val_accuracy: 0.9281\n",
      "Epoch 56/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2014 - accuracy: 0.9423 - val_loss: 0.2440 - val_accuracy: 0.9291\n",
      "Epoch 57/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1992 - accuracy: 0.9423 - val_loss: 0.2390 - val_accuracy: 0.9321\n",
      "Epoch 58/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1981 - accuracy: 0.9426 - val_loss: 0.2386 - val_accuracy: 0.9325\n",
      "Epoch 59/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1965 - accuracy: 0.9438 - val_loss: 0.2389 - val_accuracy: 0.9321\n",
      "Epoch 60/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1953 - accuracy: 0.9441 - val_loss: 0.2343 - val_accuracy: 0.9342\n",
      "Epoch 61/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1939 - accuracy: 0.9444 - val_loss: 0.2340 - val_accuracy: 0.9335\n",
      "Epoch 62/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1927 - accuracy: 0.9455 - val_loss: 0.2339 - val_accuracy: 0.9342\n",
      "Epoch 63/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1914 - accuracy: 0.9455 - val_loss: 0.2362 - val_accuracy: 0.9264\n",
      "Epoch 64/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1896 - accuracy: 0.9465 - val_loss: 0.2342 - val_accuracy: 0.9304\n",
      "Epoch 65/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1882 - accuracy: 0.9453 - val_loss: 0.2327 - val_accuracy: 0.9315\n",
      "Epoch 66/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1872 - accuracy: 0.9482 - val_loss: 0.2313 - val_accuracy: 0.9311\n",
      "Epoch 67/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1859 - accuracy: 0.9478 - val_loss: 0.2325 - val_accuracy: 0.9277\n",
      "Epoch 68/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1849 - accuracy: 0.9476 - val_loss: 0.2287 - val_accuracy: 0.9335\n",
      "Epoch 69/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1834 - accuracy: 0.9484 - val_loss: 0.2258 - val_accuracy: 0.9335\n",
      "Epoch 70/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1822 - accuracy: 0.9484 - val_loss: 0.2340 - val_accuracy: 0.9240\n",
      "Epoch 71/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1812 - accuracy: 0.9489 - val_loss: 0.2265 - val_accuracy: 0.9328\n",
      "Epoch 72/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1803 - accuracy: 0.9497 - val_loss: 0.2281 - val_accuracy: 0.9277\n",
      "Epoch 73/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1790 - accuracy: 0.9497 - val_loss: 0.2232 - val_accuracy: 0.9328\n",
      "Epoch 74/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1780 - accuracy: 0.9512 - val_loss: 0.2205 - val_accuracy: 0.9369\n",
      "Epoch 75/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1774 - accuracy: 0.9505 - val_loss: 0.2198 - val_accuracy: 0.9362\n",
      "Epoch 76/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1759 - accuracy: 0.9509 - val_loss: 0.2224 - val_accuracy: 0.9318\n",
      "Epoch 77/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1750 - accuracy: 0.9505 - val_loss: 0.2199 - val_accuracy: 0.9332\n",
      "Epoch 78/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1737 - accuracy: 0.9513 - val_loss: 0.2236 - val_accuracy: 0.9287\n",
      "Epoch 79/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1732 - accuracy: 0.9506 - val_loss: 0.2193 - val_accuracy: 0.9338\n",
      "Epoch 80/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1721 - accuracy: 0.9517 - val_loss: 0.2189 - val_accuracy: 0.9345\n",
      "Epoch 81/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1710 - accuracy: 0.9531 - val_loss: 0.2195 - val_accuracy: 0.9325\n",
      "Epoch 82/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1698 - accuracy: 0.9533 - val_loss: 0.2156 - val_accuracy: 0.9355\n",
      "Epoch 83/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1692 - accuracy: 0.9521 - val_loss: 0.2180 - val_accuracy: 0.9332\n",
      "Epoch 84/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1684 - accuracy: 0.9531 - val_loss: 0.2111 - val_accuracy: 0.9372\n",
      "Epoch 85/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1673 - accuracy: 0.9531 - val_loss: 0.2187 - val_accuracy: 0.9291\n",
      "Epoch 86/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1662 - accuracy: 0.9538 - val_loss: 0.2111 - val_accuracy: 0.9396\n",
      "Epoch 87/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1660 - accuracy: 0.9532 - val_loss: 0.2218 - val_accuracy: 0.9260\n",
      "Epoch 88/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1649 - accuracy: 0.9543 - val_loss: 0.2122 - val_accuracy: 0.9345\n",
      "Epoch 89/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1641 - accuracy: 0.9540 - val_loss: 0.2080 - val_accuracy: 0.9359\n",
      "Epoch 90/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1632 - accuracy: 0.9536 - val_loss: 0.2101 - val_accuracy: 0.9376\n",
      "Epoch 91/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1627 - accuracy: 0.9540 - val_loss: 0.2087 - val_accuracy: 0.9355\n",
      "Epoch 92/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1618 - accuracy: 0.9551 - val_loss: 0.2091 - val_accuracy: 0.9348\n",
      "Epoch 93/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1606 - accuracy: 0.9554 - val_loss: 0.2053 - val_accuracy: 0.9389\n",
      "Epoch 94/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1603 - accuracy: 0.9550 - val_loss: 0.2066 - val_accuracy: 0.9352\n",
      "Epoch 95/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1593 - accuracy: 0.9578 - val_loss: 0.2058 - val_accuracy: 0.9403\n",
      "Epoch 96/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1590 - accuracy: 0.9567 - val_loss: 0.2099 - val_accuracy: 0.9325\n",
      "Epoch 97/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1579 - accuracy: 0.9572 - val_loss: 0.2053 - val_accuracy: 0.9359\n",
      "Epoch 98/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1567 - accuracy: 0.9569 - val_loss: 0.2020 - val_accuracy: 0.9403\n",
      "Epoch 99/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1563 - accuracy: 0.9574 - val_loss: 0.2075 - val_accuracy: 0.9325\n",
      "Epoch 100/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1557 - accuracy: 0.9574 - val_loss: 0.2026 - val_accuracy: 0.9362\n",
      "Epoch 101/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1547 - accuracy: 0.9584 - val_loss: 0.2006 - val_accuracy: 0.9389\n",
      "Epoch 102/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1542 - accuracy: 0.9582 - val_loss: 0.2054 - val_accuracy: 0.9348\n",
      "Epoch 103/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1537 - accuracy: 0.9580 - val_loss: 0.2004 - val_accuracy: 0.9403\n",
      "Epoch 104/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1527 - accuracy: 0.9582 - val_loss: 0.1986 - val_accuracy: 0.9396\n",
      "Epoch 105/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1525 - accuracy: 0.9573 - val_loss: 0.1994 - val_accuracy: 0.9382\n",
      "Epoch 106/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1514 - accuracy: 0.9596 - val_loss: 0.1997 - val_accuracy: 0.9362\n",
      "Epoch 107/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1511 - accuracy: 0.9577 - val_loss: 0.1968 - val_accuracy: 0.9406\n",
      "Epoch 108/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1503 - accuracy: 0.9569 - val_loss: 0.2056 - val_accuracy: 0.9321\n",
      "Epoch 109/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1498 - accuracy: 0.9585 - val_loss: 0.1997 - val_accuracy: 0.9365\n",
      "Epoch 110/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1490 - accuracy: 0.9603 - val_loss: 0.1979 - val_accuracy: 0.9396\n",
      "Epoch 111/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1491 - accuracy: 0.9588 - val_loss: 0.2002 - val_accuracy: 0.9369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1480 - accuracy: 0.9601 - val_loss: 0.2030 - val_accuracy: 0.9345\n",
      "Epoch 113/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1476 - accuracy: 0.9592 - val_loss: 0.1966 - val_accuracy: 0.9376\n",
      "Epoch 114/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1468 - accuracy: 0.9601 - val_loss: 0.1979 - val_accuracy: 0.9355\n",
      "Epoch 115/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1462 - accuracy: 0.9608 - val_loss: 0.1936 - val_accuracy: 0.9423\n",
      "Epoch 116/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1455 - accuracy: 0.9603 - val_loss: 0.1935 - val_accuracy: 0.9406\n",
      "Epoch 117/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1454 - accuracy: 0.9597 - val_loss: 0.1943 - val_accuracy: 0.9403\n",
      "Epoch 118/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1447 - accuracy: 0.9616 - val_loss: 0.1943 - val_accuracy: 0.9369\n",
      "Epoch 119/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1440 - accuracy: 0.9612 - val_loss: 0.1988 - val_accuracy: 0.9345\n",
      "Epoch 120/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1432 - accuracy: 0.9614 - val_loss: 0.1924 - val_accuracy: 0.9410\n",
      "Epoch 121/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1428 - accuracy: 0.9607 - val_loss: 0.1916 - val_accuracy: 0.9410\n",
      "Epoch 122/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1424 - accuracy: 0.9610 - val_loss: 0.1931 - val_accuracy: 0.9365\n",
      "Epoch 123/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1418 - accuracy: 0.9621 - val_loss: 0.1986 - val_accuracy: 0.9352\n",
      "Epoch 124/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1414 - accuracy: 0.9612 - val_loss: 0.1896 - val_accuracy: 0.9420\n",
      "Epoch 125/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1409 - accuracy: 0.9618 - val_loss: 0.1932 - val_accuracy: 0.9379\n",
      "Epoch 126/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1400 - accuracy: 0.9630 - val_loss: 0.1888 - val_accuracy: 0.9423\n",
      "Epoch 127/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1398 - accuracy: 0.9612 - val_loss: 0.1905 - val_accuracy: 0.9396\n",
      "Epoch 128/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1395 - accuracy: 0.9618 - val_loss: 0.1908 - val_accuracy: 0.9389\n",
      "Epoch 129/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1385 - accuracy: 0.9631 - val_loss: 0.1872 - val_accuracy: 0.9430\n",
      "Epoch 130/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1384 - accuracy: 0.9626 - val_loss: 0.1858 - val_accuracy: 0.9433\n",
      "Epoch 131/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1379 - accuracy: 0.9629 - val_loss: 0.1901 - val_accuracy: 0.9396\n",
      "Epoch 132/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1374 - accuracy: 0.9621 - val_loss: 0.1916 - val_accuracy: 0.9379\n",
      "Epoch 133/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1367 - accuracy: 0.9627 - val_loss: 0.1856 - val_accuracy: 0.9430\n",
      "Epoch 134/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1364 - accuracy: 0.9626 - val_loss: 0.1865 - val_accuracy: 0.9413\n",
      "Epoch 135/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1360 - accuracy: 0.9631 - val_loss: 0.1857 - val_accuracy: 0.9440\n",
      "Epoch 136/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1357 - accuracy: 0.9635 - val_loss: 0.1849 - val_accuracy: 0.9437\n",
      "Epoch 137/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1352 - accuracy: 0.9625 - val_loss: 0.1852 - val_accuracy: 0.9440\n",
      "Epoch 138/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1346 - accuracy: 0.9627 - val_loss: 0.1839 - val_accuracy: 0.9444\n",
      "Epoch 139/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1343 - accuracy: 0.9637 - val_loss: 0.1853 - val_accuracy: 0.9399\n",
      "Epoch 140/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1336 - accuracy: 0.9638 - val_loss: 0.1835 - val_accuracy: 0.9437\n",
      "Epoch 141/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1333 - accuracy: 0.9638 - val_loss: 0.1840 - val_accuracy: 0.9430\n",
      "Epoch 142/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1330 - accuracy: 0.9626 - val_loss: 0.1835 - val_accuracy: 0.9440\n",
      "Epoch 143/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1325 - accuracy: 0.9642 - val_loss: 0.1824 - val_accuracy: 0.9433\n",
      "Epoch 144/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1322 - accuracy: 0.9648 - val_loss: 0.1826 - val_accuracy: 0.9437\n",
      "Epoch 145/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1316 - accuracy: 0.9638 - val_loss: 0.1828 - val_accuracy: 0.9433\n",
      "Epoch 146/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1314 - accuracy: 0.9638 - val_loss: 0.1854 - val_accuracy: 0.9410\n",
      "Epoch 147/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1307 - accuracy: 0.9646 - val_loss: 0.1816 - val_accuracy: 0.9444\n",
      "Epoch 148/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1307 - accuracy: 0.9645 - val_loss: 0.1812 - val_accuracy: 0.9450\n",
      "Epoch 149/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1300 - accuracy: 0.9657 - val_loss: 0.1806 - val_accuracy: 0.9444\n",
      "Epoch 150/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1297 - accuracy: 0.9653 - val_loss: 0.1814 - val_accuracy: 0.9427\n",
      "Epoch 151/400\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.96 - 0s 39us/step - loss: 0.1292 - accuracy: 0.9655 - val_loss: 0.1811 - val_accuracy: 0.9413\n",
      "Epoch 152/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1291 - accuracy: 0.9649 - val_loss: 0.1834 - val_accuracy: 0.9403\n",
      "Epoch 153/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1285 - accuracy: 0.9655 - val_loss: 0.1780 - val_accuracy: 0.9454\n",
      "Epoch 154/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1280 - accuracy: 0.9649 - val_loss: 0.1850 - val_accuracy: 0.9389\n",
      "Epoch 155/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1278 - accuracy: 0.9660 - val_loss: 0.1781 - val_accuracy: 0.9450\n",
      "Epoch 156/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1273 - accuracy: 0.9650 - val_loss: 0.1806 - val_accuracy: 0.9416\n",
      "Epoch 157/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1270 - accuracy: 0.9655 - val_loss: 0.1784 - val_accuracy: 0.9450\n",
      "Epoch 158/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1268 - accuracy: 0.9652 - val_loss: 0.1807 - val_accuracy: 0.9427\n",
      "Epoch 159/400\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.96 - 0s 40us/step - loss: 0.1265 - accuracy: 0.9653 - val_loss: 0.1837 - val_accuracy: 0.9386\n",
      "Epoch 160/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1259 - accuracy: 0.9653 - val_loss: 0.1778 - val_accuracy: 0.9444\n",
      "Epoch 161/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1257 - accuracy: 0.9648 - val_loss: 0.1820 - val_accuracy: 0.9393\n",
      "Epoch 162/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1253 - accuracy: 0.9660 - val_loss: 0.1783 - val_accuracy: 0.9430\n",
      "Epoch 163/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1248 - accuracy: 0.9667 - val_loss: 0.1768 - val_accuracy: 0.9440\n",
      "Epoch 164/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1246 - accuracy: 0.9661 - val_loss: 0.1764 - val_accuracy: 0.9440\n",
      "Epoch 165/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1242 - accuracy: 0.9659 - val_loss: 0.1750 - val_accuracy: 0.9460\n",
      "Epoch 166/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1241 - accuracy: 0.9664 - val_loss: 0.1752 - val_accuracy: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1236 - accuracy: 0.9674 - val_loss: 0.1754 - val_accuracy: 0.9460\n",
      "Epoch 168/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1232 - accuracy: 0.9675 - val_loss: 0.1752 - val_accuracy: 0.9450\n",
      "Epoch 169/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1235 - accuracy: 0.9665 - val_loss: 0.1791 - val_accuracy: 0.9416\n",
      "Epoch 170/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1227 - accuracy: 0.9674 - val_loss: 0.1815 - val_accuracy: 0.9389\n",
      "Epoch 171/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1222 - accuracy: 0.9669 - val_loss: 0.1763 - val_accuracy: 0.9430\n",
      "Epoch 172/400\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1220 - accuracy: 0.9664 - val_loss: 0.1749 - val_accuracy: 0.9437\n",
      "Epoch 173/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1216 - accuracy: 0.9683 - val_loss: 0.1743 - val_accuracy: 0.9457\n",
      "Epoch 174/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1216 - accuracy: 0.9671 - val_loss: 0.1746 - val_accuracy: 0.9464\n",
      "Epoch 175/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1209 - accuracy: 0.9682 - val_loss: 0.1783 - val_accuracy: 0.9396\n",
      "Epoch 176/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1208 - accuracy: 0.9683 - val_loss: 0.1789 - val_accuracy: 0.9389\n",
      "Epoch 177/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1205 - accuracy: 0.9676 - val_loss: 0.1782 - val_accuracy: 0.9399\n",
      "Epoch 178/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1201 - accuracy: 0.9687 - val_loss: 0.1779 - val_accuracy: 0.9406\n",
      "Epoch 179/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1197 - accuracy: 0.9684 - val_loss: 0.1729 - val_accuracy: 0.9460\n",
      "Epoch 180/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1195 - accuracy: 0.9675 - val_loss: 0.1748 - val_accuracy: 0.9454\n",
      "Epoch 181/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1192 - accuracy: 0.9690 - val_loss: 0.1723 - val_accuracy: 0.9444\n",
      "Epoch 182/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1189 - accuracy: 0.9676 - val_loss: 0.1753 - val_accuracy: 0.9444\n",
      "Epoch 183/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1184 - accuracy: 0.9691 - val_loss: 0.1736 - val_accuracy: 0.9437\n",
      "Epoch 184/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1182 - accuracy: 0.9682 - val_loss: 0.1729 - val_accuracy: 0.9454\n",
      "Epoch 185/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1183 - accuracy: 0.9676 - val_loss: 0.1707 - val_accuracy: 0.9457\n",
      "Epoch 186/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1177 - accuracy: 0.9682 - val_loss: 0.1698 - val_accuracy: 0.9484\n",
      "Epoch 187/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1175 - accuracy: 0.9686 - val_loss: 0.1708 - val_accuracy: 0.9457\n",
      "Epoch 188/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1171 - accuracy: 0.9697 - val_loss: 0.1710 - val_accuracy: 0.9454\n",
      "Epoch 189/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1172 - accuracy: 0.9691 - val_loss: 0.1701 - val_accuracy: 0.9460\n",
      "Epoch 190/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1164 - accuracy: 0.9690 - val_loss: 0.1708 - val_accuracy: 0.9454\n",
      "Epoch 191/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1162 - accuracy: 0.9697 - val_loss: 0.1693 - val_accuracy: 0.9471\n",
      "Epoch 192/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1163 - accuracy: 0.9698 - val_loss: 0.1712 - val_accuracy: 0.9430\n",
      "Epoch 193/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1155 - accuracy: 0.9697 - val_loss: 0.1708 - val_accuracy: 0.9460\n",
      "Epoch 194/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1153 - accuracy: 0.9698 - val_loss: 0.1689 - val_accuracy: 0.9467\n",
      "Epoch 195/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1154 - accuracy: 0.9698 - val_loss: 0.1695 - val_accuracy: 0.9457\n",
      "Epoch 196/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1150 - accuracy: 0.9695 - val_loss: 0.1708 - val_accuracy: 0.9450\n",
      "Epoch 197/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1148 - accuracy: 0.9701 - val_loss: 0.1680 - val_accuracy: 0.9467\n",
      "Epoch 198/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1144 - accuracy: 0.9699 - val_loss: 0.1672 - val_accuracy: 0.9498\n",
      "Epoch 199/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1140 - accuracy: 0.9697 - val_loss: 0.1696 - val_accuracy: 0.9467\n",
      "Epoch 200/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1140 - accuracy: 0.9699 - val_loss: 0.1688 - val_accuracy: 0.9460\n",
      "Epoch 201/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1136 - accuracy: 0.9703 - val_loss: 0.1671 - val_accuracy: 0.9471\n",
      "Epoch 202/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1133 - accuracy: 0.9698 - val_loss: 0.1696 - val_accuracy: 0.9454\n",
      "Epoch 203/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1130 - accuracy: 0.9701 - val_loss: 0.1692 - val_accuracy: 0.9460\n",
      "Epoch 204/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1129 - accuracy: 0.9708 - val_loss: 0.1694 - val_accuracy: 0.9460\n",
      "Epoch 205/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1126 - accuracy: 0.9694 - val_loss: 0.1680 - val_accuracy: 0.9457\n",
      "Epoch 206/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1125 - accuracy: 0.9708 - val_loss: 0.1672 - val_accuracy: 0.9454\n",
      "Epoch 207/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1123 - accuracy: 0.9705 - val_loss: 0.1750 - val_accuracy: 0.9393\n",
      "Epoch 208/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1120 - accuracy: 0.9705 - val_loss: 0.1678 - val_accuracy: 0.9467\n",
      "Epoch 209/400\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.97 - 0s 40us/step - loss: 0.1113 - accuracy: 0.9712 - val_loss: 0.1652 - val_accuracy: 0.9484\n",
      "Epoch 210/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1118 - accuracy: 0.9699 - val_loss: 0.1664 - val_accuracy: 0.9467\n",
      "Epoch 211/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1112 - accuracy: 0.9717 - val_loss: 0.1723 - val_accuracy: 0.9406\n",
      "Epoch 212/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1109 - accuracy: 0.9713 - val_loss: 0.1667 - val_accuracy: 0.9444\n",
      "Epoch 213/400\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.1110 - accuracy: 0.9713 - val_loss: 0.1662 - val_accuracy: 0.9460\n",
      "Epoch 214/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1103 - accuracy: 0.9708 - val_loss: 0.1684 - val_accuracy: 0.9450\n",
      "Epoch 215/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1101 - accuracy: 0.9709 - val_loss: 0.1662 - val_accuracy: 0.9471\n",
      "Epoch 216/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1102 - accuracy: 0.9708 - val_loss: 0.1678 - val_accuracy: 0.9457\n",
      "Epoch 217/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1097 - accuracy: 0.9714 - val_loss: 0.1643 - val_accuracy: 0.9474\n",
      "Epoch 218/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1096 - accuracy: 0.9710 - val_loss: 0.1653 - val_accuracy: 0.9454\n",
      "Epoch 219/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1093 - accuracy: 0.9710 - val_loss: 0.1644 - val_accuracy: 0.9464\n",
      "Epoch 220/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1090 - accuracy: 0.9709 - val_loss: 0.1655 - val_accuracy: 0.9454\n",
      "Epoch 221/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1086 - accuracy: 0.9724 - val_loss: 0.1635 - val_accuracy: 0.9484\n",
      "Epoch 222/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1086 - accuracy: 0.9703 - val_loss: 0.1635 - val_accuracy: 0.9471\n",
      "Epoch 223/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1085 - accuracy: 0.9712 - val_loss: 0.1644 - val_accuracy: 0.9467\n",
      "Epoch 224/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1083 - accuracy: 0.9705 - val_loss: 0.1698 - val_accuracy: 0.9413\n",
      "Epoch 225/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1080 - accuracy: 0.9713 - val_loss: 0.1638 - val_accuracy: 0.9464\n",
      "Epoch 226/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1078 - accuracy: 0.9713 - val_loss: 0.1637 - val_accuracy: 0.9474\n",
      "Epoch 227/400\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.1076 - accuracy: 0.9708 - val_loss: 0.1617 - val_accuracy: 0.9505\n",
      "Epoch 228/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1073 - accuracy: 0.9714 - val_loss: 0.1625 - val_accuracy: 0.9481\n",
      "Epoch 229/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1071 - accuracy: 0.9724 - val_loss: 0.1652 - val_accuracy: 0.9467\n",
      "Epoch 230/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1069 - accuracy: 0.9718 - val_loss: 0.1661 - val_accuracy: 0.9454\n",
      "Epoch 231/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1069 - accuracy: 0.9723 - val_loss: 0.1634 - val_accuracy: 0.9460\n",
      "Epoch 232/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1064 - accuracy: 0.9714 - val_loss: 0.1616 - val_accuracy: 0.9481\n",
      "Epoch 233/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1064 - accuracy: 0.9725 - val_loss: 0.1692 - val_accuracy: 0.9406\n",
      "Epoch 234/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1060 - accuracy: 0.9713 - val_loss: 0.1650 - val_accuracy: 0.9464\n",
      "Epoch 235/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1059 - accuracy: 0.9728 - val_loss: 0.1621 - val_accuracy: 0.9471\n",
      "Epoch 236/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1057 - accuracy: 0.9732 - val_loss: 0.1627 - val_accuracy: 0.9474\n",
      "Epoch 237/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1057 - accuracy: 0.9714 - val_loss: 0.1627 - val_accuracy: 0.9464\n",
      "Epoch 238/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1051 - accuracy: 0.9723 - val_loss: 0.1607 - val_accuracy: 0.9484\n",
      "Epoch 239/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1051 - accuracy: 0.9735 - val_loss: 0.1667 - val_accuracy: 0.9433\n",
      "Epoch 240/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1049 - accuracy: 0.9720 - val_loss: 0.1618 - val_accuracy: 0.9477\n",
      "Epoch 241/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1045 - accuracy: 0.9724 - val_loss: 0.1608 - val_accuracy: 0.9481\n",
      "Epoch 242/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1045 - accuracy: 0.9724 - val_loss: 0.1610 - val_accuracy: 0.9477\n",
      "Epoch 243/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1043 - accuracy: 0.9731 - val_loss: 0.1603 - val_accuracy: 0.9488\n",
      "Epoch 244/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1041 - accuracy: 0.9733 - val_loss: 0.1613 - val_accuracy: 0.9474\n",
      "Epoch 245/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1038 - accuracy: 0.9720 - val_loss: 0.1631 - val_accuracy: 0.9460\n",
      "Epoch 246/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1036 - accuracy: 0.9729 - val_loss: 0.1606 - val_accuracy: 0.9488\n",
      "Epoch 247/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1035 - accuracy: 0.9729 - val_loss: 0.1619 - val_accuracy: 0.9460\n",
      "Epoch 248/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1034 - accuracy: 0.9723 - val_loss: 0.1621 - val_accuracy: 0.9464\n",
      "Epoch 249/400\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.97 - 0s 39us/step - loss: 0.1030 - accuracy: 0.9727 - val_loss: 0.1610 - val_accuracy: 0.9467\n",
      "Epoch 250/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1030 - accuracy: 0.9742 - val_loss: 0.1639 - val_accuracy: 0.9447\n",
      "Epoch 251/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1028 - accuracy: 0.9728 - val_loss: 0.1615 - val_accuracy: 0.9471\n",
      "Epoch 252/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1026 - accuracy: 0.9729 - val_loss: 0.1600 - val_accuracy: 0.9474\n",
      "Epoch 253/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1027 - accuracy: 0.9735 - val_loss: 0.1609 - val_accuracy: 0.9471\n",
      "Epoch 254/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1022 - accuracy: 0.9742 - val_loss: 0.1636 - val_accuracy: 0.9454\n",
      "Epoch 255/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1022 - accuracy: 0.9720 - val_loss: 0.1582 - val_accuracy: 0.9494\n",
      "Epoch 256/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1019 - accuracy: 0.9739 - val_loss: 0.1582 - val_accuracy: 0.9477\n",
      "Epoch 257/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1016 - accuracy: 0.9742 - val_loss: 0.1585 - val_accuracy: 0.9481\n",
      "Epoch 258/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1013 - accuracy: 0.9731 - val_loss: 0.1594 - val_accuracy: 0.9491\n",
      "Epoch 259/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1014 - accuracy: 0.9736 - val_loss: 0.1578 - val_accuracy: 0.9491\n",
      "Epoch 260/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1014 - accuracy: 0.9733 - val_loss: 0.1615 - val_accuracy: 0.9464\n",
      "Epoch 261/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1011 - accuracy: 0.9746 - val_loss: 0.1584 - val_accuracy: 0.9491\n",
      "Epoch 262/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1008 - accuracy: 0.9729 - val_loss: 0.1609 - val_accuracy: 0.9477\n",
      "Epoch 263/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1008 - accuracy: 0.9743 - val_loss: 0.1604 - val_accuracy: 0.9481\n",
      "Epoch 264/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1004 - accuracy: 0.9737 - val_loss: 0.1597 - val_accuracy: 0.9484\n",
      "Epoch 265/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1002 - accuracy: 0.9746 - val_loss: 0.1568 - val_accuracy: 0.9505\n",
      "Epoch 266/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1003 - accuracy: 0.9751 - val_loss: 0.1571 - val_accuracy: 0.9494\n",
      "Epoch 267/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1001 - accuracy: 0.9743 - val_loss: 0.1583 - val_accuracy: 0.9488\n",
      "Epoch 268/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0998 - accuracy: 0.9743 - val_loss: 0.1565 - val_accuracy: 0.9505\n",
      "Epoch 269/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0996 - accuracy: 0.9739 - val_loss: 0.1570 - val_accuracy: 0.9498\n",
      "Epoch 270/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0994 - accuracy: 0.9744 - val_loss: 0.1581 - val_accuracy: 0.9484\n",
      "Epoch 271/400\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.0992 - accuracy: 0.9750 - val_loss: 0.1578 - val_accuracy: 0.9491\n",
      "Epoch 272/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0990 - accuracy: 0.9747 - val_loss: 0.1648 - val_accuracy: 0.9440\n",
      "Epoch 273/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0989 - accuracy: 0.9746 - val_loss: 0.1568 - val_accuracy: 0.9494\n",
      "Epoch 274/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0988 - accuracy: 0.9748 - val_loss: 0.1637 - val_accuracy: 0.9433\n",
      "Epoch 275/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0983 - accuracy: 0.9740 - val_loss: 0.1552 - val_accuracy: 0.9518\n",
      "Epoch 276/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0986 - accuracy: 0.9744 - val_loss: 0.1567 - val_accuracy: 0.9494\n",
      "Epoch 277/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0981 - accuracy: 0.9746 - val_loss: 0.1557 - val_accuracy: 0.9515\n",
      "Epoch 278/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0982 - accuracy: 0.9743 - val_loss: 0.1576 - val_accuracy: 0.9491\n",
      "Epoch 279/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0979 - accuracy: 0.9747 - val_loss: 0.1565 - val_accuracy: 0.9494\n",
      "Epoch 280/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0978 - accuracy: 0.9754 - val_loss: 0.1591 - val_accuracy: 0.9481\n",
      "Epoch 281/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0975 - accuracy: 0.9751 - val_loss: 0.1588 - val_accuracy: 0.9467\n",
      "Epoch 282/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0976 - accuracy: 0.9757 - val_loss: 0.1570 - val_accuracy: 0.9491\n",
      "Epoch 283/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0975 - accuracy: 0.9746 - val_loss: 0.1573 - val_accuracy: 0.9488\n",
      "Epoch 284/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0972 - accuracy: 0.9748 - val_loss: 0.1575 - val_accuracy: 0.9488\n",
      "Epoch 285/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0969 - accuracy: 0.9746 - val_loss: 0.1564 - val_accuracy: 0.9484\n",
      "Epoch 286/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0968 - accuracy: 0.9746 - val_loss: 0.1546 - val_accuracy: 0.9515\n",
      "Epoch 287/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0970 - accuracy: 0.9752 - val_loss: 0.1561 - val_accuracy: 0.9494\n",
      "Epoch 288/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0963 - accuracy: 0.9757 - val_loss: 0.1553 - val_accuracy: 0.9508\n",
      "Epoch 289/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0966 - accuracy: 0.9755 - val_loss: 0.1563 - val_accuracy: 0.9494\n",
      "Epoch 290/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0964 - accuracy: 0.9750 - val_loss: 0.1567 - val_accuracy: 0.9488\n",
      "Epoch 291/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0962 - accuracy: 0.9761 - val_loss: 0.1529 - val_accuracy: 0.9522\n",
      "Epoch 292/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0962 - accuracy: 0.9751 - val_loss: 0.1551 - val_accuracy: 0.9501\n",
      "Epoch 293/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0962 - accuracy: 0.9751 - val_loss: 0.1549 - val_accuracy: 0.9494\n",
      "Epoch 294/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0959 - accuracy: 0.9751 - val_loss: 0.1555 - val_accuracy: 0.9481\n",
      "Epoch 295/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0957 - accuracy: 0.9754 - val_loss: 0.1544 - val_accuracy: 0.9494\n",
      "Epoch 296/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0954 - accuracy: 0.9743 - val_loss: 0.1567 - val_accuracy: 0.9484\n",
      "Epoch 297/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0952 - accuracy: 0.9751 - val_loss: 0.1557 - val_accuracy: 0.9484\n",
      "Epoch 298/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0954 - accuracy: 0.9758 - val_loss: 0.1576 - val_accuracy: 0.9484\n",
      "Epoch 299/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0952 - accuracy: 0.9758 - val_loss: 0.1568 - val_accuracy: 0.9488\n",
      "Epoch 300/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0948 - accuracy: 0.9757 - val_loss: 0.1587 - val_accuracy: 0.9474\n",
      "Epoch 301/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0947 - accuracy: 0.9757 - val_loss: 0.1536 - val_accuracy: 0.9494\n",
      "Epoch 302/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0946 - accuracy: 0.9763 - val_loss: 0.1540 - val_accuracy: 0.9491\n",
      "Epoch 303/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0943 - accuracy: 0.9761 - val_loss: 0.1554 - val_accuracy: 0.9494\n",
      "Epoch 304/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0942 - accuracy: 0.9755 - val_loss: 0.1531 - val_accuracy: 0.9518\n",
      "Epoch 305/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0942 - accuracy: 0.9766 - val_loss: 0.1557 - val_accuracy: 0.9491\n",
      "Epoch 306/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0937 - accuracy: 0.9754 - val_loss: 0.1562 - val_accuracy: 0.9484\n",
      "Epoch 307/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0939 - accuracy: 0.9761 - val_loss: 0.1556 - val_accuracy: 0.9488\n",
      "Epoch 308/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0937 - accuracy: 0.9754 - val_loss: 0.1539 - val_accuracy: 0.9501\n",
      "Epoch 309/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0937 - accuracy: 0.9759 - val_loss: 0.1548 - val_accuracy: 0.9494\n",
      "Epoch 310/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0937 - accuracy: 0.9765 - val_loss: 0.1549 - val_accuracy: 0.9494\n",
      "Epoch 311/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0935 - accuracy: 0.9761 - val_loss: 0.1534 - val_accuracy: 0.9505\n",
      "Epoch 312/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0931 - accuracy: 0.9766 - val_loss: 0.1564 - val_accuracy: 0.9484\n",
      "Epoch 313/400\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.97 - 0s 39us/step - loss: 0.0932 - accuracy: 0.9759 - val_loss: 0.1512 - val_accuracy: 0.9522\n",
      "Epoch 314/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0930 - accuracy: 0.9766 - val_loss: 0.1569 - val_accuracy: 0.9484\n",
      "Epoch 315/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0929 - accuracy: 0.9761 - val_loss: 0.1528 - val_accuracy: 0.9508\n",
      "Epoch 316/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0926 - accuracy: 0.9767 - val_loss: 0.1548 - val_accuracy: 0.9494\n",
      "Epoch 317/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0923 - accuracy: 0.9771 - val_loss: 0.1537 - val_accuracy: 0.9498\n",
      "Epoch 318/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0924 - accuracy: 0.9769 - val_loss: 0.1511 - val_accuracy: 0.9522\n",
      "Epoch 319/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0923 - accuracy: 0.9771 - val_loss: 0.1578 - val_accuracy: 0.9467\n",
      "Epoch 320/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0920 - accuracy: 0.9762 - val_loss: 0.1506 - val_accuracy: 0.9528\n",
      "Epoch 321/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0918 - accuracy: 0.9769 - val_loss: 0.1511 - val_accuracy: 0.9532\n",
      "Epoch 322/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0918 - accuracy: 0.9771 - val_loss: 0.1522 - val_accuracy: 0.9508\n",
      "Epoch 323/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0919 - accuracy: 0.9778 - val_loss: 0.1545 - val_accuracy: 0.9488\n",
      "Epoch 324/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0916 - accuracy: 0.9763 - val_loss: 0.1534 - val_accuracy: 0.9498\n",
      "Epoch 325/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0916 - accuracy: 0.9766 - val_loss: 0.1514 - val_accuracy: 0.9515\n",
      "Epoch 326/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0913 - accuracy: 0.9769 - val_loss: 0.1543 - val_accuracy: 0.9494\n",
      "Epoch 327/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0914 - accuracy: 0.9766 - val_loss: 0.1515 - val_accuracy: 0.9511\n",
      "Epoch 328/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0911 - accuracy: 0.9766 - val_loss: 0.1517 - val_accuracy: 0.9508\n",
      "Epoch 329/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0910 - accuracy: 0.9769 - val_loss: 0.1523 - val_accuracy: 0.9498\n",
      "Epoch 330/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0909 - accuracy: 0.9769 - val_loss: 0.1518 - val_accuracy: 0.9498\n",
      "Epoch 331/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0909 - accuracy: 0.9769 - val_loss: 0.1538 - val_accuracy: 0.9491\n",
      "Epoch 332/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0906 - accuracy: 0.9766 - val_loss: 0.1534 - val_accuracy: 0.9488\n",
      "Epoch 333/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0905 - accuracy: 0.9769 - val_loss: 0.1513 - val_accuracy: 0.9501\n",
      "Epoch 334/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0904 - accuracy: 0.9763 - val_loss: 0.1562 - val_accuracy: 0.9477\n",
      "Epoch 335/400\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.0903 - accuracy: 0.9771 - val_loss: 0.1514 - val_accuracy: 0.9501\n",
      "Epoch 336/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0901 - accuracy: 0.9778 - val_loss: 0.1524 - val_accuracy: 0.9508\n",
      "Epoch 337/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0902 - accuracy: 0.9773 - val_loss: 0.1514 - val_accuracy: 0.9505\n",
      "Epoch 338/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0899 - accuracy: 0.9767 - val_loss: 0.1549 - val_accuracy: 0.9488\n",
      "Epoch 339/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0897 - accuracy: 0.9771 - val_loss: 0.1537 - val_accuracy: 0.9491\n",
      "Epoch 340/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0898 - accuracy: 0.9766 - val_loss: 0.1502 - val_accuracy: 0.9518\n",
      "Epoch 341/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0896 - accuracy: 0.9769 - val_loss: 0.1533 - val_accuracy: 0.9494\n",
      "Epoch 342/400\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.97 - 0s 38us/step - loss: 0.0895 - accuracy: 0.9770 - val_loss: 0.1495 - val_accuracy: 0.9525\n",
      "Epoch 343/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0895 - accuracy: 0.9774 - val_loss: 0.1543 - val_accuracy: 0.9491\n",
      "Epoch 344/400\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0893 - accuracy: 0.9766 - val_loss: 0.1526 - val_accuracy: 0.9494\n",
      "Epoch 345/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0891 - accuracy: 0.9770 - val_loss: 0.1487 - val_accuracy: 0.9535\n",
      "Epoch 346/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0890 - accuracy: 0.9784 - val_loss: 0.1542 - val_accuracy: 0.9491\n",
      "Epoch 347/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0886 - accuracy: 0.9778 - val_loss: 0.1505 - val_accuracy: 0.9508\n",
      "Epoch 348/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0888 - accuracy: 0.9774 - val_loss: 0.1514 - val_accuracy: 0.9498\n",
      "Epoch 349/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0886 - accuracy: 0.9771 - val_loss: 0.1492 - val_accuracy: 0.9522\n",
      "Epoch 350/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0885 - accuracy: 0.9770 - val_loss: 0.1552 - val_accuracy: 0.9484\n",
      "Epoch 351/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0886 - accuracy: 0.9780 - val_loss: 0.1498 - val_accuracy: 0.9518\n",
      "Epoch 352/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0883 - accuracy: 0.9780 - val_loss: 0.1492 - val_accuracy: 0.9515\n",
      "Epoch 353/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0883 - accuracy: 0.9773 - val_loss: 0.1490 - val_accuracy: 0.9518\n",
      "Epoch 354/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0880 - accuracy: 0.9769 - val_loss: 0.1482 - val_accuracy: 0.9539\n",
      "Epoch 355/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0879 - accuracy: 0.9767 - val_loss: 0.1503 - val_accuracy: 0.9515\n",
      "Epoch 356/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0878 - accuracy: 0.9776 - val_loss: 0.1552 - val_accuracy: 0.9484\n",
      "Epoch 357/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0879 - accuracy: 0.9780 - val_loss: 0.1492 - val_accuracy: 0.9515\n",
      "Epoch 358/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0877 - accuracy: 0.9782 - val_loss: 0.1517 - val_accuracy: 0.9494\n",
      "Epoch 359/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0875 - accuracy: 0.9771 - val_loss: 0.1532 - val_accuracy: 0.9494\n",
      "Epoch 360/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0875 - accuracy: 0.9777 - val_loss: 0.1477 - val_accuracy: 0.9528\n",
      "Epoch 361/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0875 - accuracy: 0.9774 - val_loss: 0.1500 - val_accuracy: 0.9505\n",
      "Epoch 362/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0869 - accuracy: 0.9781 - val_loss: 0.1479 - val_accuracy: 0.9539\n",
      "Epoch 363/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0871 - accuracy: 0.9777 - val_loss: 0.1488 - val_accuracy: 0.9525\n",
      "Epoch 364/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0870 - accuracy: 0.9778 - val_loss: 0.1485 - val_accuracy: 0.9525\n",
      "Epoch 365/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0870 - accuracy: 0.9776 - val_loss: 0.1479 - val_accuracy: 0.9525\n",
      "Epoch 366/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0868 - accuracy: 0.9777 - val_loss: 0.1495 - val_accuracy: 0.9511\n",
      "Epoch 367/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0866 - accuracy: 0.9778 - val_loss: 0.1483 - val_accuracy: 0.9515\n",
      "Epoch 368/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0867 - accuracy: 0.9784 - val_loss: 0.1486 - val_accuracy: 0.9518\n",
      "Epoch 369/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0864 - accuracy: 0.9778 - val_loss: 0.1491 - val_accuracy: 0.9518\n",
      "Epoch 370/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0864 - accuracy: 0.9778 - val_loss: 0.1490 - val_accuracy: 0.9515\n",
      "Epoch 371/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0863 - accuracy: 0.9780 - val_loss: 0.1469 - val_accuracy: 0.9542\n",
      "Epoch 372/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0863 - accuracy: 0.9785 - val_loss: 0.1495 - val_accuracy: 0.9508\n",
      "Epoch 373/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0861 - accuracy: 0.9778 - val_loss: 0.1467 - val_accuracy: 0.9535\n",
      "Epoch 374/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0858 - accuracy: 0.9782 - val_loss: 0.1474 - val_accuracy: 0.9539\n",
      "Epoch 375/400\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0859 - accuracy: 0.9778 - val_loss: 0.1517 - val_accuracy: 0.9491\n",
      "Epoch 376/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0859 - accuracy: 0.9780 - val_loss: 0.1497 - val_accuracy: 0.9511\n",
      "Epoch 377/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0856 - accuracy: 0.9784 - val_loss: 0.1473 - val_accuracy: 0.9522\n",
      "Epoch 378/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0854 - accuracy: 0.9781 - val_loss: 0.1585 - val_accuracy: 0.9464\n",
      "Epoch 379/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0855 - accuracy: 0.9784 - val_loss: 0.1474 - val_accuracy: 0.9511\n",
      "Epoch 380/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0854 - accuracy: 0.9786 - val_loss: 0.1482 - val_accuracy: 0.9515\n",
      "Epoch 381/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0852 - accuracy: 0.9785 - val_loss: 0.1469 - val_accuracy: 0.9518\n",
      "Epoch 382/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0852 - accuracy: 0.9784 - val_loss: 0.1488 - val_accuracy: 0.9508\n",
      "Epoch 383/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0849 - accuracy: 0.9780 - val_loss: 0.1459 - val_accuracy: 0.9535\n",
      "Epoch 384/400\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0850 - accuracy: 0.9781 - val_loss: 0.1518 - val_accuracy: 0.9494\n",
      "Epoch 385/400\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0848 - accuracy: 0.9777 - val_loss: 0.1480 - val_accuracy: 0.9525\n",
      "Epoch 386/400\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.1478 - val_accuracy: 0.9511\n",
      "Epoch 387/400\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0846 - accuracy: 0.9777 - val_loss: 0.1504 - val_accuracy: 0.9505\n",
      "Epoch 388/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0846 - accuracy: 0.9782 - val_loss: 0.1464 - val_accuracy: 0.9539\n",
      "Epoch 389/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0845 - accuracy: 0.9789 - val_loss: 0.1485 - val_accuracy: 0.9515\n",
      "Epoch 390/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0844 - accuracy: 0.9785 - val_loss: 0.1490 - val_accuracy: 0.9515\n",
      "Epoch 391/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0844 - accuracy: 0.9777 - val_loss: 0.1493 - val_accuracy: 0.9505\n",
      "Epoch 392/400\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0841 - accuracy: 0.9769 - val_loss: 0.1503 - val_accuracy: 0.9505\n",
      "Epoch 393/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0840 - accuracy: 0.9784 - val_loss: 0.1455 - val_accuracy: 0.9539\n",
      "Epoch 394/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0842 - accuracy: 0.9782 - val_loss: 0.1474 - val_accuracy: 0.9515\n",
      "Epoch 395/400\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0839 - accuracy: 0.9781 - val_loss: 0.1521 - val_accuracy: 0.9494\n",
      "Epoch 396/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0838 - accuracy: 0.9784 - val_loss: 0.1476 - val_accuracy: 0.9518\n",
      "Epoch 397/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0838 - accuracy: 0.9782 - val_loss: 0.1461 - val_accuracy: 0.9528\n",
      "Epoch 398/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0838 - accuracy: 0.9785 - val_loss: 0.1496 - val_accuracy: 0.9505\n",
      "Epoch 399/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0836 - accuracy: 0.9793 - val_loss: 0.1466 - val_accuracy: 0.9518\n",
      "Epoch 400/400\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0833 - accuracy: 0.9788 - val_loss: 0.1500 - val_accuracy: 0.9505\n",
      "Test score: 0.1500128983343946\n",
      "Test accuracy: 0.9504581093788147\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=400, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/600\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.3305 - accuracy: 0.4842 - val_loss: 1.0907 - val_accuracy: 0.6281\n",
      "Epoch 2/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.9051 - accuracy: 0.7403 - val_loss: 0.8656 - val_accuracy: 0.7112\n",
      "Epoch 3/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.7438 - accuracy: 0.8123 - val_loss: 0.7324 - val_accuracy: 0.8320\n",
      "Epoch 4/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.6461 - accuracy: 0.8486 - val_loss: 0.6588 - val_accuracy: 0.8205\n",
      "Epoch 5/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.5814 - accuracy: 0.8587 - val_loss: 0.6139 - val_accuracy: 0.7995\n",
      "Epoch 6/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.5333 - accuracy: 0.8697 - val_loss: 0.5654 - val_accuracy: 0.8602\n",
      "Epoch 7/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.4960 - accuracy: 0.8766 - val_loss: 0.5267 - val_accuracy: 0.8666\n",
      "Epoch 8/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.4662 - accuracy: 0.8844 - val_loss: 0.5056 - val_accuracy: 0.8741\n",
      "Epoch 9/600\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.4429 - accuracy: 0.8855 - val_loss: 0.4804 - val_accuracy: 0.8748\n",
      "Epoch 10/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.4221 - accuracy: 0.8906 - val_loss: 0.4715 - val_accuracy: 0.8490\n",
      "Epoch 11/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.4054 - accuracy: 0.8901 - val_loss: 0.4428 - val_accuracy: 0.8846\n",
      "Epoch 12/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3897 - accuracy: 0.8950 - val_loss: 0.4263 - val_accuracy: 0.8901\n",
      "Epoch 13/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.3763 - accuracy: 0.8972 - val_loss: 0.4134 - val_accuracy: 0.8955\n",
      "Epoch 14/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3640 - accuracy: 0.8999 - val_loss: 0.4010 - val_accuracy: 0.8979\n",
      "Epoch 15/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.3532 - accuracy: 0.9011 - val_loss: 0.3923 - val_accuracy: 0.8914\n",
      "Epoch 16/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3438 - accuracy: 0.9041 - val_loss: 0.3942 - val_accuracy: 0.8734\n",
      "Epoch 17/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.3356 - accuracy: 0.9042 - val_loss: 0.3803 - val_accuracy: 0.8921\n",
      "Epoch 18/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3270 - accuracy: 0.9063 - val_loss: 0.3724 - val_accuracy: 0.8924\n",
      "Epoch 19/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3188 - accuracy: 0.9100 - val_loss: 0.3589 - val_accuracy: 0.9091\n",
      "Epoch 20/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3124 - accuracy: 0.9108 - val_loss: 0.3514 - val_accuracy: 0.9019\n",
      "Epoch 21/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.3063 - accuracy: 0.9100 - val_loss: 0.3506 - val_accuracy: 0.9013\n",
      "Epoch 22/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.3000 - accuracy: 0.9136 - val_loss: 0.3352 - val_accuracy: 0.9114\n",
      "Epoch 23/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2942 - accuracy: 0.9151 - val_loss: 0.3313 - val_accuracy: 0.9108\n",
      "Epoch 24/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2894 - accuracy: 0.9165 - val_loss: 0.3369 - val_accuracy: 0.9016\n",
      "Epoch 25/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2844 - accuracy: 0.9172 - val_loss: 0.3242 - val_accuracy: 0.9128\n",
      "Epoch 26/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2793 - accuracy: 0.9202 - val_loss: 0.3209 - val_accuracy: 0.9070\n",
      "Epoch 27/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2755 - accuracy: 0.9204 - val_loss: 0.3124 - val_accuracy: 0.9148\n",
      "Epoch 28/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2707 - accuracy: 0.9226 - val_loss: 0.3132 - val_accuracy: 0.9158\n",
      "Epoch 29/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2671 - accuracy: 0.9217 - val_loss: 0.3069 - val_accuracy: 0.9138\n",
      "Epoch 30/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2631 - accuracy: 0.9253 - val_loss: 0.3119 - val_accuracy: 0.8989\n",
      "Epoch 31/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2596 - accuracy: 0.9268 - val_loss: 0.2997 - val_accuracy: 0.9182\n",
      "Epoch 32/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2562 - accuracy: 0.9252 - val_loss: 0.2957 - val_accuracy: 0.9203\n",
      "Epoch 33/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2531 - accuracy: 0.9280 - val_loss: 0.2979 - val_accuracy: 0.9118\n",
      "Epoch 34/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2496 - accuracy: 0.9268 - val_loss: 0.2858 - val_accuracy: 0.9250\n",
      "Epoch 35/600\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.2470 - accuracy: 0.9264 - val_loss: 0.2857 - val_accuracy: 0.9199\n",
      "Epoch 36/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2435 - accuracy: 0.9297 - val_loss: 0.2902 - val_accuracy: 0.9070\n",
      "Epoch 37/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2408 - accuracy: 0.9302 - val_loss: 0.2773 - val_accuracy: 0.9264\n",
      "Epoch 38/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2383 - accuracy: 0.9319 - val_loss: 0.2807 - val_accuracy: 0.9186\n",
      "Epoch 39/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2351 - accuracy: 0.9312 - val_loss: 0.2752 - val_accuracy: 0.9264\n",
      "Epoch 40/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2325 - accuracy: 0.9323 - val_loss: 0.2815 - val_accuracy: 0.9097\n",
      "Epoch 41/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2304 - accuracy: 0.9344 - val_loss: 0.2785 - val_accuracy: 0.9114\n",
      "Epoch 42/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2278 - accuracy: 0.9350 - val_loss: 0.2691 - val_accuracy: 0.9237\n",
      "Epoch 43/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2256 - accuracy: 0.9350 - val_loss: 0.2673 - val_accuracy: 0.9267\n",
      "Epoch 44/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2230 - accuracy: 0.9362 - val_loss: 0.2652 - val_accuracy: 0.9281\n",
      "Epoch 45/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2215 - accuracy: 0.9359 - val_loss: 0.2623 - val_accuracy: 0.9257\n",
      "Epoch 46/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2192 - accuracy: 0.9378 - val_loss: 0.2658 - val_accuracy: 0.9128\n",
      "Epoch 47/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2171 - accuracy: 0.9385 - val_loss: 0.2577 - val_accuracy: 0.9274\n",
      "Epoch 48/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2152 - accuracy: 0.9378 - val_loss: 0.2554 - val_accuracy: 0.9281\n",
      "Epoch 49/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2133 - accuracy: 0.9396 - val_loss: 0.2542 - val_accuracy: 0.9287\n",
      "Epoch 50/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2111 - accuracy: 0.9406 - val_loss: 0.2607 - val_accuracy: 0.9162\n",
      "Epoch 51/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.2096 - accuracy: 0.9423 - val_loss: 0.2516 - val_accuracy: 0.9260\n",
      "Epoch 52/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2077 - accuracy: 0.9421 - val_loss: 0.2497 - val_accuracy: 0.9284\n",
      "Epoch 53/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2060 - accuracy: 0.9425 - val_loss: 0.2507 - val_accuracy: 0.9213\n",
      "Epoch 54/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.2048 - accuracy: 0.9423 - val_loss: 0.2498 - val_accuracy: 0.9226\n",
      "Epoch 55/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2027 - accuracy: 0.9430 - val_loss: 0.2493 - val_accuracy: 0.9230\n",
      "Epoch 56/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2013 - accuracy: 0.9429 - val_loss: 0.2448 - val_accuracy: 0.9298\n",
      "Epoch 57/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1997 - accuracy: 0.9437 - val_loss: 0.2419 - val_accuracy: 0.9318\n",
      "Epoch 58/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1984 - accuracy: 0.9446 - val_loss: 0.2407 - val_accuracy: 0.9304\n",
      "Epoch 59/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1965 - accuracy: 0.9453 - val_loss: 0.2389 - val_accuracy: 0.9301\n",
      "Epoch 60/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1953 - accuracy: 0.9464 - val_loss: 0.2387 - val_accuracy: 0.9304\n",
      "Epoch 61/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1936 - accuracy: 0.9471 - val_loss: 0.2365 - val_accuracy: 0.9311\n",
      "Epoch 62/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1926 - accuracy: 0.9455 - val_loss: 0.2334 - val_accuracy: 0.9332\n",
      "Epoch 63/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1914 - accuracy: 0.9467 - val_loss: 0.2382 - val_accuracy: 0.9277\n",
      "Epoch 64/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1898 - accuracy: 0.9476 - val_loss: 0.2312 - val_accuracy: 0.9321\n",
      "Epoch 65/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1887 - accuracy: 0.9474 - val_loss: 0.2315 - val_accuracy: 0.9342\n",
      "Epoch 66/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1875 - accuracy: 0.9489 - val_loss: 0.2365 - val_accuracy: 0.9243\n",
      "Epoch 67/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1860 - accuracy: 0.9489 - val_loss: 0.2292 - val_accuracy: 0.9321\n",
      "Epoch 68/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1841 - accuracy: 0.9495 - val_loss: 0.2266 - val_accuracy: 0.9362\n",
      "Epoch 69/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1835 - accuracy: 0.9497 - val_loss: 0.2321 - val_accuracy: 0.9274\n",
      "Epoch 70/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1824 - accuracy: 0.9478 - val_loss: 0.2330 - val_accuracy: 0.9250\n",
      "Epoch 71/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1811 - accuracy: 0.9505 - val_loss: 0.2253 - val_accuracy: 0.9348\n",
      "Epoch 72/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1802 - accuracy: 0.9499 - val_loss: 0.2289 - val_accuracy: 0.9291\n",
      "Epoch 73/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1792 - accuracy: 0.9516 - val_loss: 0.2316 - val_accuracy: 0.9250\n",
      "Epoch 74/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1780 - accuracy: 0.9520 - val_loss: 0.2279 - val_accuracy: 0.9274\n",
      "Epoch 75/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1771 - accuracy: 0.9509 - val_loss: 0.2288 - val_accuracy: 0.9250\n",
      "Epoch 76/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1759 - accuracy: 0.9510 - val_loss: 0.2224 - val_accuracy: 0.9328\n",
      "Epoch 77/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1751 - accuracy: 0.9518 - val_loss: 0.2266 - val_accuracy: 0.9284\n",
      "Epoch 78/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1738 - accuracy: 0.9520 - val_loss: 0.2181 - val_accuracy: 0.9359\n",
      "Epoch 79/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1725 - accuracy: 0.9539 - val_loss: 0.2260 - val_accuracy: 0.9267\n",
      "Epoch 80/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1721 - accuracy: 0.9538 - val_loss: 0.2165 - val_accuracy: 0.9379\n",
      "Epoch 81/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1714 - accuracy: 0.9524 - val_loss: 0.2159 - val_accuracy: 0.9372\n",
      "Epoch 82/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1700 - accuracy: 0.9539 - val_loss: 0.2161 - val_accuracy: 0.9355\n",
      "Epoch 83/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1690 - accuracy: 0.9532 - val_loss: 0.2153 - val_accuracy: 0.9365\n",
      "Epoch 84/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1680 - accuracy: 0.9546 - val_loss: 0.2130 - val_accuracy: 0.9372\n",
      "Epoch 85/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1674 - accuracy: 0.9535 - val_loss: 0.2183 - val_accuracy: 0.9294\n",
      "Epoch 86/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1664 - accuracy: 0.9547 - val_loss: 0.2125 - val_accuracy: 0.9359\n",
      "Epoch 87/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1655 - accuracy: 0.9555 - val_loss: 0.2118 - val_accuracy: 0.9359\n",
      "Epoch 88/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1647 - accuracy: 0.9546 - val_loss: 0.2110 - val_accuracy: 0.9386\n",
      "Epoch 89/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1636 - accuracy: 0.9551 - val_loss: 0.2104 - val_accuracy: 0.9365\n",
      "Epoch 90/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1628 - accuracy: 0.9558 - val_loss: 0.2093 - val_accuracy: 0.9393\n",
      "Epoch 91/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1624 - accuracy: 0.9557 - val_loss: 0.2204 - val_accuracy: 0.9284\n",
      "Epoch 92/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1616 - accuracy: 0.9554 - val_loss: 0.2100 - val_accuracy: 0.9396\n",
      "Epoch 93/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1606 - accuracy: 0.9569 - val_loss: 0.2063 - val_accuracy: 0.9399\n",
      "Epoch 94/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1598 - accuracy: 0.9554 - val_loss: 0.2088 - val_accuracy: 0.9359\n",
      "Epoch 95/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1596 - accuracy: 0.9553 - val_loss: 0.2046 - val_accuracy: 0.9413\n",
      "Epoch 96/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1582 - accuracy: 0.9565 - val_loss: 0.2073 - val_accuracy: 0.9413\n",
      "Epoch 97/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1577 - accuracy: 0.9573 - val_loss: 0.2041 - val_accuracy: 0.9413\n",
      "Epoch 98/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1567 - accuracy: 0.9558 - val_loss: 0.2033 - val_accuracy: 0.9410\n",
      "Epoch 99/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1562 - accuracy: 0.9553 - val_loss: 0.2032 - val_accuracy: 0.9406\n",
      "Epoch 100/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1555 - accuracy: 0.9559 - val_loss: 0.2048 - val_accuracy: 0.9352\n",
      "Epoch 101/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1545 - accuracy: 0.9578 - val_loss: 0.2013 - val_accuracy: 0.9410\n",
      "Epoch 102/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1541 - accuracy: 0.9573 - val_loss: 0.1994 - val_accuracy: 0.9413\n",
      "Epoch 103/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1534 - accuracy: 0.9573 - val_loss: 0.1986 - val_accuracy: 0.9420\n",
      "Epoch 104/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1528 - accuracy: 0.9580 - val_loss: 0.2036 - val_accuracy: 0.9355\n",
      "Epoch 105/600\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.95 - 0s 40us/step - loss: 0.1518 - accuracy: 0.9580 - val_loss: 0.2005 - val_accuracy: 0.9410\n",
      "Epoch 106/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1516 - accuracy: 0.9587 - val_loss: 0.2003 - val_accuracy: 0.9396\n",
      "Epoch 107/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1508 - accuracy: 0.9570 - val_loss: 0.1994 - val_accuracy: 0.9410\n",
      "Epoch 108/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1500 - accuracy: 0.9597 - val_loss: 0.1975 - val_accuracy: 0.9433\n",
      "Epoch 109/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1502 - accuracy: 0.9584 - val_loss: 0.1972 - val_accuracy: 0.9413\n",
      "Epoch 110/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1489 - accuracy: 0.9595 - val_loss: 0.1969 - val_accuracy: 0.9410\n",
      "Epoch 111/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1483 - accuracy: 0.9591 - val_loss: 0.2008 - val_accuracy: 0.9345\n",
      "Epoch 112/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1477 - accuracy: 0.9588 - val_loss: 0.1979 - val_accuracy: 0.9423\n",
      "Epoch 113/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1471 - accuracy: 0.9599 - val_loss: 0.1998 - val_accuracy: 0.9365\n",
      "Epoch 114/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1464 - accuracy: 0.9595 - val_loss: 0.1969 - val_accuracy: 0.9382\n",
      "Epoch 115/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1458 - accuracy: 0.9585 - val_loss: 0.1941 - val_accuracy: 0.9437\n",
      "Epoch 116/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1452 - accuracy: 0.9599 - val_loss: 0.1961 - val_accuracy: 0.9393\n",
      "Epoch 117/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1449 - accuracy: 0.9592 - val_loss: 0.1923 - val_accuracy: 0.9433\n",
      "Epoch 118/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1440 - accuracy: 0.9611 - val_loss: 0.1942 - val_accuracy: 0.9410\n",
      "Epoch 119/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1439 - accuracy: 0.9599 - val_loss: 0.1929 - val_accuracy: 0.9416\n",
      "Epoch 120/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1434 - accuracy: 0.9608 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
      "Epoch 121/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1426 - accuracy: 0.9614 - val_loss: 0.1921 - val_accuracy: 0.9423\n",
      "Epoch 122/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1423 - accuracy: 0.9600 - val_loss: 0.1933 - val_accuracy: 0.9403\n",
      "Epoch 123/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1418 - accuracy: 0.9611 - val_loss: 0.1911 - val_accuracy: 0.9450\n",
      "Epoch 124/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1409 - accuracy: 0.9614 - val_loss: 0.1906 - val_accuracy: 0.9430\n",
      "Epoch 125/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1405 - accuracy: 0.9619 - val_loss: 0.1909 - val_accuracy: 0.9433\n",
      "Epoch 126/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1400 - accuracy: 0.9623 - val_loss: 0.1922 - val_accuracy: 0.9393\n",
      "Epoch 127/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1393 - accuracy: 0.9612 - val_loss: 0.1894 - val_accuracy: 0.9427\n",
      "Epoch 128/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1389 - accuracy: 0.9618 - val_loss: 0.1895 - val_accuracy: 0.9430\n",
      "Epoch 129/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1386 - accuracy: 0.9630 - val_loss: 0.1925 - val_accuracy: 0.9406\n",
      "Epoch 130/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1381 - accuracy: 0.9626 - val_loss: 0.1895 - val_accuracy: 0.9403\n",
      "Epoch 131/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1376 - accuracy: 0.9633 - val_loss: 0.1895 - val_accuracy: 0.9430\n",
      "Epoch 132/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1370 - accuracy: 0.9634 - val_loss: 0.1905 - val_accuracy: 0.9372\n",
      "Epoch 133/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1369 - accuracy: 0.9622 - val_loss: 0.1874 - val_accuracy: 0.9427\n",
      "Epoch 134/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1362 - accuracy: 0.9630 - val_loss: 0.1899 - val_accuracy: 0.9410\n",
      "Epoch 135/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1357 - accuracy: 0.9640 - val_loss: 0.1950 - val_accuracy: 0.9369\n",
      "Epoch 136/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1353 - accuracy: 0.9626 - val_loss: 0.1860 - val_accuracy: 0.9433\n",
      "Epoch 137/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1347 - accuracy: 0.9644 - val_loss: 0.1876 - val_accuracy: 0.9413\n",
      "Epoch 138/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1342 - accuracy: 0.9641 - val_loss: 0.1844 - val_accuracy: 0.9444\n",
      "Epoch 139/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1337 - accuracy: 0.9652 - val_loss: 0.1888 - val_accuracy: 0.9389\n",
      "Epoch 140/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1333 - accuracy: 0.9640 - val_loss: 0.1886 - val_accuracy: 0.9389\n",
      "Epoch 141/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1333 - accuracy: 0.9637 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
      "Epoch 142/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1329 - accuracy: 0.9649 - val_loss: 0.1818 - val_accuracy: 0.9430\n",
      "Epoch 143/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1324 - accuracy: 0.9644 - val_loss: 0.1838 - val_accuracy: 0.9420\n",
      "Epoch 144/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1318 - accuracy: 0.9642 - val_loss: 0.1844 - val_accuracy: 0.9440\n",
      "Epoch 145/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1316 - accuracy: 0.9644 - val_loss: 0.1881 - val_accuracy: 0.9382\n",
      "Epoch 146/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1312 - accuracy: 0.9649 - val_loss: 0.1840 - val_accuracy: 0.9430\n",
      "Epoch 147/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1310 - accuracy: 0.9644 - val_loss: 0.1826 - val_accuracy: 0.9454\n",
      "Epoch 148/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1300 - accuracy: 0.9653 - val_loss: 0.1831 - val_accuracy: 0.9427\n",
      "Epoch 149/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1298 - accuracy: 0.9657 - val_loss: 0.1795 - val_accuracy: 0.9440\n",
      "Epoch 150/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1294 - accuracy: 0.9645 - val_loss: 0.1825 - val_accuracy: 0.9454\n",
      "Epoch 151/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1289 - accuracy: 0.9660 - val_loss: 0.1815 - val_accuracy: 0.9454\n",
      "Epoch 152/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1286 - accuracy: 0.9663 - val_loss: 0.1800 - val_accuracy: 0.9440\n",
      "Epoch 153/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1282 - accuracy: 0.9668 - val_loss: 0.1814 - val_accuracy: 0.9447\n",
      "Epoch 154/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1277 - accuracy: 0.9664 - val_loss: 0.1781 - val_accuracy: 0.9450\n",
      "Epoch 155/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1275 - accuracy: 0.9656 - val_loss: 0.1862 - val_accuracy: 0.9386\n",
      "Epoch 156/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1274 - accuracy: 0.9652 - val_loss: 0.1810 - val_accuracy: 0.9447\n",
      "Epoch 157/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1267 - accuracy: 0.9661 - val_loss: 0.1802 - val_accuracy: 0.9437\n",
      "Epoch 158/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1264 - accuracy: 0.9671 - val_loss: 0.1809 - val_accuracy: 0.9437\n",
      "Epoch 159/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1262 - accuracy: 0.9664 - val_loss: 0.1779 - val_accuracy: 0.9454\n",
      "Epoch 160/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1259 - accuracy: 0.9661 - val_loss: 0.1812 - val_accuracy: 0.9430\n",
      "Epoch 161/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1254 - accuracy: 0.9667 - val_loss: 0.1789 - val_accuracy: 0.9454\n",
      "Epoch 162/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1250 - accuracy: 0.9665 - val_loss: 0.1769 - val_accuracy: 0.9450\n",
      "Epoch 163/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1247 - accuracy: 0.9660 - val_loss: 0.1781 - val_accuracy: 0.9460\n",
      "Epoch 164/600\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.1245 - accuracy: 0.9655 - val_loss: 0.1799 - val_accuracy: 0.9430\n",
      "Epoch 165/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1240 - accuracy: 0.9672 - val_loss: 0.1863 - val_accuracy: 0.9386\n",
      "Epoch 166/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1237 - accuracy: 0.9669 - val_loss: 0.1759 - val_accuracy: 0.9454\n",
      "Epoch 167/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1231 - accuracy: 0.9674 - val_loss: 0.1812 - val_accuracy: 0.9420\n",
      "Epoch 168/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1232 - accuracy: 0.9663 - val_loss: 0.1861 - val_accuracy: 0.9386\n",
      "Epoch 169/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1228 - accuracy: 0.9659 - val_loss: 0.1748 - val_accuracy: 0.9454\n",
      "Epoch 170/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1226 - accuracy: 0.9663 - val_loss: 0.1740 - val_accuracy: 0.9464\n",
      "Epoch 171/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1218 - accuracy: 0.9674 - val_loss: 0.1769 - val_accuracy: 0.9447\n",
      "Epoch 172/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1216 - accuracy: 0.9674 - val_loss: 0.1748 - val_accuracy: 0.9447\n",
      "Epoch 173/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1215 - accuracy: 0.9671 - val_loss: 0.1739 - val_accuracy: 0.9464\n",
      "Epoch 174/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1211 - accuracy: 0.9674 - val_loss: 0.1754 - val_accuracy: 0.9457\n",
      "Epoch 175/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1205 - accuracy: 0.9675 - val_loss: 0.1750 - val_accuracy: 0.9467\n",
      "Epoch 176/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1202 - accuracy: 0.9672 - val_loss: 0.1727 - val_accuracy: 0.9491\n",
      "Epoch 177/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1203 - accuracy: 0.9687 - val_loss: 0.1733 - val_accuracy: 0.9464\n",
      "Epoch 178/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1198 - accuracy: 0.9678 - val_loss: 0.1749 - val_accuracy: 0.9464\n",
      "Epoch 179/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1195 - accuracy: 0.9682 - val_loss: 0.1754 - val_accuracy: 0.9457\n",
      "Epoch 180/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1193 - accuracy: 0.9676 - val_loss: 0.1741 - val_accuracy: 0.9474\n",
      "Epoch 181/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1188 - accuracy: 0.9676 - val_loss: 0.1777 - val_accuracy: 0.9416\n",
      "Epoch 182/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1187 - accuracy: 0.9672 - val_loss: 0.1717 - val_accuracy: 0.9447\n",
      "Epoch 183/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1183 - accuracy: 0.9676 - val_loss: 0.1717 - val_accuracy: 0.9454\n",
      "Epoch 184/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1183 - accuracy: 0.9683 - val_loss: 0.1717 - val_accuracy: 0.9467\n",
      "Epoch 185/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1176 - accuracy: 0.9691 - val_loss: 0.1705 - val_accuracy: 0.9474\n",
      "Epoch 186/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1175 - accuracy: 0.9684 - val_loss: 0.1710 - val_accuracy: 0.9460\n",
      "Epoch 187/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1171 - accuracy: 0.9682 - val_loss: 0.1820 - val_accuracy: 0.9393\n",
      "Epoch 188/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1170 - accuracy: 0.9680 - val_loss: 0.1730 - val_accuracy: 0.9464\n",
      "Epoch 189/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1166 - accuracy: 0.9689 - val_loss: 0.1716 - val_accuracy: 0.9481\n",
      "Epoch 190/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1160 - accuracy: 0.9682 - val_loss: 0.1699 - val_accuracy: 0.9467\n",
      "Epoch 191/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1161 - accuracy: 0.9684 - val_loss: 0.1710 - val_accuracy: 0.9477\n",
      "Epoch 192/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1158 - accuracy: 0.9679 - val_loss: 0.1715 - val_accuracy: 0.9471\n",
      "Epoch 193/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1157 - accuracy: 0.9689 - val_loss: 0.1690 - val_accuracy: 0.9464\n",
      "Epoch 194/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1150 - accuracy: 0.9691 - val_loss: 0.1694 - val_accuracy: 0.9467\n",
      "Epoch 195/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1150 - accuracy: 0.9693 - val_loss: 0.1703 - val_accuracy: 0.9471\n",
      "Epoch 196/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1148 - accuracy: 0.9698 - val_loss: 0.1693 - val_accuracy: 0.9474\n",
      "Epoch 197/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1142 - accuracy: 0.9691 - val_loss: 0.1686 - val_accuracy: 0.9477\n",
      "Epoch 198/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1143 - accuracy: 0.9699 - val_loss: 0.1716 - val_accuracy: 0.9467\n",
      "Epoch 199/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1138 - accuracy: 0.9694 - val_loss: 0.1684 - val_accuracy: 0.9477\n",
      "Epoch 200/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1135 - accuracy: 0.9705 - val_loss: 0.1688 - val_accuracy: 0.9474\n",
      "Epoch 201/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1133 - accuracy: 0.9698 - val_loss: 0.1684 - val_accuracy: 0.9474\n",
      "Epoch 202/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1131 - accuracy: 0.9697 - val_loss: 0.1706 - val_accuracy: 0.9471\n",
      "Epoch 203/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1129 - accuracy: 0.9702 - val_loss: 0.1694 - val_accuracy: 0.9471\n",
      "Epoch 204/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1123 - accuracy: 0.9702 - val_loss: 0.1675 - val_accuracy: 0.9477\n",
      "Epoch 205/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1122 - accuracy: 0.9694 - val_loss: 0.1713 - val_accuracy: 0.9454\n",
      "Epoch 206/600\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1120 - accuracy: 0.9699 - val_loss: 0.1695 - val_accuracy: 0.9477\n",
      "Epoch 207/600\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.1119 - accuracy: 0.9697 - val_loss: 0.1684 - val_accuracy: 0.9474\n",
      "Epoch 208/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1116 - accuracy: 0.9709 - val_loss: 0.1662 - val_accuracy: 0.9505\n",
      "Epoch 209/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1115 - accuracy: 0.9701 - val_loss: 0.1697 - val_accuracy: 0.9467\n",
      "Epoch 210/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1112 - accuracy: 0.9709 - val_loss: 0.1666 - val_accuracy: 0.9481\n",
      "Epoch 211/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1110 - accuracy: 0.9690 - val_loss: 0.1664 - val_accuracy: 0.9477\n",
      "Epoch 212/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1107 - accuracy: 0.9702 - val_loss: 0.1658 - val_accuracy: 0.9484\n",
      "Epoch 213/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1105 - accuracy: 0.9708 - val_loss: 0.1649 - val_accuracy: 0.9484\n",
      "Epoch 214/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1101 - accuracy: 0.9710 - val_loss: 0.1664 - val_accuracy: 0.9484\n",
      "Epoch 215/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1100 - accuracy: 0.9698 - val_loss: 0.1678 - val_accuracy: 0.9471\n",
      "Epoch 216/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1095 - accuracy: 0.9706 - val_loss: 0.1671 - val_accuracy: 0.9481\n",
      "Epoch 217/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1096 - accuracy: 0.9714 - val_loss: 0.1722 - val_accuracy: 0.9433\n",
      "Epoch 218/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1093 - accuracy: 0.9708 - val_loss: 0.1640 - val_accuracy: 0.9491\n",
      "Epoch 219/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1090 - accuracy: 0.9706 - val_loss: 0.1718 - val_accuracy: 0.9440\n",
      "Epoch 220/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1091 - accuracy: 0.9706 - val_loss: 0.1690 - val_accuracy: 0.9464\n",
      "Epoch 221/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1086 - accuracy: 0.9712 - val_loss: 0.1674 - val_accuracy: 0.9474\n",
      "Epoch 222/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1084 - accuracy: 0.9710 - val_loss: 0.1656 - val_accuracy: 0.9474\n",
      "Epoch 223/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1080 - accuracy: 0.9716 - val_loss: 0.1679 - val_accuracy: 0.9460\n",
      "Epoch 224/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1078 - accuracy: 0.9716 - val_loss: 0.1628 - val_accuracy: 0.9481\n",
      "Epoch 225/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1077 - accuracy: 0.9702 - val_loss: 0.1661 - val_accuracy: 0.9471\n",
      "Epoch 226/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1074 - accuracy: 0.9710 - val_loss: 0.1651 - val_accuracy: 0.9477\n",
      "Epoch 227/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1071 - accuracy: 0.9720 - val_loss: 0.1628 - val_accuracy: 0.9498\n",
      "Epoch 228/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1070 - accuracy: 0.9714 - val_loss: 0.1663 - val_accuracy: 0.9471\n",
      "Epoch 229/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1069 - accuracy: 0.9718 - val_loss: 0.1636 - val_accuracy: 0.9484\n",
      "Epoch 230/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1067 - accuracy: 0.9713 - val_loss: 0.1651 - val_accuracy: 0.9471\n",
      "Epoch 231/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1067 - accuracy: 0.9718 - val_loss: 0.1639 - val_accuracy: 0.9488\n",
      "Epoch 232/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1063 - accuracy: 0.9720 - val_loss: 0.1676 - val_accuracy: 0.9457\n",
      "Epoch 233/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1061 - accuracy: 0.9717 - val_loss: 0.1643 - val_accuracy: 0.9474\n",
      "Epoch 234/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1056 - accuracy: 0.9727 - val_loss: 0.1635 - val_accuracy: 0.9488\n",
      "Epoch 235/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1055 - accuracy: 0.9717 - val_loss: 0.1635 - val_accuracy: 0.9488\n",
      "Epoch 236/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1056 - accuracy: 0.9714 - val_loss: 0.1648 - val_accuracy: 0.9474\n",
      "Epoch 237/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1050 - accuracy: 0.9724 - val_loss: 0.1629 - val_accuracy: 0.9498\n",
      "Epoch 238/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1053 - accuracy: 0.9721 - val_loss: 0.1632 - val_accuracy: 0.9481\n",
      "Epoch 239/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1049 - accuracy: 0.9714 - val_loss: 0.1649 - val_accuracy: 0.9471\n",
      "Epoch 240/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1046 - accuracy: 0.9729 - val_loss: 0.1615 - val_accuracy: 0.9484\n",
      "Epoch 241/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1044 - accuracy: 0.9723 - val_loss: 0.1616 - val_accuracy: 0.9484\n",
      "Epoch 242/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1044 - accuracy: 0.9717 - val_loss: 0.1632 - val_accuracy: 0.9471\n",
      "Epoch 243/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1039 - accuracy: 0.9731 - val_loss: 0.1602 - val_accuracy: 0.9494\n",
      "Epoch 244/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1039 - accuracy: 0.9732 - val_loss: 0.1614 - val_accuracy: 0.9498\n",
      "Epoch 245/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1033 - accuracy: 0.9728 - val_loss: 0.1687 - val_accuracy: 0.9440\n",
      "Epoch 246/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1036 - accuracy: 0.9727 - val_loss: 0.1602 - val_accuracy: 0.9498\n",
      "Epoch 247/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1033 - accuracy: 0.9736 - val_loss: 0.1600 - val_accuracy: 0.9498\n",
      "Epoch 248/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1030 - accuracy: 0.9731 - val_loss: 0.1608 - val_accuracy: 0.9488\n",
      "Epoch 249/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1028 - accuracy: 0.9732 - val_loss: 0.1598 - val_accuracy: 0.9494\n",
      "Epoch 250/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1027 - accuracy: 0.9728 - val_loss: 0.1609 - val_accuracy: 0.9491\n",
      "Epoch 251/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1026 - accuracy: 0.9728 - val_loss: 0.1603 - val_accuracy: 0.9494\n",
      "Epoch 252/600\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1024 - accuracy: 0.9733 - val_loss: 0.1596 - val_accuracy: 0.9505\n",
      "Epoch 253/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1021 - accuracy: 0.9743 - val_loss: 0.1593 - val_accuracy: 0.9505\n",
      "Epoch 254/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1020 - accuracy: 0.9737 - val_loss: 0.1596 - val_accuracy: 0.9505\n",
      "Epoch 255/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1018 - accuracy: 0.9728 - val_loss: 0.1576 - val_accuracy: 0.9522\n",
      "Epoch 256/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1015 - accuracy: 0.9744 - val_loss: 0.1659 - val_accuracy: 0.9450\n",
      "Epoch 257/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1015 - accuracy: 0.9733 - val_loss: 0.1618 - val_accuracy: 0.9474\n",
      "Epoch 258/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1014 - accuracy: 0.9736 - val_loss: 0.1598 - val_accuracy: 0.9491\n",
      "Epoch 259/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1007 - accuracy: 0.9735 - val_loss: 0.1614 - val_accuracy: 0.9481\n",
      "Epoch 260/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.1010 - accuracy: 0.9737 - val_loss: 0.1576 - val_accuracy: 0.9518\n",
      "Epoch 261/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1009 - accuracy: 0.9731 - val_loss: 0.1598 - val_accuracy: 0.9498\n",
      "Epoch 262/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1005 - accuracy: 0.9737 - val_loss: 0.1602 - val_accuracy: 0.9491\n",
      "Epoch 263/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1004 - accuracy: 0.9737 - val_loss: 0.1606 - val_accuracy: 0.9484\n",
      "Epoch 264/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1002 - accuracy: 0.9736 - val_loss: 0.1591 - val_accuracy: 0.9501\n",
      "Epoch 265/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1001 - accuracy: 0.9743 - val_loss: 0.1576 - val_accuracy: 0.9494\n",
      "Epoch 266/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0999 - accuracy: 0.9736 - val_loss: 0.1590 - val_accuracy: 0.9498\n",
      "Epoch 267/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0995 - accuracy: 0.9746 - val_loss: 0.1593 - val_accuracy: 0.9491\n",
      "Epoch 268/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0994 - accuracy: 0.9744 - val_loss: 0.1634 - val_accuracy: 0.9460\n",
      "Epoch 269/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0993 - accuracy: 0.9740 - val_loss: 0.1611 - val_accuracy: 0.9467\n",
      "Epoch 270/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0993 - accuracy: 0.9747 - val_loss: 0.1578 - val_accuracy: 0.9491\n",
      "Epoch 271/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0989 - accuracy: 0.9742 - val_loss: 0.1587 - val_accuracy: 0.9494\n",
      "Epoch 272/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0988 - accuracy: 0.9747 - val_loss: 0.1581 - val_accuracy: 0.9498\n",
      "Epoch 273/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0986 - accuracy: 0.9743 - val_loss: 0.1565 - val_accuracy: 0.9511\n",
      "Epoch 274/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0985 - accuracy: 0.9740 - val_loss: 0.1593 - val_accuracy: 0.9491\n",
      "Epoch 275/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0984 - accuracy: 0.9746 - val_loss: 0.1594 - val_accuracy: 0.9477\n",
      "Epoch 276/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0981 - accuracy: 0.9746 - val_loss: 0.1608 - val_accuracy: 0.9474\n",
      "Epoch 277/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0982 - accuracy: 0.9750 - val_loss: 0.1588 - val_accuracy: 0.9488\n",
      "Epoch 278/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.1579 - val_accuracy: 0.9494\n",
      "Epoch 279/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0978 - accuracy: 0.9748 - val_loss: 0.1574 - val_accuracy: 0.9488\n",
      "Epoch 280/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0976 - accuracy: 0.9733 - val_loss: 0.1561 - val_accuracy: 0.9501\n",
      "Epoch 281/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0973 - accuracy: 0.9740 - val_loss: 0.1558 - val_accuracy: 0.9505\n",
      "Epoch 282/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0973 - accuracy: 0.9748 - val_loss: 0.1588 - val_accuracy: 0.9488\n",
      "Epoch 283/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0972 - accuracy: 0.9748 - val_loss: 0.1584 - val_accuracy: 0.9484\n",
      "Epoch 284/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0966 - accuracy: 0.9747 - val_loss: 0.1550 - val_accuracy: 0.9508\n",
      "Epoch 285/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0970 - accuracy: 0.9743 - val_loss: 0.1553 - val_accuracy: 0.9505\n",
      "Epoch 286/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0966 - accuracy: 0.9748 - val_loss: 0.1566 - val_accuracy: 0.9498\n",
      "Epoch 287/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0964 - accuracy: 0.9747 - val_loss: 0.1582 - val_accuracy: 0.9494\n",
      "Epoch 288/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0964 - accuracy: 0.9750 - val_loss: 0.1558 - val_accuracy: 0.9501\n",
      "Epoch 289/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0963 - accuracy: 0.9746 - val_loss: 0.1553 - val_accuracy: 0.9518\n",
      "Epoch 290/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0961 - accuracy: 0.9743 - val_loss: 0.1560 - val_accuracy: 0.9511\n",
      "Epoch 291/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0957 - accuracy: 0.9739 - val_loss: 0.1547 - val_accuracy: 0.9505\n",
      "Epoch 292/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0956 - accuracy: 0.9747 - val_loss: 0.1593 - val_accuracy: 0.9477\n",
      "Epoch 293/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0955 - accuracy: 0.9759 - val_loss: 0.1580 - val_accuracy: 0.9491\n",
      "Epoch 294/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0956 - accuracy: 0.9744 - val_loss: 0.1571 - val_accuracy: 0.9488\n",
      "Epoch 295/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0955 - accuracy: 0.9739 - val_loss: 0.1556 - val_accuracy: 0.9498\n",
      "Epoch 296/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0950 - accuracy: 0.9763 - val_loss: 0.1552 - val_accuracy: 0.9511\n",
      "Epoch 297/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0951 - accuracy: 0.9747 - val_loss: 0.1550 - val_accuracy: 0.9501\n",
      "Epoch 298/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0949 - accuracy: 0.9758 - val_loss: 0.1569 - val_accuracy: 0.9491\n",
      "Epoch 299/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0947 - accuracy: 0.9744 - val_loss: 0.1535 - val_accuracy: 0.9508\n",
      "Epoch 300/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0943 - accuracy: 0.9758 - val_loss: 0.1592 - val_accuracy: 0.9481\n",
      "Epoch 301/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0944 - accuracy: 0.9755 - val_loss: 0.1561 - val_accuracy: 0.9494\n",
      "Epoch 302/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0942 - accuracy: 0.9757 - val_loss: 0.1596 - val_accuracy: 0.9477\n",
      "Epoch 303/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0942 - accuracy: 0.9751 - val_loss: 0.1563 - val_accuracy: 0.9498\n",
      "Epoch 304/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0941 - accuracy: 0.9758 - val_loss: 0.1583 - val_accuracy: 0.9477\n",
      "Epoch 305/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0940 - accuracy: 0.9751 - val_loss: 0.1531 - val_accuracy: 0.9505\n",
      "Epoch 306/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0937 - accuracy: 0.9758 - val_loss: 0.1527 - val_accuracy: 0.9525\n",
      "Epoch 307/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0940 - accuracy: 0.9752 - val_loss: 0.1542 - val_accuracy: 0.9508\n",
      "Epoch 308/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0934 - accuracy: 0.9758 - val_loss: 0.1567 - val_accuracy: 0.9481\n",
      "Epoch 309/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0933 - accuracy: 0.9761 - val_loss: 0.1544 - val_accuracy: 0.9515\n",
      "Epoch 310/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0931 - accuracy: 0.9761 - val_loss: 0.1603 - val_accuracy: 0.9460\n",
      "Epoch 311/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0932 - accuracy: 0.9758 - val_loss: 0.1631 - val_accuracy: 0.9447\n",
      "Epoch 312/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0931 - accuracy: 0.9761 - val_loss: 0.1553 - val_accuracy: 0.9481\n",
      "Epoch 313/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0929 - accuracy: 0.9757 - val_loss: 0.1541 - val_accuracy: 0.9515\n",
      "Epoch 314/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0927 - accuracy: 0.9754 - val_loss: 0.1536 - val_accuracy: 0.9518\n",
      "Epoch 315/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0923 - accuracy: 0.9757 - val_loss: 0.1550 - val_accuracy: 0.9498\n",
      "Epoch 316/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0924 - accuracy: 0.9759 - val_loss: 0.1527 - val_accuracy: 0.9505\n",
      "Epoch 317/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0923 - accuracy: 0.9761 - val_loss: 0.1543 - val_accuracy: 0.9498\n",
      "Epoch 318/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0919 - accuracy: 0.9763 - val_loss: 0.1518 - val_accuracy: 0.9528\n",
      "Epoch 319/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0922 - accuracy: 0.9758 - val_loss: 0.1570 - val_accuracy: 0.9481\n",
      "Epoch 320/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0920 - accuracy: 0.9755 - val_loss: 0.1531 - val_accuracy: 0.9508\n",
      "Epoch 321/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0919 - accuracy: 0.9761 - val_loss: 0.1545 - val_accuracy: 0.9494\n",
      "Epoch 322/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0917 - accuracy: 0.9762 - val_loss: 0.1513 - val_accuracy: 0.9508\n",
      "Epoch 323/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0916 - accuracy: 0.9758 - val_loss: 0.1591 - val_accuracy: 0.9464\n",
      "Epoch 324/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0914 - accuracy: 0.9762 - val_loss: 0.1511 - val_accuracy: 0.9511\n",
      "Epoch 325/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0912 - accuracy: 0.9770 - val_loss: 0.1516 - val_accuracy: 0.9518\n",
      "Epoch 326/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0910 - accuracy: 0.9765 - val_loss: 0.1549 - val_accuracy: 0.9484\n",
      "Epoch 327/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0911 - accuracy: 0.9762 - val_loss: 0.1538 - val_accuracy: 0.9484\n",
      "Epoch 328/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0911 - accuracy: 0.9769 - val_loss: 0.1515 - val_accuracy: 0.9525\n",
      "Epoch 329/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0909 - accuracy: 0.9759 - val_loss: 0.1505 - val_accuracy: 0.9525\n",
      "Epoch 330/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0908 - accuracy: 0.9755 - val_loss: 0.1521 - val_accuracy: 0.9525\n",
      "Epoch 331/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0906 - accuracy: 0.9769 - val_loss: 0.1525 - val_accuracy: 0.9522\n",
      "Epoch 332/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0904 - accuracy: 0.9765 - val_loss: 0.1523 - val_accuracy: 0.9508\n",
      "Epoch 333/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0901 - accuracy: 0.9758 - val_loss: 0.1510 - val_accuracy: 0.9515\n",
      "Epoch 334/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0901 - accuracy: 0.9761 - val_loss: 0.1544 - val_accuracy: 0.9488\n",
      "Epoch 335/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0901 - accuracy: 0.9761 - val_loss: 0.1538 - val_accuracy: 0.9494\n",
      "Epoch 336/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0899 - accuracy: 0.9777 - val_loss: 0.1568 - val_accuracy: 0.9467\n",
      "Epoch 337/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0897 - accuracy: 0.9762 - val_loss: 0.1568 - val_accuracy: 0.9471\n",
      "Epoch 338/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0897 - accuracy: 0.9770 - val_loss: 0.1511 - val_accuracy: 0.9522\n",
      "Epoch 339/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0895 - accuracy: 0.9763 - val_loss: 0.1541 - val_accuracy: 0.9491\n",
      "Epoch 340/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0895 - accuracy: 0.9761 - val_loss: 0.1518 - val_accuracy: 0.9501\n",
      "Epoch 341/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0894 - accuracy: 0.9762 - val_loss: 0.1507 - val_accuracy: 0.9515\n",
      "Epoch 342/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0892 - accuracy: 0.9761 - val_loss: 0.1555 - val_accuracy: 0.9481\n",
      "Epoch 343/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0892 - accuracy: 0.9767 - val_loss: 0.1505 - val_accuracy: 0.9522\n",
      "Epoch 344/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0891 - accuracy: 0.9771 - val_loss: 0.1500 - val_accuracy: 0.9522\n",
      "Epoch 345/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0888 - accuracy: 0.9777 - val_loss: 0.1492 - val_accuracy: 0.9528\n",
      "Epoch 346/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0889 - accuracy: 0.9761 - val_loss: 0.1510 - val_accuracy: 0.9508\n",
      "Epoch 347/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0885 - accuracy: 0.9771 - val_loss: 0.1493 - val_accuracy: 0.9515\n",
      "Epoch 348/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0885 - accuracy: 0.9769 - val_loss: 0.1500 - val_accuracy: 0.9518\n",
      "Epoch 349/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0885 - accuracy: 0.9759 - val_loss: 0.1530 - val_accuracy: 0.9494\n",
      "Epoch 350/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0882 - accuracy: 0.9777 - val_loss: 0.1580 - val_accuracy: 0.9460\n",
      "Epoch 351/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0883 - accuracy: 0.9769 - val_loss: 0.1512 - val_accuracy: 0.9508\n",
      "Epoch 352/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0881 - accuracy: 0.9774 - val_loss: 0.1498 - val_accuracy: 0.9522\n",
      "Epoch 353/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0880 - accuracy: 0.9765 - val_loss: 0.1510 - val_accuracy: 0.9505\n",
      "Epoch 354/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0879 - accuracy: 0.9769 - val_loss: 0.1497 - val_accuracy: 0.9515\n",
      "Epoch 355/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0877 - accuracy: 0.9776 - val_loss: 0.1556 - val_accuracy: 0.9467\n",
      "Epoch 356/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0877 - accuracy: 0.9770 - val_loss: 0.1504 - val_accuracy: 0.9508\n",
      "Epoch 357/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0874 - accuracy: 0.9769 - val_loss: 0.1525 - val_accuracy: 0.9498\n",
      "Epoch 358/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0874 - accuracy: 0.9780 - val_loss: 0.1504 - val_accuracy: 0.9505\n",
      "Epoch 359/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0873 - accuracy: 0.9773 - val_loss: 0.1505 - val_accuracy: 0.9508\n",
      "Epoch 360/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0871 - accuracy: 0.9782 - val_loss: 0.1499 - val_accuracy: 0.9508\n",
      "Epoch 361/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0871 - accuracy: 0.9773 - val_loss: 0.1485 - val_accuracy: 0.9518\n",
      "Epoch 362/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0869 - accuracy: 0.9774 - val_loss: 0.1506 - val_accuracy: 0.9501\n",
      "Epoch 363/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0869 - accuracy: 0.9776 - val_loss: 0.1478 - val_accuracy: 0.9522\n",
      "Epoch 364/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0868 - accuracy: 0.9774 - val_loss: 0.1508 - val_accuracy: 0.9498\n",
      "Epoch 365/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0866 - accuracy: 0.9778 - val_loss: 0.1521 - val_accuracy: 0.9498\n",
      "Epoch 366/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0866 - accuracy: 0.9780 - val_loss: 0.1485 - val_accuracy: 0.9525\n",
      "Epoch 367/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0865 - accuracy: 0.9781 - val_loss: 0.1545 - val_accuracy: 0.9471\n",
      "Epoch 368/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0863 - accuracy: 0.9781 - val_loss: 0.1475 - val_accuracy: 0.9535\n",
      "Epoch 369/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0864 - accuracy: 0.9774 - val_loss: 0.1484 - val_accuracy: 0.9525\n",
      "Epoch 370/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0863 - accuracy: 0.9773 - val_loss: 0.1499 - val_accuracy: 0.9505\n",
      "Epoch 371/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0859 - accuracy: 0.9777 - val_loss: 0.1538 - val_accuracy: 0.9477\n",
      "Epoch 372/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0858 - accuracy: 0.9773 - val_loss: 0.1590 - val_accuracy: 0.9457\n",
      "Epoch 373/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0859 - accuracy: 0.9771 - val_loss: 0.1492 - val_accuracy: 0.9508\n",
      "Epoch 374/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0857 - accuracy: 0.9776 - val_loss: 0.1486 - val_accuracy: 0.9518\n",
      "Epoch 375/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0855 - accuracy: 0.9773 - val_loss: 0.1480 - val_accuracy: 0.9515\n",
      "Epoch 376/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0855 - accuracy: 0.9774 - val_loss: 0.1518 - val_accuracy: 0.9501\n",
      "Epoch 377/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0856 - accuracy: 0.9778 - val_loss: 0.1503 - val_accuracy: 0.9505\n",
      "Epoch 378/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0854 - accuracy: 0.9782 - val_loss: 0.1502 - val_accuracy: 0.9505\n",
      "Epoch 379/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0851 - accuracy: 0.9773 - val_loss: 0.1514 - val_accuracy: 0.9494\n",
      "Epoch 380/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0850 - accuracy: 0.9776 - val_loss: 0.1463 - val_accuracy: 0.9542\n",
      "Epoch 381/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0853 - accuracy: 0.9773 - val_loss: 0.1481 - val_accuracy: 0.9508\n",
      "Epoch 382/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0848 - accuracy: 0.9784 - val_loss: 0.1497 - val_accuracy: 0.9505\n",
      "Epoch 383/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0849 - accuracy: 0.9773 - val_loss: 0.1475 - val_accuracy: 0.9522\n",
      "Epoch 384/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0847 - accuracy: 0.9778 - val_loss: 0.1496 - val_accuracy: 0.9508\n",
      "Epoch 385/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0847 - accuracy: 0.9786 - val_loss: 0.1476 - val_accuracy: 0.9525\n",
      "Epoch 386/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0846 - accuracy: 0.9786 - val_loss: 0.1506 - val_accuracy: 0.9498\n",
      "Epoch 387/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0844 - accuracy: 0.9770 - val_loss: 0.1524 - val_accuracy: 0.9484\n",
      "Epoch 388/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0844 - accuracy: 0.9785 - val_loss: 0.1498 - val_accuracy: 0.9505\n",
      "Epoch 389/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0841 - accuracy: 0.9776 - val_loss: 0.1500 - val_accuracy: 0.9501\n",
      "Epoch 390/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0842 - accuracy: 0.9792 - val_loss: 0.1474 - val_accuracy: 0.9525\n",
      "Epoch 391/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0840 - accuracy: 0.9782 - val_loss: 0.1482 - val_accuracy: 0.9511\n",
      "Epoch 392/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0839 - accuracy: 0.9785 - val_loss: 0.1477 - val_accuracy: 0.9518\n",
      "Epoch 393/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0839 - accuracy: 0.9777 - val_loss: 0.1471 - val_accuracy: 0.9525\n",
      "Epoch 394/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0839 - accuracy: 0.9781 - val_loss: 0.1471 - val_accuracy: 0.9525\n",
      "Epoch 395/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0837 - accuracy: 0.9781 - val_loss: 0.1485 - val_accuracy: 0.9511\n",
      "Epoch 396/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0834 - accuracy: 0.9780 - val_loss: 0.1480 - val_accuracy: 0.9511\n",
      "Epoch 397/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0835 - accuracy: 0.9781 - val_loss: 0.1483 - val_accuracy: 0.9508\n",
      "Epoch 398/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0835 - accuracy: 0.9780 - val_loss: 0.1479 - val_accuracy: 0.9508\n",
      "Epoch 399/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0831 - accuracy: 0.9776 - val_loss: 0.1460 - val_accuracy: 0.9522\n",
      "Epoch 400/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0835 - accuracy: 0.9785 - val_loss: 0.1478 - val_accuracy: 0.9511\n",
      "Epoch 401/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0831 - accuracy: 0.9777 - val_loss: 0.1476 - val_accuracy: 0.9505\n",
      "Epoch 402/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0830 - accuracy: 0.9788 - val_loss: 0.1466 - val_accuracy: 0.9525\n",
      "Epoch 403/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0829 - accuracy: 0.9782 - val_loss: 0.1475 - val_accuracy: 0.9511\n",
      "Epoch 404/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0830 - accuracy: 0.9780 - val_loss: 0.1460 - val_accuracy: 0.9522\n",
      "Epoch 405/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0828 - accuracy: 0.9785 - val_loss: 0.1494 - val_accuracy: 0.9498\n",
      "Epoch 406/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0827 - accuracy: 0.9786 - val_loss: 0.1480 - val_accuracy: 0.9511\n",
      "Epoch 407/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0823 - accuracy: 0.9792 - val_loss: 0.1524 - val_accuracy: 0.9481\n",
      "Epoch 408/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0825 - accuracy: 0.9777 - val_loss: 0.1458 - val_accuracy: 0.9532\n",
      "Epoch 409/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0823 - accuracy: 0.9780 - val_loss: 0.1483 - val_accuracy: 0.9505\n",
      "Epoch 410/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0823 - accuracy: 0.9784 - val_loss: 0.1491 - val_accuracy: 0.9498\n",
      "Epoch 411/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0822 - accuracy: 0.9795 - val_loss: 0.1467 - val_accuracy: 0.9518\n",
      "Epoch 412/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0818 - accuracy: 0.9782 - val_loss: 0.1449 - val_accuracy: 0.9525\n",
      "Epoch 413/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0820 - accuracy: 0.9780 - val_loss: 0.1475 - val_accuracy: 0.9511\n",
      "Epoch 414/600\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0820 - accuracy: 0.9780 - val_loss: 0.1483 - val_accuracy: 0.9505\n",
      "Epoch 415/600\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.0818 - accuracy: 0.9788 - val_loss: 0.1488 - val_accuracy: 0.9501\n",
      "Epoch 416/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0817 - accuracy: 0.9776 - val_loss: 0.1491 - val_accuracy: 0.9501\n",
      "Epoch 417/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0819 - accuracy: 0.9784 - val_loss: 0.1460 - val_accuracy: 0.9522\n",
      "Epoch 418/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0817 - accuracy: 0.9791 - val_loss: 0.1475 - val_accuracy: 0.9511\n",
      "Epoch 419/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0815 - accuracy: 0.9778 - val_loss: 0.1484 - val_accuracy: 0.9498\n",
      "Epoch 420/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0815 - accuracy: 0.9788 - val_loss: 0.1455 - val_accuracy: 0.9528\n",
      "Epoch 421/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0814 - accuracy: 0.9791 - val_loss: 0.1471 - val_accuracy: 0.9508\n",
      "Epoch 422/600\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.0812 - accuracy: 0.9793 - val_loss: 0.1464 - val_accuracy: 0.9511\n",
      "Epoch 423/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0808 - accuracy: 0.9780 - val_loss: 0.1540 - val_accuracy: 0.9471\n",
      "Epoch 424/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0812 - accuracy: 0.9786 - val_loss: 0.1503 - val_accuracy: 0.9491\n",
      "Epoch 425/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0811 - accuracy: 0.9785 - val_loss: 0.1438 - val_accuracy: 0.9518\n",
      "Epoch 426/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0809 - accuracy: 0.9796 - val_loss: 0.1447 - val_accuracy: 0.9528\n",
      "Epoch 427/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0808 - accuracy: 0.9786 - val_loss: 0.1501 - val_accuracy: 0.9488\n",
      "Epoch 428/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0808 - accuracy: 0.9786 - val_loss: 0.1463 - val_accuracy: 0.9515\n",
      "Epoch 429/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0808 - accuracy: 0.9780 - val_loss: 0.1465 - val_accuracy: 0.9505\n",
      "Epoch 430/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0805 - accuracy: 0.9788 - val_loss: 0.1477 - val_accuracy: 0.9501\n",
      "Epoch 431/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0804 - accuracy: 0.9784 - val_loss: 0.1468 - val_accuracy: 0.9508\n",
      "Epoch 432/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0805 - accuracy: 0.9785 - val_loss: 0.1494 - val_accuracy: 0.9494\n",
      "Epoch 433/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0803 - accuracy: 0.9791 - val_loss: 0.1450 - val_accuracy: 0.9522\n",
      "Epoch 434/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0803 - accuracy: 0.9793 - val_loss: 0.1459 - val_accuracy: 0.9511\n",
      "Epoch 435/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0801 - accuracy: 0.9789 - val_loss: 0.1447 - val_accuracy: 0.9528\n",
      "Epoch 436/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0803 - accuracy: 0.9785 - val_loss: 0.1451 - val_accuracy: 0.9522\n",
      "Epoch 437/600\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.0801 - accuracy: 0.9780 - val_loss: 0.1470 - val_accuracy: 0.9508\n",
      "Epoch 438/600\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0799 - accuracy: 0.9793 - val_loss: 0.1478 - val_accuracy: 0.9501\n",
      "Epoch 439/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0800 - accuracy: 0.9792 - val_loss: 0.1442 - val_accuracy: 0.9542\n",
      "Epoch 440/600\n",
      "7352/7352 [==============================] - 0s 51us/step - loss: 0.0796 - accuracy: 0.9799 - val_loss: 0.1444 - val_accuracy: 0.9535\n",
      "Epoch 441/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0798 - accuracy: 0.9786 - val_loss: 0.1444 - val_accuracy: 0.9525\n",
      "Epoch 442/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0797 - accuracy: 0.9784 - val_loss: 0.1425 - val_accuracy: 0.9535\n",
      "Epoch 443/600\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.0797 - accuracy: 0.9792 - val_loss: 0.1470 - val_accuracy: 0.9505\n",
      "Epoch 444/600\n",
      "7352/7352 [==============================] - 0s 51us/step - loss: 0.0794 - accuracy: 0.9797 - val_loss: 0.1494 - val_accuracy: 0.9498\n",
      "Epoch 445/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0796 - accuracy: 0.9786 - val_loss: 0.1459 - val_accuracy: 0.9511\n",
      "Epoch 446/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0793 - accuracy: 0.9789 - val_loss: 0.1460 - val_accuracy: 0.9511\n",
      "Epoch 447/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0793 - accuracy: 0.9792 - val_loss: 0.1509 - val_accuracy: 0.9474\n",
      "Epoch 448/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0792 - accuracy: 0.9791 - val_loss: 0.1443 - val_accuracy: 0.9518\n",
      "Epoch 449/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0792 - accuracy: 0.9793 - val_loss: 0.1499 - val_accuracy: 0.9488\n",
      "Epoch 450/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0790 - accuracy: 0.9789 - val_loss: 0.1423 - val_accuracy: 0.9525\n",
      "Epoch 451/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0790 - accuracy: 0.9781 - val_loss: 0.1465 - val_accuracy: 0.9511\n",
      "Epoch 452/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0786 - accuracy: 0.9792 - val_loss: 0.1476 - val_accuracy: 0.9508\n",
      "Epoch 453/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0788 - accuracy: 0.9791 - val_loss: 0.1463 - val_accuracy: 0.9511\n",
      "Epoch 454/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0786 - accuracy: 0.9789 - val_loss: 0.1503 - val_accuracy: 0.9484\n",
      "Epoch 455/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0785 - accuracy: 0.9803 - val_loss: 0.1441 - val_accuracy: 0.9532\n",
      "Epoch 456/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0785 - accuracy: 0.9791 - val_loss: 0.1467 - val_accuracy: 0.9511\n",
      "Epoch 457/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0785 - accuracy: 0.9795 - val_loss: 0.1445 - val_accuracy: 0.9522\n",
      "Epoch 458/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0785 - accuracy: 0.9793 - val_loss: 0.1465 - val_accuracy: 0.9505\n",
      "Epoch 459/600\n",
      "7352/7352 [==============================] - 0s 52us/step - loss: 0.0783 - accuracy: 0.9791 - val_loss: 0.1437 - val_accuracy: 0.9518\n",
      "Epoch 460/600\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0782 - accuracy: 0.9797 - val_loss: 0.1440 - val_accuracy: 0.9522\n",
      "Epoch 461/600\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0781 - accuracy: 0.9804 - val_loss: 0.1428 - val_accuracy: 0.9542\n",
      "Epoch 462/600\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0779 - accuracy: 0.9800 - val_loss: 0.1443 - val_accuracy: 0.9515\n",
      "Epoch 463/600\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0781 - accuracy: 0.9797 - val_loss: 0.1449 - val_accuracy: 0.9515\n",
      "Epoch 464/600\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0779 - accuracy: 0.9793 - val_loss: 0.1463 - val_accuracy: 0.9501\n",
      "Epoch 465/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0778 - accuracy: 0.9795 - val_loss: 0.1488 - val_accuracy: 0.9501\n",
      "Epoch 466/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0780 - accuracy: 0.9786 - val_loss: 0.1441 - val_accuracy: 0.9518\n",
      "Epoch 467/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0777 - accuracy: 0.9793 - val_loss: 0.1441 - val_accuracy: 0.9515\n",
      "Epoch 468/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0778 - accuracy: 0.9782 - val_loss: 0.1433 - val_accuracy: 0.9522\n",
      "Epoch 469/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0775 - accuracy: 0.9792 - val_loss: 0.1462 - val_accuracy: 0.9511\n",
      "Epoch 470/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0774 - accuracy: 0.9804 - val_loss: 0.1500 - val_accuracy: 0.9474\n",
      "Epoch 471/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0775 - accuracy: 0.9800 - val_loss: 0.1427 - val_accuracy: 0.9532\n",
      "Epoch 472/600\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.0775 - accuracy: 0.9797 - val_loss: 0.1460 - val_accuracy: 0.9498\n",
      "Epoch 473/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0773 - accuracy: 0.9785 - val_loss: 0.1444 - val_accuracy: 0.9518\n",
      "Epoch 474/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0772 - accuracy: 0.9791 - val_loss: 0.1477 - val_accuracy: 0.9494\n",
      "Epoch 475/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0772 - accuracy: 0.9803 - val_loss: 0.1429 - val_accuracy: 0.9535\n",
      "Epoch 476/600\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.0771 - accuracy: 0.9796 - val_loss: 0.1469 - val_accuracy: 0.9498\n",
      "Epoch 477/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0771 - accuracy: 0.9791 - val_loss: 0.1464 - val_accuracy: 0.9501\n",
      "Epoch 478/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0771 - accuracy: 0.9801 - val_loss: 0.1433 - val_accuracy: 0.9522\n",
      "Epoch 479/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0770 - accuracy: 0.9799 - val_loss: 0.1435 - val_accuracy: 0.9525\n",
      "Epoch 480/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0768 - accuracy: 0.9796 - val_loss: 0.1440 - val_accuracy: 0.9522\n",
      "Epoch 481/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0767 - accuracy: 0.9799 - val_loss: 0.1423 - val_accuracy: 0.9542\n",
      "Epoch 482/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0767 - accuracy: 0.9792 - val_loss: 0.1421 - val_accuracy: 0.9542\n",
      "Epoch 483/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0764 - accuracy: 0.9796 - val_loss: 0.1420 - val_accuracy: 0.9545\n",
      "Epoch 484/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0766 - accuracy: 0.9795 - val_loss: 0.1432 - val_accuracy: 0.9528\n",
      "Epoch 485/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0764 - accuracy: 0.9796 - val_loss: 0.1419 - val_accuracy: 0.9542\n",
      "Epoch 486/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0764 - accuracy: 0.9795 - val_loss: 0.1441 - val_accuracy: 0.9518\n",
      "Epoch 487/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0763 - accuracy: 0.9797 - val_loss: 0.1416 - val_accuracy: 0.9542\n",
      "Epoch 488/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0763 - accuracy: 0.9796 - val_loss: 0.1439 - val_accuracy: 0.9518\n",
      "Epoch 489/600\n",
      "7352/7352 [==============================] - 0s 50us/step - loss: 0.0762 - accuracy: 0.9796 - val_loss: 0.1414 - val_accuracy: 0.9532\n",
      "Epoch 490/600\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.0763 - accuracy: 0.9795 - val_loss: 0.1417 - val_accuracy: 0.9539\n",
      "Epoch 491/600\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0761 - accuracy: 0.9795 - val_loss: 0.1454 - val_accuracy: 0.9508\n",
      "Epoch 492/600\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0761 - accuracy: 0.9796 - val_loss: 0.1419 - val_accuracy: 0.9528\n",
      "Epoch 493/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0760 - accuracy: 0.9799 - val_loss: 0.1410 - val_accuracy: 0.9542\n",
      "Epoch 494/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0760 - accuracy: 0.9795 - val_loss: 0.1451 - val_accuracy: 0.9505\n",
      "Epoch 495/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.1457 - val_accuracy: 0.9508\n",
      "Epoch 496/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0757 - accuracy: 0.9795 - val_loss: 0.1430 - val_accuracy: 0.9525\n",
      "Epoch 497/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0756 - accuracy: 0.9805 - val_loss: 0.1421 - val_accuracy: 0.9532\n",
      "Epoch 498/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0755 - accuracy: 0.9801 - val_loss: 0.1437 - val_accuracy: 0.9511\n",
      "Epoch 499/600\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 0.1410 - val_accuracy: 0.9549\n",
      "Epoch 500/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0755 - accuracy: 0.9803 - val_loss: 0.1420 - val_accuracy: 0.9532\n",
      "Epoch 501/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0755 - accuracy: 0.9795 - val_loss: 0.1460 - val_accuracy: 0.9505\n",
      "Epoch 502/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0754 - accuracy: 0.9795 - val_loss: 0.1437 - val_accuracy: 0.9511\n",
      "Epoch 503/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0751 - accuracy: 0.9803 - val_loss: 0.1453 - val_accuracy: 0.9508\n",
      "Epoch 504/600\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0750 - accuracy: 0.9801 - val_loss: 0.1441 - val_accuracy: 0.9511\n",
      "Epoch 505/600\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0751 - accuracy: 0.9795 - val_loss: 0.1431 - val_accuracy: 0.9515\n",
      "Epoch 506/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0750 - accuracy: 0.9800 - val_loss: 0.1417 - val_accuracy: 0.9535\n",
      "Epoch 507/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0751 - accuracy: 0.9801 - val_loss: 0.1451 - val_accuracy: 0.9501\n",
      "Epoch 508/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0749 - accuracy: 0.9800 - val_loss: 0.1447 - val_accuracy: 0.9508\n",
      "Epoch 509/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0748 - accuracy: 0.9804 - val_loss: 0.1419 - val_accuracy: 0.9532\n",
      "Epoch 510/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0748 - accuracy: 0.9810 - val_loss: 0.1428 - val_accuracy: 0.9518\n",
      "Epoch 511/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0747 - accuracy: 0.9805 - val_loss: 0.1431 - val_accuracy: 0.9522\n",
      "Epoch 512/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0745 - accuracy: 0.9804 - val_loss: 0.1444 - val_accuracy: 0.9508\n",
      "Epoch 513/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0747 - accuracy: 0.9797 - val_loss: 0.1413 - val_accuracy: 0.9535\n",
      "Epoch 514/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0745 - accuracy: 0.9803 - val_loss: 0.1474 - val_accuracy: 0.9484\n",
      "Epoch 515/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0746 - accuracy: 0.9804 - val_loss: 0.1405 - val_accuracy: 0.9545\n",
      "Epoch 516/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0745 - accuracy: 0.9801 - val_loss: 0.1415 - val_accuracy: 0.9528\n",
      "Epoch 517/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0743 - accuracy: 0.9805 - val_loss: 0.1491 - val_accuracy: 0.9484\n",
      "Epoch 518/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0743 - accuracy: 0.9801 - val_loss: 0.1407 - val_accuracy: 0.9545\n",
      "Epoch 519/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0742 - accuracy: 0.9803 - val_loss: 0.1417 - val_accuracy: 0.9532\n",
      "Epoch 520/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0740 - accuracy: 0.9811 - val_loss: 0.1411 - val_accuracy: 0.9532\n",
      "Epoch 521/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0741 - accuracy: 0.9801 - val_loss: 0.1422 - val_accuracy: 0.9522\n",
      "Epoch 522/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0740 - accuracy: 0.9814 - val_loss: 0.1433 - val_accuracy: 0.9511\n",
      "Epoch 523/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0741 - accuracy: 0.9810 - val_loss: 0.1405 - val_accuracy: 0.9535\n",
      "Epoch 524/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0739 - accuracy: 0.9803 - val_loss: 0.1443 - val_accuracy: 0.9501\n",
      "Epoch 525/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0739 - accuracy: 0.9797 - val_loss: 0.1446 - val_accuracy: 0.9508\n",
      "Epoch 526/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0739 - accuracy: 0.9815 - val_loss: 0.1423 - val_accuracy: 0.9515\n",
      "Epoch 527/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0737 - accuracy: 0.9805 - val_loss: 0.1437 - val_accuracy: 0.9508\n",
      "Epoch 528/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0736 - accuracy: 0.9804 - val_loss: 0.1411 - val_accuracy: 0.9535\n",
      "Epoch 529/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0736 - accuracy: 0.9808 - val_loss: 0.1457 - val_accuracy: 0.9501\n",
      "Epoch 530/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0733 - accuracy: 0.9799 - val_loss: 0.1427 - val_accuracy: 0.9511\n",
      "Epoch 531/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0733 - accuracy: 0.9815 - val_loss: 0.1399 - val_accuracy: 0.9528\n",
      "Epoch 532/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0734 - accuracy: 0.9811 - val_loss: 0.1419 - val_accuracy: 0.9525\n",
      "Epoch 533/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0734 - accuracy: 0.9799 - val_loss: 0.1430 - val_accuracy: 0.9508\n",
      "Epoch 534/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0732 - accuracy: 0.9807 - val_loss: 0.1419 - val_accuracy: 0.9522\n",
      "Epoch 535/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0733 - accuracy: 0.9811 - val_loss: 0.1473 - val_accuracy: 0.9484\n",
      "Epoch 536/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0733 - accuracy: 0.9808 - val_loss: 0.1421 - val_accuracy: 0.9511\n",
      "Epoch 537/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0731 - accuracy: 0.9805 - val_loss: 0.1444 - val_accuracy: 0.9511\n",
      "Epoch 538/600\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0732 - accuracy: 0.9811 - val_loss: 0.1415 - val_accuracy: 0.9518\n",
      "Epoch 539/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0730 - accuracy: 0.9805 - val_loss: 0.1473 - val_accuracy: 0.9474\n",
      "Epoch 540/600\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0729 - accuracy: 0.9810 - val_loss: 0.1419 - val_accuracy: 0.9511\n",
      "Epoch 541/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0727 - accuracy: 0.9800 - val_loss: 0.1399 - val_accuracy: 0.9535\n",
      "Epoch 542/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0728 - accuracy: 0.9808 - val_loss: 0.1453 - val_accuracy: 0.9498\n",
      "Epoch 543/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0729 - accuracy: 0.9803 - val_loss: 0.1396 - val_accuracy: 0.9545\n",
      "Epoch 544/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0726 - accuracy: 0.9814 - val_loss: 0.1425 - val_accuracy: 0.9518\n",
      "Epoch 545/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0726 - accuracy: 0.9807 - val_loss: 0.1410 - val_accuracy: 0.9525\n",
      "Epoch 546/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0726 - accuracy: 0.9812 - val_loss: 0.1409 - val_accuracy: 0.9518\n",
      "Epoch 547/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0726 - accuracy: 0.9811 - val_loss: 0.1441 - val_accuracy: 0.9498\n",
      "Epoch 548/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0724 - accuracy: 0.9812 - val_loss: 0.1404 - val_accuracy: 0.9528\n",
      "Epoch 549/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0725 - accuracy: 0.9804 - val_loss: 0.1437 - val_accuracy: 0.9505\n",
      "Epoch 550/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0725 - accuracy: 0.9805 - val_loss: 0.1439 - val_accuracy: 0.9511\n",
      "Epoch 551/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0724 - accuracy: 0.9814 - val_loss: 0.1388 - val_accuracy: 0.9528\n",
      "Epoch 552/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0722 - accuracy: 0.9816 - val_loss: 0.1441 - val_accuracy: 0.9508\n",
      "Epoch 553/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0721 - accuracy: 0.9807 - val_loss: 0.1446 - val_accuracy: 0.9508\n",
      "Epoch 554/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0723 - accuracy: 0.9807 - val_loss: 0.1396 - val_accuracy: 0.9542\n",
      "Epoch 555/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0720 - accuracy: 0.9811 - val_loss: 0.1395 - val_accuracy: 0.9535\n",
      "Epoch 556/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0718 - accuracy: 0.9816 - val_loss: 0.1417 - val_accuracy: 0.9515\n",
      "Epoch 557/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0720 - accuracy: 0.9811 - val_loss: 0.1418 - val_accuracy: 0.9515\n",
      "Epoch 558/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0719 - accuracy: 0.9810 - val_loss: 0.1436 - val_accuracy: 0.9505\n",
      "Epoch 559/600\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0718 - accuracy: 0.9815 - val_loss: 0.1403 - val_accuracy: 0.9528\n",
      "Epoch 560/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0717 - accuracy: 0.9812 - val_loss: 0.1426 - val_accuracy: 0.9505\n",
      "Epoch 561/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0716 - accuracy: 0.9820 - val_loss: 0.1389 - val_accuracy: 0.9545\n",
      "Epoch 562/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0716 - accuracy: 0.9816 - val_loss: 0.1423 - val_accuracy: 0.9511\n",
      "Epoch 563/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0717 - accuracy: 0.9811 - val_loss: 0.1416 - val_accuracy: 0.9518\n",
      "Epoch 564/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0716 - accuracy: 0.9810 - val_loss: 0.1393 - val_accuracy: 0.9535\n",
      "Epoch 565/600\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0715 - accuracy: 0.9808 - val_loss: 0.1418 - val_accuracy: 0.9515\n",
      "Epoch 566/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0716 - accuracy: 0.9805 - val_loss: 0.1404 - val_accuracy: 0.9522\n",
      "Epoch 567/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0714 - accuracy: 0.9825 - val_loss: 0.1396 - val_accuracy: 0.9535\n",
      "Epoch 568/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0714 - accuracy: 0.9811 - val_loss: 0.1429 - val_accuracy: 0.9505\n",
      "Epoch 569/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0715 - accuracy: 0.9811 - val_loss: 0.1431 - val_accuracy: 0.9511\n",
      "Epoch 570/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0713 - accuracy: 0.9814 - val_loss: 0.1396 - val_accuracy: 0.9535\n",
      "Epoch 571/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0712 - accuracy: 0.9810 - val_loss: 0.1420 - val_accuracy: 0.9511\n",
      "Epoch 572/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0711 - accuracy: 0.9816 - val_loss: 0.1428 - val_accuracy: 0.9505\n",
      "Epoch 573/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0710 - accuracy: 0.9815 - val_loss: 0.1394 - val_accuracy: 0.9528\n",
      "Epoch 574/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0708 - accuracy: 0.9814 - val_loss: 0.1403 - val_accuracy: 0.9525\n",
      "Epoch 575/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0710 - accuracy: 0.9818 - val_loss: 0.1399 - val_accuracy: 0.9525\n",
      "Epoch 576/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0709 - accuracy: 0.9811 - val_loss: 0.1405 - val_accuracy: 0.9518\n",
      "Epoch 577/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0708 - accuracy: 0.9825 - val_loss: 0.1412 - val_accuracy: 0.9515\n",
      "Epoch 578/600\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0708 - accuracy: 0.9822 - val_loss: 0.1397 - val_accuracy: 0.9525\n",
      "Epoch 579/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0708 - accuracy: 0.9814 - val_loss: 0.1411 - val_accuracy: 0.9515\n",
      "Epoch 580/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0708 - accuracy: 0.9812 - val_loss: 0.1405 - val_accuracy: 0.9522\n",
      "Epoch 581/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0707 - accuracy: 0.9825 - val_loss: 0.1421 - val_accuracy: 0.9505\n",
      "Epoch 582/600\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0702 - accuracy: 0.9825 - val_loss: 0.1392 - val_accuracy: 0.9535\n",
      "Epoch 583/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0705 - accuracy: 0.9815 - val_loss: 0.1392 - val_accuracy: 0.9525\n",
      "Epoch 584/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0705 - accuracy: 0.9810 - val_loss: 0.1428 - val_accuracy: 0.9505\n",
      "Epoch 585/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0703 - accuracy: 0.9827 - val_loss: 0.1424 - val_accuracy: 0.9505\n",
      "Epoch 586/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0704 - accuracy: 0.9822 - val_loss: 0.1384 - val_accuracy: 0.9539\n",
      "Epoch 587/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0703 - accuracy: 0.9815 - val_loss: 0.1417 - val_accuracy: 0.9511\n",
      "Epoch 588/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0705 - accuracy: 0.9825 - val_loss: 0.1434 - val_accuracy: 0.9505\n",
      "Epoch 589/600\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0704 - accuracy: 0.9815 - val_loss: 0.1428 - val_accuracy: 0.9505\n",
      "Epoch 590/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0701 - accuracy: 0.9816 - val_loss: 0.1400 - val_accuracy: 0.9528\n",
      "Epoch 591/600\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0701 - accuracy: 0.9823 - val_loss: 0.1374 - val_accuracy: 0.9545\n",
      "Epoch 592/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0700 - accuracy: 0.9816 - val_loss: 0.1436 - val_accuracy: 0.9498\n",
      "Epoch 593/600\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0699 - accuracy: 0.9815 - val_loss: 0.1409 - val_accuracy: 0.9515\n",
      "Epoch 594/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0700 - accuracy: 0.9811 - val_loss: 0.1386 - val_accuracy: 0.9528\n",
      "Epoch 595/600\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0701 - accuracy: 0.9816 - val_loss: 0.1399 - val_accuracy: 0.9525\n",
      "Epoch 596/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0698 - accuracy: 0.9818 - val_loss: 0.1382 - val_accuracy: 0.9535\n",
      "Epoch 597/600\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0699 - accuracy: 0.9825 - val_loss: 0.1385 - val_accuracy: 0.9539\n",
      "Epoch 598/600\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0698 - accuracy: 0.9820 - val_loss: 0.1382 - val_accuracy: 0.9535\n",
      "Epoch 599/600\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0697 - accuracy: 0.9827 - val_loss: 0.1384 - val_accuracy: 0.9539\n",
      "Epoch 600/600\n",
      "7352/7352 [==============================] - 0s 47us/step - loss: 0.0697 - accuracy: 0.9815 - val_loss: 0.1394 - val_accuracy: 0.9522\n",
      "Test score: 0.13943639911349684\n",
      "Test accuracy: 0.9521547555923462\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=600, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + SGD + Softmax + 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/1000\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 1.3133 - accuracy: 0.5171 - val_loss: 1.0264 - val_accuracy: 0.7119\n",
      "Epoch 2/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.8756 - accuracy: 0.7697 - val_loss: 0.8230 - val_accuracy: 0.7662\n",
      "Epoch 3/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.7229 - accuracy: 0.8301 - val_loss: 0.7190 - val_accuracy: 0.7842\n",
      "Epoch 4/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.6306 - accuracy: 0.8576 - val_loss: 0.6425 - val_accuracy: 0.8510\n",
      "Epoch 5/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.5697 - accuracy: 0.8702 - val_loss: 0.5935 - val_accuracy: 0.8239\n",
      "Epoch 6/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.5217 - accuracy: 0.8844 - val_loss: 0.5515 - val_accuracy: 0.8466\n",
      "Epoch 7/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.4892 - accuracy: 0.8829 - val_loss: 0.5187 - val_accuracy: 0.8521\n",
      "Epoch 8/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.4601 - accuracy: 0.8901 - val_loss: 0.4967 - val_accuracy: 0.8544\n",
      "Epoch 9/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.4363 - accuracy: 0.8917 - val_loss: 0.4776 - val_accuracy: 0.8537\n",
      "Epoch 10/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.4158 - accuracy: 0.8957 - val_loss: 0.4595 - val_accuracy: 0.8734\n",
      "Epoch 11/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3988 - accuracy: 0.8984 - val_loss: 0.4377 - val_accuracy: 0.8856\n",
      "Epoch 12/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.3842 - accuracy: 0.8996 - val_loss: 0.4232 - val_accuracy: 0.8846\n",
      "Epoch 13/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.3715 - accuracy: 0.9023 - val_loss: 0.4092 - val_accuracy: 0.8863\n",
      "Epoch 14/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.3594 - accuracy: 0.9030 - val_loss: 0.4010 - val_accuracy: 0.8772\n",
      "Epoch 15/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3489 - accuracy: 0.9052 - val_loss: 0.3929 - val_accuracy: 0.8768\n",
      "Epoch 16/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3399 - accuracy: 0.9056 - val_loss: 0.3810 - val_accuracy: 0.8880\n",
      "Epoch 17/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.3304 - accuracy: 0.9095 - val_loss: 0.3722 - val_accuracy: 0.8846\n",
      "Epoch 18/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.3234 - accuracy: 0.9098 - val_loss: 0.3655 - val_accuracy: 0.8928\n",
      "Epoch 19/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.3159 - accuracy: 0.9117 - val_loss: 0.3588 - val_accuracy: 0.8880\n",
      "Epoch 20/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3091 - accuracy: 0.9138 - val_loss: 0.3568 - val_accuracy: 0.8850\n",
      "Epoch 21/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.3038 - accuracy: 0.9144 - val_loss: 0.3476 - val_accuracy: 0.9036\n",
      "Epoch 22/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2969 - accuracy: 0.9154 - val_loss: 0.3407 - val_accuracy: 0.9006\n",
      "Epoch 23/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2919 - accuracy: 0.9174 - val_loss: 0.3355 - val_accuracy: 0.9023\n",
      "Epoch 24/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2866 - accuracy: 0.9184 - val_loss: 0.3290 - val_accuracy: 0.9009\n",
      "Epoch 25/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2818 - accuracy: 0.9210 - val_loss: 0.3239 - val_accuracy: 0.9050\n",
      "Epoch 26/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2770 - accuracy: 0.9196 - val_loss: 0.3205 - val_accuracy: 0.9030\n",
      "Epoch 27/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2725 - accuracy: 0.9219 - val_loss: 0.3181 - val_accuracy: 0.8999\n",
      "Epoch 28/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.2683 - accuracy: 0.9237 - val_loss: 0.3140 - val_accuracy: 0.9002\n",
      "Epoch 29/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2640 - accuracy: 0.9256 - val_loss: 0.3098 - val_accuracy: 0.9067\n",
      "Epoch 30/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2603 - accuracy: 0.9256 - val_loss: 0.3033 - val_accuracy: 0.9097\n",
      "Epoch 31/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2569 - accuracy: 0.9271 - val_loss: 0.3006 - val_accuracy: 0.9165\n",
      "Epoch 32/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2535 - accuracy: 0.9280 - val_loss: 0.3015 - val_accuracy: 0.9097\n",
      "Epoch 33/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2509 - accuracy: 0.9278 - val_loss: 0.2932 - val_accuracy: 0.9179\n",
      "Epoch 34/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2472 - accuracy: 0.9313 - val_loss: 0.2875 - val_accuracy: 0.9182\n",
      "Epoch 35/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2435 - accuracy: 0.9325 - val_loss: 0.2927 - val_accuracy: 0.9087\n",
      "Epoch 36/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2416 - accuracy: 0.9314 - val_loss: 0.2881 - val_accuracy: 0.9111\n",
      "Epoch 37/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2380 - accuracy: 0.9344 - val_loss: 0.2839 - val_accuracy: 0.9182\n",
      "Epoch 38/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2359 - accuracy: 0.9321 - val_loss: 0.2825 - val_accuracy: 0.9203\n",
      "Epoch 39/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2334 - accuracy: 0.9327 - val_loss: 0.2802 - val_accuracy: 0.9182\n",
      "Epoch 40/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.2305 - accuracy: 0.9353 - val_loss: 0.2777 - val_accuracy: 0.9192\n",
      "Epoch 41/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2283 - accuracy: 0.9348 - val_loss: 0.2713 - val_accuracy: 0.9230\n",
      "Epoch 42/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2255 - accuracy: 0.9365 - val_loss: 0.2827 - val_accuracy: 0.9050\n",
      "Epoch 43/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2238 - accuracy: 0.9362 - val_loss: 0.2724 - val_accuracy: 0.9213\n",
      "Epoch 44/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.2212 - accuracy: 0.9372 - val_loss: 0.2726 - val_accuracy: 0.9158\n",
      "Epoch 45/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2195 - accuracy: 0.9374 - val_loss: 0.2686 - val_accuracy: 0.9179\n",
      "Epoch 46/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2173 - accuracy: 0.9391 - val_loss: 0.2638 - val_accuracy: 0.9237\n",
      "Epoch 47/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2152 - accuracy: 0.9382 - val_loss: 0.2612 - val_accuracy: 0.9223\n",
      "Epoch 48/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2133 - accuracy: 0.9384 - val_loss: 0.2653 - val_accuracy: 0.9138\n",
      "Epoch 49/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2117 - accuracy: 0.9406 - val_loss: 0.2562 - val_accuracy: 0.9270\n",
      "Epoch 50/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.2091 - accuracy: 0.9410 - val_loss: 0.2570 - val_accuracy: 0.9243\n",
      "Epoch 51/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2079 - accuracy: 0.9416 - val_loss: 0.2542 - val_accuracy: 0.9267\n",
      "Epoch 52/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.2061 - accuracy: 0.9421 - val_loss: 0.2506 - val_accuracy: 0.9308\n",
      "Epoch 53/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2045 - accuracy: 0.9442 - val_loss: 0.2534 - val_accuracy: 0.9230\n",
      "Epoch 54/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2029 - accuracy: 0.9434 - val_loss: 0.2534 - val_accuracy: 0.9216\n",
      "Epoch 55/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.2009 - accuracy: 0.9434 - val_loss: 0.2501 - val_accuracy: 0.9247\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1995 - accuracy: 0.9444 - val_loss: 0.2494 - val_accuracy: 0.9237\n",
      "Epoch 57/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1982 - accuracy: 0.9433 - val_loss: 0.2469 - val_accuracy: 0.9260\n",
      "Epoch 58/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1962 - accuracy: 0.9448 - val_loss: 0.2425 - val_accuracy: 0.9321\n",
      "Epoch 59/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1947 - accuracy: 0.9461 - val_loss: 0.2460 - val_accuracy: 0.9250\n",
      "Epoch 60/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1937 - accuracy: 0.9460 - val_loss: 0.2426 - val_accuracy: 0.9260\n",
      "Epoch 61/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1921 - accuracy: 0.9464 - val_loss: 0.2419 - val_accuracy: 0.9267\n",
      "Epoch 62/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1906 - accuracy: 0.9476 - val_loss: 0.2393 - val_accuracy: 0.9291\n",
      "Epoch 63/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1898 - accuracy: 0.9467 - val_loss: 0.2355 - val_accuracy: 0.9338\n",
      "Epoch 64/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1878 - accuracy: 0.9490 - val_loss: 0.2327 - val_accuracy: 0.9355\n",
      "Epoch 65/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1868 - accuracy: 0.9505 - val_loss: 0.2333 - val_accuracy: 0.9315\n",
      "Epoch 66/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1855 - accuracy: 0.9491 - val_loss: 0.2373 - val_accuracy: 0.9274\n",
      "Epoch 67/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1840 - accuracy: 0.9491 - val_loss: 0.2417 - val_accuracy: 0.9192\n",
      "Epoch 68/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1833 - accuracy: 0.9502 - val_loss: 0.2318 - val_accuracy: 0.9318\n",
      "Epoch 69/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1819 - accuracy: 0.9510 - val_loss: 0.2295 - val_accuracy: 0.9321\n",
      "Epoch 70/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1812 - accuracy: 0.9512 - val_loss: 0.2298 - val_accuracy: 0.9328\n",
      "Epoch 71/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1794 - accuracy: 0.9517 - val_loss: 0.2278 - val_accuracy: 0.9318\n",
      "Epoch 72/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1788 - accuracy: 0.9512 - val_loss: 0.2374 - val_accuracy: 0.9199\n",
      "Epoch 73/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1776 - accuracy: 0.9508 - val_loss: 0.2296 - val_accuracy: 0.9281\n",
      "Epoch 74/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1769 - accuracy: 0.9513 - val_loss: 0.2259 - val_accuracy: 0.9325\n",
      "Epoch 75/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1754 - accuracy: 0.9518 - val_loss: 0.2260 - val_accuracy: 0.9304\n",
      "Epoch 76/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1744 - accuracy: 0.9532 - val_loss: 0.2234 - val_accuracy: 0.9335\n",
      "Epoch 77/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1732 - accuracy: 0.9533 - val_loss: 0.2229 - val_accuracy: 0.9338\n",
      "Epoch 78/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1725 - accuracy: 0.9533 - val_loss: 0.2206 - val_accuracy: 0.9355\n",
      "Epoch 79/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1711 - accuracy: 0.9540 - val_loss: 0.2213 - val_accuracy: 0.9338\n",
      "Epoch 80/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1702 - accuracy: 0.9532 - val_loss: 0.2210 - val_accuracy: 0.9338\n",
      "Epoch 81/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1691 - accuracy: 0.9542 - val_loss: 0.2233 - val_accuracy: 0.9291\n",
      "Epoch 82/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1686 - accuracy: 0.9554 - val_loss: 0.2223 - val_accuracy: 0.9294\n",
      "Epoch 83/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1675 - accuracy: 0.9539 - val_loss: 0.2181 - val_accuracy: 0.9342\n",
      "Epoch 84/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1671 - accuracy: 0.9553 - val_loss: 0.2184 - val_accuracy: 0.9332\n",
      "Epoch 85/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1660 - accuracy: 0.9542 - val_loss: 0.2199 - val_accuracy: 0.9301\n",
      "Epoch 86/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1649 - accuracy: 0.9554 - val_loss: 0.2160 - val_accuracy: 0.9348\n",
      "Epoch 87/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1640 - accuracy: 0.9559 - val_loss: 0.2140 - val_accuracy: 0.9362\n",
      "Epoch 88/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1635 - accuracy: 0.9561 - val_loss: 0.2184 - val_accuracy: 0.9294\n",
      "Epoch 89/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1624 - accuracy: 0.9555 - val_loss: 0.2131 - val_accuracy: 0.9355\n",
      "Epoch 90/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1618 - accuracy: 0.9570 - val_loss: 0.2228 - val_accuracy: 0.9237\n",
      "Epoch 91/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1610 - accuracy: 0.9567 - val_loss: 0.2126 - val_accuracy: 0.9362\n",
      "Epoch 92/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1599 - accuracy: 0.9566 - val_loss: 0.2133 - val_accuracy: 0.9321\n",
      "Epoch 93/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1594 - accuracy: 0.9573 - val_loss: 0.2086 - val_accuracy: 0.9379\n",
      "Epoch 94/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1586 - accuracy: 0.9584 - val_loss: 0.2102 - val_accuracy: 0.9365\n",
      "Epoch 95/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1577 - accuracy: 0.9584 - val_loss: 0.2095 - val_accuracy: 0.9372\n",
      "Epoch 96/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1572 - accuracy: 0.9599 - val_loss: 0.2074 - val_accuracy: 0.9382\n",
      "Epoch 97/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1565 - accuracy: 0.9589 - val_loss: 0.2071 - val_accuracy: 0.9379\n",
      "Epoch 98/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1556 - accuracy: 0.9601 - val_loss: 0.2047 - val_accuracy: 0.9393\n",
      "Epoch 99/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1548 - accuracy: 0.9587 - val_loss: 0.2074 - val_accuracy: 0.9342\n",
      "Epoch 100/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1543 - accuracy: 0.9581 - val_loss: 0.2055 - val_accuracy: 0.9389\n",
      "Epoch 101/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1534 - accuracy: 0.9597 - val_loss: 0.2030 - val_accuracy: 0.9386\n",
      "Epoch 102/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1526 - accuracy: 0.9588 - val_loss: 0.2065 - val_accuracy: 0.9338\n",
      "Epoch 103/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1519 - accuracy: 0.9604 - val_loss: 0.2050 - val_accuracy: 0.9352\n",
      "Epoch 104/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1516 - accuracy: 0.9589 - val_loss: 0.2065 - val_accuracy: 0.9342\n",
      "Epoch 105/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1509 - accuracy: 0.9599 - val_loss: 0.2040 - val_accuracy: 0.9348\n",
      "Epoch 106/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1503 - accuracy: 0.9610 - val_loss: 0.2017 - val_accuracy: 0.9382\n",
      "Epoch 107/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1496 - accuracy: 0.9606 - val_loss: 0.2001 - val_accuracy: 0.9399\n",
      "Epoch 108/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1490 - accuracy: 0.9606 - val_loss: 0.2013 - val_accuracy: 0.9396\n",
      "Epoch 109/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1480 - accuracy: 0.9610 - val_loss: 0.2053 - val_accuracy: 0.9321\n",
      "Epoch 110/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1479 - accuracy: 0.9612 - val_loss: 0.2026 - val_accuracy: 0.9352\n",
      "Epoch 111/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1475 - accuracy: 0.9614 - val_loss: 0.2039 - val_accuracy: 0.9328\n",
      "Epoch 112/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1469 - accuracy: 0.9611 - val_loss: 0.1979 - val_accuracy: 0.9396\n",
      "Epoch 113/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1460 - accuracy: 0.9629 - val_loss: 0.2018 - val_accuracy: 0.9369\n",
      "Epoch 114/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1452 - accuracy: 0.9622 - val_loss: 0.1964 - val_accuracy: 0.9406\n",
      "Epoch 115/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1447 - accuracy: 0.9616 - val_loss: 0.2029 - val_accuracy: 0.9328\n",
      "Epoch 116/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1445 - accuracy: 0.9623 - val_loss: 0.1957 - val_accuracy: 0.9396\n",
      "Epoch 117/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1433 - accuracy: 0.9626 - val_loss: 0.1945 - val_accuracy: 0.9410\n",
      "Epoch 118/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1431 - accuracy: 0.9626 - val_loss: 0.1941 - val_accuracy: 0.9396\n",
      "Epoch 119/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1427 - accuracy: 0.9627 - val_loss: 0.1986 - val_accuracy: 0.9369\n",
      "Epoch 120/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1423 - accuracy: 0.9623 - val_loss: 0.1944 - val_accuracy: 0.9396\n",
      "Epoch 121/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1416 - accuracy: 0.9627 - val_loss: 0.1937 - val_accuracy: 0.9413\n",
      "Epoch 122/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1410 - accuracy: 0.9634 - val_loss: 0.1948 - val_accuracy: 0.9389\n",
      "Epoch 123/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1405 - accuracy: 0.9630 - val_loss: 0.1925 - val_accuracy: 0.9406\n",
      "Epoch 124/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1401 - accuracy: 0.9646 - val_loss: 0.1932 - val_accuracy: 0.9399\n",
      "Epoch 125/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1396 - accuracy: 0.9631 - val_loss: 0.1942 - val_accuracy: 0.9403\n",
      "Epoch 126/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1391 - accuracy: 0.9631 - val_loss: 0.1946 - val_accuracy: 0.9393\n",
      "Epoch 127/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1386 - accuracy: 0.9644 - val_loss: 0.1942 - val_accuracy: 0.9396\n",
      "Epoch 128/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1379 - accuracy: 0.9631 - val_loss: 0.1927 - val_accuracy: 0.9396\n",
      "Epoch 129/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1375 - accuracy: 0.9646 - val_loss: 0.1923 - val_accuracy: 0.9403\n",
      "Epoch 130/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1372 - accuracy: 0.9629 - val_loss: 0.1896 - val_accuracy: 0.9410\n",
      "Epoch 131/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1364 - accuracy: 0.9648 - val_loss: 0.1904 - val_accuracy: 0.9396\n",
      "Epoch 132/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1363 - accuracy: 0.9630 - val_loss: 0.1875 - val_accuracy: 0.9399\n",
      "Epoch 133/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1357 - accuracy: 0.9645 - val_loss: 0.1876 - val_accuracy: 0.9403\n",
      "Epoch 134/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1354 - accuracy: 0.9642 - val_loss: 0.1901 - val_accuracy: 0.9399\n",
      "Epoch 135/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1347 - accuracy: 0.9635 - val_loss: 0.1877 - val_accuracy: 0.9416\n",
      "Epoch 136/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1341 - accuracy: 0.9645 - val_loss: 0.1887 - val_accuracy: 0.9416\n",
      "Epoch 137/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1340 - accuracy: 0.9641 - val_loss: 0.1940 - val_accuracy: 0.9335\n",
      "Epoch 138/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1335 - accuracy: 0.9644 - val_loss: 0.1911 - val_accuracy: 0.9379\n",
      "Epoch 139/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1329 - accuracy: 0.9652 - val_loss: 0.1882 - val_accuracy: 0.9416\n",
      "Epoch 140/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1326 - accuracy: 0.9645 - val_loss: 0.1864 - val_accuracy: 0.9403\n",
      "Epoch 141/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1320 - accuracy: 0.9656 - val_loss: 0.1894 - val_accuracy: 0.9372\n",
      "Epoch 142/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1320 - accuracy: 0.9660 - val_loss: 0.1860 - val_accuracy: 0.9420\n",
      "Epoch 143/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1312 - accuracy: 0.9653 - val_loss: 0.1879 - val_accuracy: 0.9382\n",
      "Epoch 144/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1308 - accuracy: 0.9656 - val_loss: 0.1886 - val_accuracy: 0.9379\n",
      "Epoch 145/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1304 - accuracy: 0.9650 - val_loss: 0.1866 - val_accuracy: 0.9403\n",
      "Epoch 146/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1299 - accuracy: 0.9667 - val_loss: 0.1882 - val_accuracy: 0.9396\n",
      "Epoch 147/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1296 - accuracy: 0.9659 - val_loss: 0.1836 - val_accuracy: 0.9427\n",
      "Epoch 148/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1292 - accuracy: 0.9665 - val_loss: 0.1838 - val_accuracy: 0.9406\n",
      "Epoch 149/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1287 - accuracy: 0.9657 - val_loss: 0.1873 - val_accuracy: 0.9376\n",
      "Epoch 150/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1284 - accuracy: 0.9667 - val_loss: 0.1831 - val_accuracy: 0.9413\n",
      "Epoch 151/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1282 - accuracy: 0.9653 - val_loss: 0.1828 - val_accuracy: 0.9423\n",
      "Epoch 152/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1275 - accuracy: 0.9661 - val_loss: 0.1839 - val_accuracy: 0.9420\n",
      "Epoch 153/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1273 - accuracy: 0.9660 - val_loss: 0.1818 - val_accuracy: 0.9423\n",
      "Epoch 154/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1271 - accuracy: 0.9665 - val_loss: 0.1881 - val_accuracy: 0.9355\n",
      "Epoch 155/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1267 - accuracy: 0.9676 - val_loss: 0.1843 - val_accuracy: 0.9406\n",
      "Epoch 156/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1261 - accuracy: 0.9675 - val_loss: 0.1804 - val_accuracy: 0.9430\n",
      "Epoch 157/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1261 - accuracy: 0.9661 - val_loss: 0.1804 - val_accuracy: 0.9423\n",
      "Epoch 158/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1256 - accuracy: 0.9665 - val_loss: 0.1818 - val_accuracy: 0.9416\n",
      "Epoch 159/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1250 - accuracy: 0.9676 - val_loss: 0.1838 - val_accuracy: 0.9403\n",
      "Epoch 160/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1249 - accuracy: 0.9676 - val_loss: 0.1835 - val_accuracy: 0.9399\n",
      "Epoch 161/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1244 - accuracy: 0.9667 - val_loss: 0.1842 - val_accuracy: 0.9396\n",
      "Epoch 162/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1242 - accuracy: 0.9679 - val_loss: 0.1787 - val_accuracy: 0.9413\n",
      "Epoch 163/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1238 - accuracy: 0.9680 - val_loss: 0.1797 - val_accuracy: 0.9413\n",
      "Epoch 164/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1232 - accuracy: 0.9674 - val_loss: 0.1828 - val_accuracy: 0.9410\n",
      "Epoch 165/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.1232 - accuracy: 0.9676 - val_loss: 0.1837 - val_accuracy: 0.9393\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1226 - accuracy: 0.9676 - val_loss: 0.1819 - val_accuracy: 0.9410\n",
      "Epoch 167/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1224 - accuracy: 0.9684 - val_loss: 0.1786 - val_accuracy: 0.9416\n",
      "Epoch 168/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1221 - accuracy: 0.9683 - val_loss: 0.1823 - val_accuracy: 0.9403\n",
      "Epoch 169/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1218 - accuracy: 0.9680 - val_loss: 0.1848 - val_accuracy: 0.9379\n",
      "Epoch 170/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1214 - accuracy: 0.9682 - val_loss: 0.1825 - val_accuracy: 0.9393\n",
      "Epoch 171/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1212 - accuracy: 0.9678 - val_loss: 0.1801 - val_accuracy: 0.9403\n",
      "Epoch 172/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1207 - accuracy: 0.9687 - val_loss: 0.1801 - val_accuracy: 0.9416\n",
      "Epoch 173/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1204 - accuracy: 0.9691 - val_loss: 0.1767 - val_accuracy: 0.9423\n",
      "Epoch 174/1000\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.1200 - accuracy: 0.9675 - val_loss: 0.1823 - val_accuracy: 0.9393\n",
      "Epoch 175/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1197 - accuracy: 0.9693 - val_loss: 0.1800 - val_accuracy: 0.9399\n",
      "Epoch 176/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1194 - accuracy: 0.9686 - val_loss: 0.1821 - val_accuracy: 0.9376\n",
      "Epoch 177/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1191 - accuracy: 0.9690 - val_loss: 0.1745 - val_accuracy: 0.9440\n",
      "Epoch 178/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1189 - accuracy: 0.9694 - val_loss: 0.1760 - val_accuracy: 0.9437\n",
      "Epoch 179/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1187 - accuracy: 0.9697 - val_loss: 0.1750 - val_accuracy: 0.9440\n",
      "Epoch 180/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1181 - accuracy: 0.9698 - val_loss: 0.1750 - val_accuracy: 0.9444\n",
      "Epoch 181/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1181 - accuracy: 0.9695 - val_loss: 0.1742 - val_accuracy: 0.9447\n",
      "Epoch 182/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1181 - accuracy: 0.9689 - val_loss: 0.1761 - val_accuracy: 0.9420\n",
      "Epoch 183/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1174 - accuracy: 0.9699 - val_loss: 0.1759 - val_accuracy: 0.9423\n",
      "Epoch 184/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1173 - accuracy: 0.9702 - val_loss: 0.1739 - val_accuracy: 0.9427\n",
      "Epoch 185/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1170 - accuracy: 0.9701 - val_loss: 0.1742 - val_accuracy: 0.9427\n",
      "Epoch 186/1000\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.1164 - accuracy: 0.9698 - val_loss: 0.1794 - val_accuracy: 0.9399\n",
      "Epoch 187/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1164 - accuracy: 0.9699 - val_loss: 0.1745 - val_accuracy: 0.9447\n",
      "Epoch 188/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1160 - accuracy: 0.9702 - val_loss: 0.1721 - val_accuracy: 0.9430\n",
      "Epoch 189/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1156 - accuracy: 0.9698 - val_loss: 0.1780 - val_accuracy: 0.9399\n",
      "Epoch 190/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.1154 - accuracy: 0.9710 - val_loss: 0.1737 - val_accuracy: 0.9430\n",
      "Epoch 191/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1153 - accuracy: 0.9694 - val_loss: 0.1733 - val_accuracy: 0.9423\n",
      "Epoch 192/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1150 - accuracy: 0.9712 - val_loss: 0.1722 - val_accuracy: 0.9450\n",
      "Epoch 193/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1145 - accuracy: 0.9705 - val_loss: 0.1734 - val_accuracy: 0.9427\n",
      "Epoch 194/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1144 - accuracy: 0.9697 - val_loss: 0.1760 - val_accuracy: 0.9416\n",
      "Epoch 195/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1141 - accuracy: 0.9702 - val_loss: 0.1719 - val_accuracy: 0.9433\n",
      "Epoch 196/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1139 - accuracy: 0.9699 - val_loss: 0.1710 - val_accuracy: 0.9444\n",
      "Epoch 197/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1134 - accuracy: 0.9708 - val_loss: 0.1698 - val_accuracy: 0.9460\n",
      "Epoch 198/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1133 - accuracy: 0.9697 - val_loss: 0.1741 - val_accuracy: 0.9430\n",
      "Epoch 199/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1130 - accuracy: 0.9713 - val_loss: 0.1715 - val_accuracy: 0.9433\n",
      "Epoch 200/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1130 - accuracy: 0.9713 - val_loss: 0.1746 - val_accuracy: 0.9413\n",
      "Epoch 201/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1128 - accuracy: 0.9708 - val_loss: 0.1693 - val_accuracy: 0.9467\n",
      "Epoch 202/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1124 - accuracy: 0.9712 - val_loss: 0.1699 - val_accuracy: 0.9447\n",
      "Epoch 203/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1122 - accuracy: 0.9708 - val_loss: 0.1710 - val_accuracy: 0.9423\n",
      "Epoch 204/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1115 - accuracy: 0.9710 - val_loss: 0.1694 - val_accuracy: 0.9437\n",
      "Epoch 205/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1116 - accuracy: 0.9705 - val_loss: 0.1731 - val_accuracy: 0.9427\n",
      "Epoch 206/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1113 - accuracy: 0.9703 - val_loss: 0.1690 - val_accuracy: 0.9454\n",
      "Epoch 207/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1114 - accuracy: 0.9706 - val_loss: 0.1690 - val_accuracy: 0.9440\n",
      "Epoch 208/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1110 - accuracy: 0.9712 - val_loss: 0.1702 - val_accuracy: 0.9423\n",
      "Epoch 209/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1107 - accuracy: 0.9706 - val_loss: 0.1685 - val_accuracy: 0.9460\n",
      "Epoch 210/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1103 - accuracy: 0.9713 - val_loss: 0.1699 - val_accuracy: 0.9433\n",
      "Epoch 211/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1100 - accuracy: 0.9709 - val_loss: 0.1692 - val_accuracy: 0.9444\n",
      "Epoch 212/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1098 - accuracy: 0.9716 - val_loss: 0.1726 - val_accuracy: 0.9433\n",
      "Epoch 213/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1098 - accuracy: 0.9714 - val_loss: 0.1718 - val_accuracy: 0.9427\n",
      "Epoch 214/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1095 - accuracy: 0.9721 - val_loss: 0.1696 - val_accuracy: 0.9427\n",
      "Epoch 215/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1094 - accuracy: 0.9717 - val_loss: 0.1704 - val_accuracy: 0.9447\n",
      "Epoch 216/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1088 - accuracy: 0.9716 - val_loss: 0.1692 - val_accuracy: 0.9444\n",
      "Epoch 217/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1091 - accuracy: 0.9718 - val_loss: 0.1687 - val_accuracy: 0.9433\n",
      "Epoch 218/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1086 - accuracy: 0.9729 - val_loss: 0.1712 - val_accuracy: 0.9427\n",
      "Epoch 219/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1082 - accuracy: 0.9727 - val_loss: 0.1689 - val_accuracy: 0.9430\n",
      "Epoch 220/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1081 - accuracy: 0.9718 - val_loss: 0.1735 - val_accuracy: 0.9403\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1080 - accuracy: 0.9720 - val_loss: 0.1680 - val_accuracy: 0.9444\n",
      "Epoch 222/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1076 - accuracy: 0.9712 - val_loss: 0.1684 - val_accuracy: 0.9437\n",
      "Epoch 223/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1075 - accuracy: 0.9721 - val_loss: 0.1667 - val_accuracy: 0.9457\n",
      "Epoch 224/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1070 - accuracy: 0.9725 - val_loss: 0.1697 - val_accuracy: 0.9440\n",
      "Epoch 225/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1071 - accuracy: 0.9729 - val_loss: 0.1675 - val_accuracy: 0.9440\n",
      "Epoch 226/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.1069 - accuracy: 0.9720 - val_loss: 0.1679 - val_accuracy: 0.9430\n",
      "Epoch 227/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1067 - accuracy: 0.9720 - val_loss: 0.1697 - val_accuracy: 0.9423\n",
      "Epoch 228/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1064 - accuracy: 0.9727 - val_loss: 0.1728 - val_accuracy: 0.9406\n",
      "Epoch 229/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1061 - accuracy: 0.9724 - val_loss: 0.1688 - val_accuracy: 0.9440\n",
      "Epoch 230/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1060 - accuracy: 0.9725 - val_loss: 0.1656 - val_accuracy: 0.9457\n",
      "Epoch 231/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1060 - accuracy: 0.9732 - val_loss: 0.1701 - val_accuracy: 0.9420\n",
      "Epoch 232/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.1055 - accuracy: 0.9733 - val_loss: 0.1672 - val_accuracy: 0.9440\n",
      "Epoch 233/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1053 - accuracy: 0.9733 - val_loss: 0.1639 - val_accuracy: 0.9474\n",
      "Epoch 234/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1053 - accuracy: 0.9727 - val_loss: 0.1680 - val_accuracy: 0.9427\n",
      "Epoch 235/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1049 - accuracy: 0.9729 - val_loss: 0.1655 - val_accuracy: 0.9447\n",
      "Epoch 236/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1048 - accuracy: 0.9735 - val_loss: 0.1655 - val_accuracy: 0.9444\n",
      "Epoch 237/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1044 - accuracy: 0.9732 - val_loss: 0.1664 - val_accuracy: 0.9450\n",
      "Epoch 238/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1043 - accuracy: 0.9733 - val_loss: 0.1654 - val_accuracy: 0.9454\n",
      "Epoch 239/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1044 - accuracy: 0.9729 - val_loss: 0.1645 - val_accuracy: 0.9467\n",
      "Epoch 240/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1039 - accuracy: 0.9727 - val_loss: 0.1682 - val_accuracy: 0.9420\n",
      "Epoch 241/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1037 - accuracy: 0.9740 - val_loss: 0.1632 - val_accuracy: 0.9464\n",
      "Epoch 242/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1035 - accuracy: 0.9728 - val_loss: 0.1669 - val_accuracy: 0.9440\n",
      "Epoch 243/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1037 - accuracy: 0.9732 - val_loss: 0.1635 - val_accuracy: 0.9467\n",
      "Epoch 244/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1032 - accuracy: 0.9725 - val_loss: 0.1655 - val_accuracy: 0.9444\n",
      "Epoch 245/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1029 - accuracy: 0.9744 - val_loss: 0.1630 - val_accuracy: 0.9481\n",
      "Epoch 246/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1026 - accuracy: 0.9736 - val_loss: 0.1618 - val_accuracy: 0.9474\n",
      "Epoch 247/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.1030 - accuracy: 0.9721 - val_loss: 0.1637 - val_accuracy: 0.9467\n",
      "Epoch 248/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1023 - accuracy: 0.9739 - val_loss: 0.1628 - val_accuracy: 0.9481\n",
      "Epoch 249/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1023 - accuracy: 0.9736 - val_loss: 0.1628 - val_accuracy: 0.9460\n",
      "Epoch 250/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1021 - accuracy: 0.9739 - val_loss: 0.1633 - val_accuracy: 0.9464\n",
      "Epoch 251/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1019 - accuracy: 0.9739 - val_loss: 0.1608 - val_accuracy: 0.9481\n",
      "Epoch 252/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1016 - accuracy: 0.9731 - val_loss: 0.1632 - val_accuracy: 0.9454\n",
      "Epoch 253/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.1014 - accuracy: 0.9742 - val_loss: 0.1634 - val_accuracy: 0.9457\n",
      "Epoch 254/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1012 - accuracy: 0.9744 - val_loss: 0.1608 - val_accuracy: 0.9481\n",
      "Epoch 255/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1013 - accuracy: 0.9747 - val_loss: 0.1659 - val_accuracy: 0.9450\n",
      "Epoch 256/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1008 - accuracy: 0.9733 - val_loss: 0.1690 - val_accuracy: 0.9416\n",
      "Epoch 257/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1009 - accuracy: 0.9746 - val_loss: 0.1609 - val_accuracy: 0.9484\n",
      "Epoch 258/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.1005 - accuracy: 0.9750 - val_loss: 0.1607 - val_accuracy: 0.9481\n",
      "Epoch 259/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1006 - accuracy: 0.9736 - val_loss: 0.1658 - val_accuracy: 0.9437\n",
      "Epoch 260/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.1003 - accuracy: 0.9744 - val_loss: 0.1609 - val_accuracy: 0.9494\n",
      "Epoch 261/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.1000 - accuracy: 0.9739 - val_loss: 0.1615 - val_accuracy: 0.9484\n",
      "Epoch 262/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0998 - accuracy: 0.9742 - val_loss: 0.1635 - val_accuracy: 0.9440\n",
      "Epoch 263/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0995 - accuracy: 0.9748 - val_loss: 0.1627 - val_accuracy: 0.9447\n",
      "Epoch 264/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0995 - accuracy: 0.9752 - val_loss: 0.1610 - val_accuracy: 0.9464\n",
      "Epoch 265/1000\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.0995 - accuracy: 0.9740 - val_loss: 0.1630 - val_accuracy: 0.9437\n",
      "Epoch 266/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.97 - 0s 39us/step - loss: 0.0992 - accuracy: 0.9744 - val_loss: 0.1655 - val_accuracy: 0.9444\n",
      "Epoch 267/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0989 - accuracy: 0.9740 - val_loss: 0.1587 - val_accuracy: 0.9481\n",
      "Epoch 268/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0991 - accuracy: 0.9754 - val_loss: 0.1600 - val_accuracy: 0.9491\n",
      "Epoch 269/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0986 - accuracy: 0.9754 - val_loss: 0.1610 - val_accuracy: 0.9457\n",
      "Epoch 270/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0987 - accuracy: 0.9751 - val_loss: 0.1623 - val_accuracy: 0.9457\n",
      "Epoch 271/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0983 - accuracy: 0.9754 - val_loss: 0.1625 - val_accuracy: 0.9450\n",
      "Epoch 272/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.97 - 0s 39us/step - loss: 0.0983 - accuracy: 0.9748 - val_loss: 0.1597 - val_accuracy: 0.9498\n",
      "Epoch 273/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0978 - accuracy: 0.9751 - val_loss: 0.1700 - val_accuracy: 0.9403\n",
      "Epoch 274/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0980 - accuracy: 0.9752 - val_loss: 0.1614 - val_accuracy: 0.9457\n",
      "Epoch 275/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0977 - accuracy: 0.9740 - val_loss: 0.1595 - val_accuracy: 0.9477\n",
      "Epoch 276/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0978 - accuracy: 0.9747 - val_loss: 0.1604 - val_accuracy: 0.9464\n",
      "Epoch 277/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0974 - accuracy: 0.9755 - val_loss: 0.1588 - val_accuracy: 0.9491\n",
      "Epoch 278/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0973 - accuracy: 0.9747 - val_loss: 0.1595 - val_accuracy: 0.9464\n",
      "Epoch 279/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0972 - accuracy: 0.9751 - val_loss: 0.1600 - val_accuracy: 0.9460\n",
      "Epoch 280/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0970 - accuracy: 0.9750 - val_loss: 0.1608 - val_accuracy: 0.9457\n",
      "Epoch 281/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0970 - accuracy: 0.9752 - val_loss: 0.1619 - val_accuracy: 0.9447\n",
      "Epoch 282/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0968 - accuracy: 0.9755 - val_loss: 0.1604 - val_accuracy: 0.9457\n",
      "Epoch 283/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0964 - accuracy: 0.9757 - val_loss: 0.1579 - val_accuracy: 0.9494\n",
      "Epoch 284/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0964 - accuracy: 0.9754 - val_loss: 0.1575 - val_accuracy: 0.9498\n",
      "Epoch 285/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0961 - accuracy: 0.9758 - val_loss: 0.1602 - val_accuracy: 0.9454\n",
      "Epoch 286/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0961 - accuracy: 0.9751 - val_loss: 0.1594 - val_accuracy: 0.9460\n",
      "Epoch 287/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0960 - accuracy: 0.9759 - val_loss: 0.1589 - val_accuracy: 0.9467\n",
      "Epoch 288/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0958 - accuracy: 0.9755 - val_loss: 0.1602 - val_accuracy: 0.9457\n",
      "Epoch 289/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0954 - accuracy: 0.9755 - val_loss: 0.1568 - val_accuracy: 0.9488\n",
      "Epoch 290/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0955 - accuracy: 0.9761 - val_loss: 0.1584 - val_accuracy: 0.9484\n",
      "Epoch 291/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0955 - accuracy: 0.9761 - val_loss: 0.1600 - val_accuracy: 0.9454\n",
      "Epoch 292/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0952 - accuracy: 0.9758 - val_loss: 0.1560 - val_accuracy: 0.9498\n",
      "Epoch 293/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0952 - accuracy: 0.9754 - val_loss: 0.1596 - val_accuracy: 0.9454\n",
      "Epoch 294/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0951 - accuracy: 0.9754 - val_loss: 0.1587 - val_accuracy: 0.9457\n",
      "Epoch 295/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0949 - accuracy: 0.9762 - val_loss: 0.1579 - val_accuracy: 0.9464\n",
      "Epoch 296/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0946 - accuracy: 0.9763 - val_loss: 0.1577 - val_accuracy: 0.9464\n",
      "Epoch 297/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0945 - accuracy: 0.9759 - val_loss: 0.1561 - val_accuracy: 0.9494\n",
      "Epoch 298/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0944 - accuracy: 0.9754 - val_loss: 0.1573 - val_accuracy: 0.9477\n",
      "Epoch 299/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0943 - accuracy: 0.9758 - val_loss: 0.1578 - val_accuracy: 0.9457\n",
      "Epoch 300/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0941 - accuracy: 0.9771 - val_loss: 0.1580 - val_accuracy: 0.9464\n",
      "Epoch 301/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0938 - accuracy: 0.9765 - val_loss: 0.1562 - val_accuracy: 0.9501\n",
      "Epoch 302/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0938 - accuracy: 0.9755 - val_loss: 0.1600 - val_accuracy: 0.9467\n",
      "Epoch 303/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0938 - accuracy: 0.9771 - val_loss: 0.1617 - val_accuracy: 0.9460\n",
      "Epoch 304/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0934 - accuracy: 0.9755 - val_loss: 0.1561 - val_accuracy: 0.9488\n",
      "Epoch 305/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0935 - accuracy: 0.9765 - val_loss: 0.1569 - val_accuracy: 0.9477\n",
      "Epoch 306/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0932 - accuracy: 0.9771 - val_loss: 0.1564 - val_accuracy: 0.9471\n",
      "Epoch 307/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0929 - accuracy: 0.9767 - val_loss: 0.1571 - val_accuracy: 0.9471\n",
      "Epoch 308/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0929 - accuracy: 0.9765 - val_loss: 0.1566 - val_accuracy: 0.9474\n",
      "Epoch 309/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0929 - accuracy: 0.9767 - val_loss: 0.1561 - val_accuracy: 0.9474\n",
      "Epoch 310/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.97 - 0s 40us/step - loss: 0.0927 - accuracy: 0.9766 - val_loss: 0.1540 - val_accuracy: 0.9508\n",
      "Epoch 311/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0927 - accuracy: 0.9766 - val_loss: 0.1572 - val_accuracy: 0.9464\n",
      "Epoch 312/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0924 - accuracy: 0.9776 - val_loss: 0.1564 - val_accuracy: 0.9467\n",
      "Epoch 313/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0924 - accuracy: 0.9766 - val_loss: 0.1568 - val_accuracy: 0.9471\n",
      "Epoch 314/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0920 - accuracy: 0.9767 - val_loss: 0.1568 - val_accuracy: 0.9467\n",
      "Epoch 315/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0921 - accuracy: 0.9766 - val_loss: 0.1558 - val_accuracy: 0.9471\n",
      "Epoch 316/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0920 - accuracy: 0.9766 - val_loss: 0.1554 - val_accuracy: 0.9481\n",
      "Epoch 317/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0918 - accuracy: 0.9770 - val_loss: 0.1566 - val_accuracy: 0.9471\n",
      "Epoch 318/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0917 - accuracy: 0.9770 - val_loss: 0.1556 - val_accuracy: 0.9477\n",
      "Epoch 319/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0915 - accuracy: 0.9776 - val_loss: 0.1548 - val_accuracy: 0.9484\n",
      "Epoch 320/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0914 - accuracy: 0.9763 - val_loss: 0.1560 - val_accuracy: 0.9467\n",
      "Epoch 321/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0914 - accuracy: 0.9767 - val_loss: 0.1577 - val_accuracy: 0.9467\n",
      "Epoch 322/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0909 - accuracy: 0.9770 - val_loss: 0.1544 - val_accuracy: 0.9484\n",
      "Epoch 323/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0909 - accuracy: 0.9767 - val_loss: 0.1548 - val_accuracy: 0.9481\n",
      "Epoch 324/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0908 - accuracy: 0.9769 - val_loss: 0.1559 - val_accuracy: 0.9471\n",
      "Epoch 325/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0907 - accuracy: 0.9773 - val_loss: 0.1536 - val_accuracy: 0.9494\n",
      "Epoch 326/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0908 - accuracy: 0.9774 - val_loss: 0.1548 - val_accuracy: 0.9477\n",
      "Epoch 327/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0904 - accuracy: 0.9771 - val_loss: 0.1534 - val_accuracy: 0.9508\n",
      "Epoch 328/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0906 - accuracy: 0.9773 - val_loss: 0.1535 - val_accuracy: 0.9494\n",
      "Epoch 329/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0904 - accuracy: 0.9767 - val_loss: 0.1565 - val_accuracy: 0.9471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0902 - accuracy: 0.9769 - val_loss: 0.1551 - val_accuracy: 0.9477\n",
      "Epoch 331/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0901 - accuracy: 0.9780 - val_loss: 0.1546 - val_accuracy: 0.9477\n",
      "Epoch 332/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0897 - accuracy: 0.9773 - val_loss: 0.1536 - val_accuracy: 0.9484\n",
      "Epoch 333/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0897 - accuracy: 0.9774 - val_loss: 0.1547 - val_accuracy: 0.9474\n",
      "Epoch 334/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0899 - accuracy: 0.9769 - val_loss: 0.1579 - val_accuracy: 0.9471\n",
      "Epoch 335/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0896 - accuracy: 0.9778 - val_loss: 0.1543 - val_accuracy: 0.9481\n",
      "Epoch 336/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0896 - accuracy: 0.9778 - val_loss: 0.1550 - val_accuracy: 0.9477\n",
      "Epoch 337/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0892 - accuracy: 0.9780 - val_loss: 0.1528 - val_accuracy: 0.9501\n",
      "Epoch 338/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0889 - accuracy: 0.9778 - val_loss: 0.1530 - val_accuracy: 0.9488\n",
      "Epoch 339/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0891 - accuracy: 0.9774 - val_loss: 0.1557 - val_accuracy: 0.9467\n",
      "Epoch 340/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0889 - accuracy: 0.9770 - val_loss: 0.1554 - val_accuracy: 0.9474\n",
      "Epoch 341/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0889 - accuracy: 0.9778 - val_loss: 0.1539 - val_accuracy: 0.9481\n",
      "Epoch 342/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0888 - accuracy: 0.9778 - val_loss: 0.1538 - val_accuracy: 0.9481\n",
      "Epoch 343/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0887 - accuracy: 0.9776 - val_loss: 0.1540 - val_accuracy: 0.9481\n",
      "Epoch 344/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0884 - accuracy: 0.9774 - val_loss: 0.1518 - val_accuracy: 0.9508\n",
      "Epoch 345/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0886 - accuracy: 0.9774 - val_loss: 0.1541 - val_accuracy: 0.9477\n",
      "Epoch 346/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0883 - accuracy: 0.9784 - val_loss: 0.1529 - val_accuracy: 0.9484\n",
      "Epoch 347/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0882 - accuracy: 0.9776 - val_loss: 0.1546 - val_accuracy: 0.9481\n",
      "Epoch 348/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0880 - accuracy: 0.9778 - val_loss: 0.1513 - val_accuracy: 0.9508\n",
      "Epoch 349/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0880 - accuracy: 0.9776 - val_loss: 0.1519 - val_accuracy: 0.9494\n",
      "Epoch 350/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0878 - accuracy: 0.9765 - val_loss: 0.1545 - val_accuracy: 0.9477\n",
      "Epoch 351/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0877 - accuracy: 0.9776 - val_loss: 0.1508 - val_accuracy: 0.9515\n",
      "Epoch 352/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0877 - accuracy: 0.9785 - val_loss: 0.1525 - val_accuracy: 0.9494\n",
      "Epoch 353/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0873 - accuracy: 0.9781 - val_loss: 0.1501 - val_accuracy: 0.9518\n",
      "Epoch 354/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0874 - accuracy: 0.9780 - val_loss: 0.1531 - val_accuracy: 0.9491\n",
      "Epoch 355/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0874 - accuracy: 0.9782 - val_loss: 0.1570 - val_accuracy: 0.9477\n",
      "Epoch 356/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0871 - accuracy: 0.9780 - val_loss: 0.1524 - val_accuracy: 0.9488\n",
      "Epoch 357/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0870 - accuracy: 0.9782 - val_loss: 0.1528 - val_accuracy: 0.9481\n",
      "Epoch 358/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0868 - accuracy: 0.9788 - val_loss: 0.1548 - val_accuracy: 0.9481\n",
      "Epoch 359/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0869 - accuracy: 0.9782 - val_loss: 0.1530 - val_accuracy: 0.9491\n",
      "Epoch 360/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0869 - accuracy: 0.9781 - val_loss: 0.1517 - val_accuracy: 0.9484\n",
      "Epoch 361/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0866 - accuracy: 0.9782 - val_loss: 0.1526 - val_accuracy: 0.9484\n",
      "Epoch 362/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0864 - accuracy: 0.9786 - val_loss: 0.1517 - val_accuracy: 0.9494\n",
      "Epoch 363/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0866 - accuracy: 0.9780 - val_loss: 0.1515 - val_accuracy: 0.9491\n",
      "Epoch 364/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0864 - accuracy: 0.9771 - val_loss: 0.1550 - val_accuracy: 0.9484\n",
      "Epoch 365/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0861 - accuracy: 0.9776 - val_loss: 0.1573 - val_accuracy: 0.9477\n",
      "Epoch 366/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0863 - accuracy: 0.9778 - val_loss: 0.1489 - val_accuracy: 0.9525\n",
      "Epoch 367/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0858 - accuracy: 0.9788 - val_loss: 0.1535 - val_accuracy: 0.9488\n",
      "Epoch 368/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0859 - accuracy: 0.9778 - val_loss: 0.1506 - val_accuracy: 0.9508\n",
      "Epoch 369/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0860 - accuracy: 0.9781 - val_loss: 0.1503 - val_accuracy: 0.9511\n",
      "Epoch 370/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0856 - accuracy: 0.9778 - val_loss: 0.1499 - val_accuracy: 0.9515\n",
      "Epoch 371/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0855 - accuracy: 0.9781 - val_loss: 0.1520 - val_accuracy: 0.9494\n",
      "Epoch 372/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0855 - accuracy: 0.9777 - val_loss: 0.1551 - val_accuracy: 0.9481\n",
      "Epoch 373/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0854 - accuracy: 0.9780 - val_loss: 0.1507 - val_accuracy: 0.9501\n",
      "Epoch 374/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0853 - accuracy: 0.9792 - val_loss: 0.1517 - val_accuracy: 0.9488\n",
      "Epoch 375/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0852 - accuracy: 0.9796 - val_loss: 0.1500 - val_accuracy: 0.9508\n",
      "Epoch 376/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0853 - accuracy: 0.9778 - val_loss: 0.1541 - val_accuracy: 0.9484\n",
      "Epoch 377/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0852 - accuracy: 0.9781 - val_loss: 0.1508 - val_accuracy: 0.9498\n",
      "Epoch 378/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.1488 - val_accuracy: 0.9518\n",
      "Epoch 379/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0850 - accuracy: 0.9785 - val_loss: 0.1532 - val_accuracy: 0.9481\n",
      "Epoch 380/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0847 - accuracy: 0.9786 - val_loss: 0.1510 - val_accuracy: 0.9491\n",
      "Epoch 381/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0846 - accuracy: 0.9778 - val_loss: 0.1524 - val_accuracy: 0.9481\n",
      "Epoch 382/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0844 - accuracy: 0.9792 - val_loss: 0.1525 - val_accuracy: 0.9488\n",
      "Epoch 383/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0845 - accuracy: 0.9788 - val_loss: 0.1501 - val_accuracy: 0.9498\n",
      "Epoch 384/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0843 - accuracy: 0.9784 - val_loss: 0.1536 - val_accuracy: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0842 - accuracy: 0.9789 - val_loss: 0.1494 - val_accuracy: 0.9515\n",
      "Epoch 386/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0841 - accuracy: 0.9785 - val_loss: 0.1529 - val_accuracy: 0.9488\n",
      "Epoch 387/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0840 - accuracy: 0.9784 - val_loss: 0.1491 - val_accuracy: 0.9515\n",
      "Epoch 388/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0839 - accuracy: 0.9785 - val_loss: 0.1489 - val_accuracy: 0.9515\n",
      "Epoch 389/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0838 - accuracy: 0.9786 - val_loss: 0.1536 - val_accuracy: 0.9484\n",
      "Epoch 390/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0835 - accuracy: 0.9788 - val_loss: 0.1484 - val_accuracy: 0.9515\n",
      "Epoch 391/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0837 - accuracy: 0.9786 - val_loss: 0.1506 - val_accuracy: 0.9498\n",
      "Epoch 392/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0836 - accuracy: 0.9785 - val_loss: 0.1516 - val_accuracy: 0.9488\n",
      "Epoch 393/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0833 - accuracy: 0.9788 - val_loss: 0.1488 - val_accuracy: 0.9515\n",
      "Epoch 394/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0833 - accuracy: 0.9786 - val_loss: 0.1578 - val_accuracy: 0.9467\n",
      "Epoch 395/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0834 - accuracy: 0.9793 - val_loss: 0.1532 - val_accuracy: 0.9484\n",
      "Epoch 396/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0833 - accuracy: 0.9784 - val_loss: 0.1488 - val_accuracy: 0.9508\n",
      "Epoch 397/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0831 - accuracy: 0.9789 - val_loss: 0.1503 - val_accuracy: 0.9494\n",
      "Epoch 398/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0830 - accuracy: 0.9795 - val_loss: 0.1535 - val_accuracy: 0.9477\n",
      "Epoch 399/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0829 - accuracy: 0.9785 - val_loss: 0.1485 - val_accuracy: 0.9511\n",
      "Epoch 400/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0828 - accuracy: 0.9796 - val_loss: 0.1492 - val_accuracy: 0.9501\n",
      "Epoch 401/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0828 - accuracy: 0.9780 - val_loss: 0.1518 - val_accuracy: 0.9488\n",
      "Epoch 402/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0827 - accuracy: 0.9782 - val_loss: 0.1527 - val_accuracy: 0.9491\n",
      "Epoch 403/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0824 - accuracy: 0.9781 - val_loss: 0.1482 - val_accuracy: 0.9511\n",
      "Epoch 404/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0826 - accuracy: 0.9786 - val_loss: 0.1486 - val_accuracy: 0.9505\n",
      "Epoch 405/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0825 - accuracy: 0.9784 - val_loss: 0.1511 - val_accuracy: 0.9494\n",
      "Epoch 406/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0824 - accuracy: 0.9796 - val_loss: 0.1501 - val_accuracy: 0.9494\n",
      "Epoch 407/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0820 - accuracy: 0.9789 - val_loss: 0.1498 - val_accuracy: 0.9501\n",
      "Epoch 408/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0819 - accuracy: 0.9799 - val_loss: 0.1487 - val_accuracy: 0.9501\n",
      "Epoch 409/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0821 - accuracy: 0.9795 - val_loss: 0.1514 - val_accuracy: 0.9491\n",
      "Epoch 410/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0819 - accuracy: 0.9797 - val_loss: 0.1507 - val_accuracy: 0.9491\n",
      "Epoch 411/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0817 - accuracy: 0.9785 - val_loss: 0.1498 - val_accuracy: 0.9494\n",
      "Epoch 412/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0816 - accuracy: 0.9793 - val_loss: 0.1487 - val_accuracy: 0.9511\n",
      "Epoch 413/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0817 - accuracy: 0.9791 - val_loss: 0.1521 - val_accuracy: 0.9491\n",
      "Epoch 414/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0816 - accuracy: 0.9792 - val_loss: 0.1481 - val_accuracy: 0.9511\n",
      "Epoch 415/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0814 - accuracy: 0.9795 - val_loss: 0.1487 - val_accuracy: 0.9501\n",
      "Epoch 416/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0813 - accuracy: 0.9792 - val_loss: 0.1474 - val_accuracy: 0.9518\n",
      "Epoch 417/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0811 - accuracy: 0.9799 - val_loss: 0.1514 - val_accuracy: 0.9491\n",
      "Epoch 418/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0812 - accuracy: 0.9795 - val_loss: 0.1459 - val_accuracy: 0.9528\n",
      "Epoch 419/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0811 - accuracy: 0.9785 - val_loss: 0.1508 - val_accuracy: 0.9494\n",
      "Epoch 420/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0812 - accuracy: 0.9800 - val_loss: 0.1512 - val_accuracy: 0.9491\n",
      "Epoch 421/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0809 - accuracy: 0.9789 - val_loss: 0.1468 - val_accuracy: 0.9518\n",
      "Epoch 422/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0811 - accuracy: 0.9797 - val_loss: 0.1486 - val_accuracy: 0.9508\n",
      "Epoch 423/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0805 - accuracy: 0.9793 - val_loss: 0.1505 - val_accuracy: 0.9494\n",
      "Epoch 424/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0808 - accuracy: 0.9800 - val_loss: 0.1491 - val_accuracy: 0.9498\n",
      "Epoch 425/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0806 - accuracy: 0.9792 - val_loss: 0.1511 - val_accuracy: 0.9494\n",
      "Epoch 426/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0803 - accuracy: 0.9804 - val_loss: 0.1484 - val_accuracy: 0.9511\n",
      "Epoch 427/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0805 - accuracy: 0.9796 - val_loss: 0.1470 - val_accuracy: 0.9518\n",
      "Epoch 428/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0804 - accuracy: 0.9793 - val_loss: 0.1486 - val_accuracy: 0.9501\n",
      "Epoch 429/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0801 - accuracy: 0.9799 - val_loss: 0.1522 - val_accuracy: 0.9481\n",
      "Epoch 430/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0800 - accuracy: 0.9803 - val_loss: 0.1460 - val_accuracy: 0.9525\n",
      "Epoch 431/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0803 - accuracy: 0.9789 - val_loss: 0.1470 - val_accuracy: 0.9508\n",
      "Epoch 432/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0801 - accuracy: 0.9795 - val_loss: 0.1476 - val_accuracy: 0.9522\n",
      "Epoch 433/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0799 - accuracy: 0.9795 - val_loss: 0.1464 - val_accuracy: 0.9515\n",
      "Epoch 434/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0798 - accuracy: 0.9800 - val_loss: 0.1478 - val_accuracy: 0.9505\n",
      "Epoch 435/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0800 - accuracy: 0.9792 - val_loss: 0.1483 - val_accuracy: 0.9511\n",
      "Epoch 436/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0795 - accuracy: 0.9795 - val_loss: 0.1455 - val_accuracy: 0.9522\n",
      "Epoch 437/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0798 - accuracy: 0.9796 - val_loss: 0.1487 - val_accuracy: 0.9501\n",
      "Epoch 438/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0797 - accuracy: 0.9791 - val_loss: 0.1492 - val_accuracy: 0.9498\n",
      "Epoch 439/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0796 - accuracy: 0.9795 - val_loss: 0.1485 - val_accuracy: 0.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0794 - accuracy: 0.9797 - val_loss: 0.1481 - val_accuracy: 0.9505\n",
      "Epoch 441/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0794 - accuracy: 0.9803 - val_loss: 0.1484 - val_accuracy: 0.9501\n",
      "Epoch 442/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0789 - accuracy: 0.9810 - val_loss: 0.1553 - val_accuracy: 0.9481\n",
      "Epoch 443/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0793 - accuracy: 0.9796 - val_loss: 0.1472 - val_accuracy: 0.9525\n",
      "Epoch 444/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0791 - accuracy: 0.9796 - val_loss: 0.1500 - val_accuracy: 0.9491\n",
      "Epoch 445/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0790 - accuracy: 0.9800 - val_loss: 0.1479 - val_accuracy: 0.9505\n",
      "Epoch 446/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0788 - accuracy: 0.9803 - val_loss: 0.1484 - val_accuracy: 0.9505\n",
      "Epoch 447/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0788 - accuracy: 0.9792 - val_loss: 0.1513 - val_accuracy: 0.9481\n",
      "Epoch 448/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0787 - accuracy: 0.9795 - val_loss: 0.1449 - val_accuracy: 0.9522\n",
      "Epoch 449/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0788 - accuracy: 0.9800 - val_loss: 0.1473 - val_accuracy: 0.9515\n",
      "Epoch 450/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0786 - accuracy: 0.9801 - val_loss: 0.1456 - val_accuracy: 0.9525\n",
      "Epoch 451/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0785 - accuracy: 0.9795 - val_loss: 0.1452 - val_accuracy: 0.9522\n",
      "Epoch 452/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0783 - accuracy: 0.9801 - val_loss: 0.1533 - val_accuracy: 0.9481\n",
      "Epoch 453/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0786 - accuracy: 0.9789 - val_loss: 0.1452 - val_accuracy: 0.9528\n",
      "Epoch 454/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0785 - accuracy: 0.9797 - val_loss: 0.1459 - val_accuracy: 0.9522\n",
      "Epoch 455/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0781 - accuracy: 0.9795 - val_loss: 0.1450 - val_accuracy: 0.9518\n",
      "Epoch 456/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0783 - accuracy: 0.9807 - val_loss: 0.1457 - val_accuracy: 0.9525\n",
      "Epoch 457/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0782 - accuracy: 0.9807 - val_loss: 0.1444 - val_accuracy: 0.9525\n",
      "Epoch 458/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0782 - accuracy: 0.9793 - val_loss: 0.1469 - val_accuracy: 0.9508\n",
      "Epoch 459/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0780 - accuracy: 0.9804 - val_loss: 0.1510 - val_accuracy: 0.9481\n",
      "Epoch 460/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0780 - accuracy: 0.9801 - val_loss: 0.1452 - val_accuracy: 0.9525\n",
      "Epoch 461/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0778 - accuracy: 0.9801 - val_loss: 0.1461 - val_accuracy: 0.9522\n",
      "Epoch 462/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0776 - accuracy: 0.9800 - val_loss: 0.1459 - val_accuracy: 0.9535\n",
      "Epoch 463/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0775 - accuracy: 0.9795 - val_loss: 0.1443 - val_accuracy: 0.9525\n",
      "Epoch 464/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0775 - accuracy: 0.9807 - val_loss: 0.1469 - val_accuracy: 0.9511\n",
      "Epoch 465/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0775 - accuracy: 0.9799 - val_loss: 0.1484 - val_accuracy: 0.9501\n",
      "Epoch 466/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0774 - accuracy: 0.9804 - val_loss: 0.1519 - val_accuracy: 0.9484\n",
      "Epoch 467/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0775 - accuracy: 0.9803 - val_loss: 0.1498 - val_accuracy: 0.9494\n",
      "Epoch 468/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0775 - accuracy: 0.9805 - val_loss: 0.1464 - val_accuracy: 0.9518\n",
      "Epoch 469/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0774 - accuracy: 0.9793 - val_loss: 0.1457 - val_accuracy: 0.9518\n",
      "Epoch 470/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0771 - accuracy: 0.9808 - val_loss: 0.1483 - val_accuracy: 0.9498\n",
      "Epoch 471/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0771 - accuracy: 0.9800 - val_loss: 0.1449 - val_accuracy: 0.9528\n",
      "Epoch 472/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0770 - accuracy: 0.9812 - val_loss: 0.1431 - val_accuracy: 0.9539\n",
      "Epoch 473/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0770 - accuracy: 0.9804 - val_loss: 0.1432 - val_accuracy: 0.9532\n",
      "Epoch 474/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0770 - accuracy: 0.9800 - val_loss: 0.1458 - val_accuracy: 0.9522\n",
      "Epoch 475/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0768 - accuracy: 0.9796 - val_loss: 0.1464 - val_accuracy: 0.9515\n",
      "Epoch 476/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0765 - accuracy: 0.9805 - val_loss: 0.1444 - val_accuracy: 0.9535\n",
      "Epoch 477/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0766 - accuracy: 0.9799 - val_loss: 0.1429 - val_accuracy: 0.9528\n",
      "Epoch 478/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0767 - accuracy: 0.9799 - val_loss: 0.1439 - val_accuracy: 0.9532\n",
      "Epoch 479/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0766 - accuracy: 0.9804 - val_loss: 0.1438 - val_accuracy: 0.9518\n",
      "Epoch 480/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0765 - accuracy: 0.9801 - val_loss: 0.1451 - val_accuracy: 0.9539\n",
      "Epoch 481/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0765 - accuracy: 0.9800 - val_loss: 0.1436 - val_accuracy: 0.9532\n",
      "Epoch 482/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0763 - accuracy: 0.9804 - val_loss: 0.1449 - val_accuracy: 0.9525\n",
      "Epoch 483/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0762 - accuracy: 0.9803 - val_loss: 0.1449 - val_accuracy: 0.9528\n",
      "Epoch 484/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0762 - accuracy: 0.9799 - val_loss: 0.1444 - val_accuracy: 0.9535\n",
      "Epoch 485/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0762 - accuracy: 0.9801 - val_loss: 0.1482 - val_accuracy: 0.9498\n",
      "Epoch 486/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0760 - accuracy: 0.9803 - val_loss: 0.1468 - val_accuracy: 0.9505\n",
      "Epoch 487/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0759 - accuracy: 0.9801 - val_loss: 0.1441 - val_accuracy: 0.9532\n",
      "Epoch 488/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0758 - accuracy: 0.9807 - val_loss: 0.1501 - val_accuracy: 0.9491\n",
      "Epoch 489/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0756 - accuracy: 0.9808 - val_loss: 0.1428 - val_accuracy: 0.9532\n",
      "Epoch 490/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0758 - accuracy: 0.9804 - val_loss: 0.1457 - val_accuracy: 0.9518\n",
      "Epoch 491/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0752 - accuracy: 0.9807 - val_loss: 0.1425 - val_accuracy: 0.9528\n",
      "Epoch 492/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0758 - accuracy: 0.9805 - val_loss: 0.1449 - val_accuracy: 0.9525\n",
      "Epoch 493/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0755 - accuracy: 0.9804 - val_loss: 0.1439 - val_accuracy: 0.9532\n",
      "Epoch 494/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0755 - accuracy: 0.9804 - val_loss: 0.1440 - val_accuracy: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.1465 - val_accuracy: 0.9501\n",
      "Epoch 496/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0751 - accuracy: 0.9815 - val_loss: 0.1465 - val_accuracy: 0.9515\n",
      "Epoch 497/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0755 - accuracy: 0.9801 - val_loss: 0.1435 - val_accuracy: 0.9539\n",
      "Epoch 498/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0753 - accuracy: 0.9812 - val_loss: 0.1450 - val_accuracy: 0.9532\n",
      "Epoch 499/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0751 - accuracy: 0.9804 - val_loss: 0.1472 - val_accuracy: 0.9498\n",
      "Epoch 500/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0749 - accuracy: 0.9803 - val_loss: 0.1455 - val_accuracy: 0.9522\n",
      "Epoch 501/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0750 - accuracy: 0.9804 - val_loss: 0.1434 - val_accuracy: 0.9528\n",
      "Epoch 502/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0748 - accuracy: 0.9803 - val_loss: 0.1437 - val_accuracy: 0.9542\n",
      "Epoch 503/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0750 - accuracy: 0.9804 - val_loss: 0.1439 - val_accuracy: 0.9539\n",
      "Epoch 504/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0748 - accuracy: 0.9812 - val_loss: 0.1440 - val_accuracy: 0.9532\n",
      "Epoch 505/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0748 - accuracy: 0.9808 - val_loss: 0.1451 - val_accuracy: 0.9522\n",
      "Epoch 506/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0748 - accuracy: 0.9807 - val_loss: 0.1463 - val_accuracy: 0.9508\n",
      "Epoch 507/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0746 - accuracy: 0.9812 - val_loss: 0.1454 - val_accuracy: 0.9518\n",
      "Epoch 508/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0747 - accuracy: 0.9812 - val_loss: 0.1487 - val_accuracy: 0.9491\n",
      "Epoch 509/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0746 - accuracy: 0.9808 - val_loss: 0.1428 - val_accuracy: 0.9535\n",
      "Epoch 510/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0744 - accuracy: 0.9810 - val_loss: 0.1443 - val_accuracy: 0.9525\n",
      "Epoch 511/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0743 - accuracy: 0.9814 - val_loss: 0.1433 - val_accuracy: 0.9535\n",
      "Epoch 512/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0744 - accuracy: 0.9804 - val_loss: 0.1458 - val_accuracy: 0.9515\n",
      "Epoch 513/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0743 - accuracy: 0.9807 - val_loss: 0.1433 - val_accuracy: 0.9535\n",
      "Epoch 514/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0744 - accuracy: 0.9810 - val_loss: 0.1462 - val_accuracy: 0.9511\n",
      "Epoch 515/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0741 - accuracy: 0.9807 - val_loss: 0.1439 - val_accuracy: 0.9532\n",
      "Epoch 516/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0743 - accuracy: 0.9805 - val_loss: 0.1431 - val_accuracy: 0.9532\n",
      "Epoch 517/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0740 - accuracy: 0.9808 - val_loss: 0.1445 - val_accuracy: 0.9525\n",
      "Epoch 518/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0740 - accuracy: 0.9814 - val_loss: 0.1441 - val_accuracy: 0.9532\n",
      "Epoch 519/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0738 - accuracy: 0.9812 - val_loss: 0.1444 - val_accuracy: 0.9532\n",
      "Epoch 520/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0738 - accuracy: 0.9807 - val_loss: 0.1447 - val_accuracy: 0.9522\n",
      "Epoch 521/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0738 - accuracy: 0.9804 - val_loss: 0.1443 - val_accuracy: 0.9528\n",
      "Epoch 522/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0737 - accuracy: 0.9818 - val_loss: 0.1459 - val_accuracy: 0.9511\n",
      "Epoch 523/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0736 - accuracy: 0.9818 - val_loss: 0.1475 - val_accuracy: 0.9501\n",
      "Epoch 524/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0736 - accuracy: 0.9807 - val_loss: 0.1454 - val_accuracy: 0.9518\n",
      "Epoch 525/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0735 - accuracy: 0.9819 - val_loss: 0.1457 - val_accuracy: 0.9511\n",
      "Epoch 526/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0734 - accuracy: 0.9812 - val_loss: 0.1434 - val_accuracy: 0.9539\n",
      "Epoch 527/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0735 - accuracy: 0.9811 - val_loss: 0.1484 - val_accuracy: 0.9494\n",
      "Epoch 528/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0732 - accuracy: 0.9815 - val_loss: 0.1447 - val_accuracy: 0.9525\n",
      "Epoch 529/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0732 - accuracy: 0.9811 - val_loss: 0.1426 - val_accuracy: 0.9539\n",
      "Epoch 530/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0733 - accuracy: 0.9810 - val_loss: 0.1428 - val_accuracy: 0.9539\n",
      "Epoch 531/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0730 - accuracy: 0.9812 - val_loss: 0.1471 - val_accuracy: 0.9505\n",
      "Epoch 532/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0731 - accuracy: 0.9816 - val_loss: 0.1417 - val_accuracy: 0.9542\n",
      "Epoch 533/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0730 - accuracy: 0.9814 - val_loss: 0.1442 - val_accuracy: 0.9522\n",
      "Epoch 534/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0729 - accuracy: 0.9810 - val_loss: 0.1445 - val_accuracy: 0.9522\n",
      "Epoch 535/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0729 - accuracy: 0.9808 - val_loss: 0.1429 - val_accuracy: 0.9539\n",
      "Epoch 536/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0729 - accuracy: 0.9814 - val_loss: 0.1447 - val_accuracy: 0.9518\n",
      "Epoch 537/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0728 - accuracy: 0.9807 - val_loss: 0.1436 - val_accuracy: 0.9535\n",
      "Epoch 538/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 0.1441 - val_accuracy: 0.9522\n",
      "Epoch 539/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0727 - accuracy: 0.9820 - val_loss: 0.1460 - val_accuracy: 0.9511\n",
      "Epoch 540/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0728 - accuracy: 0.9814 - val_loss: 0.1423 - val_accuracy: 0.9539\n",
      "Epoch 541/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0725 - accuracy: 0.9818 - val_loss: 0.1470 - val_accuracy: 0.9501\n",
      "Epoch 542/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0725 - accuracy: 0.9810 - val_loss: 0.1451 - val_accuracy: 0.9518\n",
      "Epoch 543/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0725 - accuracy: 0.9820 - val_loss: 0.1422 - val_accuracy: 0.9539\n",
      "Epoch 544/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0723 - accuracy: 0.9823 - val_loss: 0.1417 - val_accuracy: 0.9542\n",
      "Epoch 545/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0723 - accuracy: 0.9811 - val_loss: 0.1427 - val_accuracy: 0.9532\n",
      "Epoch 546/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0723 - accuracy: 0.9816 - val_loss: 0.1446 - val_accuracy: 0.9518\n",
      "Epoch 547/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0723 - accuracy: 0.9808 - val_loss: 0.1407 - val_accuracy: 0.9545\n",
      "Epoch 548/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0721 - accuracy: 0.9816 - val_loss: 0.1420 - val_accuracy: 0.9539\n",
      "Epoch 549/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.98 - 0s 39us/step - loss: 0.0719 - accuracy: 0.9816 - val_loss: 0.1400 - val_accuracy: 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0720 - accuracy: 0.9816 - val_loss: 0.1411 - val_accuracy: 0.9545\n",
      "Epoch 551/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0721 - accuracy: 0.9822 - val_loss: 0.1453 - val_accuracy: 0.9518\n",
      "Epoch 552/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0719 - accuracy: 0.9819 - val_loss: 0.1426 - val_accuracy: 0.9535\n",
      "Epoch 553/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0719 - accuracy: 0.9816 - val_loss: 0.1436 - val_accuracy: 0.9525\n",
      "Epoch 554/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0718 - accuracy: 0.9823 - val_loss: 0.1438 - val_accuracy: 0.9528\n",
      "Epoch 555/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0718 - accuracy: 0.9818 - val_loss: 0.1424 - val_accuracy: 0.9535\n",
      "Epoch 556/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0717 - accuracy: 0.9818 - val_loss: 0.1422 - val_accuracy: 0.9535\n",
      "Epoch 557/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0717 - accuracy: 0.9823 - val_loss: 0.1429 - val_accuracy: 0.9528\n",
      "Epoch 558/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0716 - accuracy: 0.9822 - val_loss: 0.1438 - val_accuracy: 0.9522\n",
      "Epoch 559/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0718 - accuracy: 0.9818 - val_loss: 0.1426 - val_accuracy: 0.9532\n",
      "Epoch 560/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0715 - accuracy: 0.9819 - val_loss: 0.1424 - val_accuracy: 0.9535\n",
      "Epoch 561/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0715 - accuracy: 0.9829 - val_loss: 0.1426 - val_accuracy: 0.9532\n",
      "Epoch 562/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0716 - accuracy: 0.9816 - val_loss: 0.1450 - val_accuracy: 0.9518\n",
      "Epoch 563/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0712 - accuracy: 0.9816 - val_loss: 0.1396 - val_accuracy: 0.9542\n",
      "Epoch 564/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 0.1431 - val_accuracy: 0.9525\n",
      "Epoch 565/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0712 - accuracy: 0.9823 - val_loss: 0.1427 - val_accuracy: 0.9528\n",
      "Epoch 566/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0712 - accuracy: 0.9819 - val_loss: 0.1423 - val_accuracy: 0.9532\n",
      "Epoch 567/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0711 - accuracy: 0.9816 - val_loss: 0.1405 - val_accuracy: 0.9549\n",
      "Epoch 568/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0712 - accuracy: 0.9818 - val_loss: 0.1420 - val_accuracy: 0.9539\n",
      "Epoch 569/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0710 - accuracy: 0.9816 - val_loss: 0.1415 - val_accuracy: 0.9542\n",
      "Epoch 570/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0709 - accuracy: 0.9827 - val_loss: 0.1449 - val_accuracy: 0.9522\n",
      "Epoch 571/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0709 - accuracy: 0.9823 - val_loss: 0.1441 - val_accuracy: 0.9525\n",
      "Epoch 572/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0708 - accuracy: 0.9820 - val_loss: 0.1413 - val_accuracy: 0.9539\n",
      "Epoch 573/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0708 - accuracy: 0.9819 - val_loss: 0.1447 - val_accuracy: 0.9522\n",
      "Epoch 574/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0706 - accuracy: 0.9815 - val_loss: 0.1403 - val_accuracy: 0.9545\n",
      "Epoch 575/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0708 - accuracy: 0.9819 - val_loss: 0.1410 - val_accuracy: 0.9539\n",
      "Epoch 576/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0706 - accuracy: 0.9822 - val_loss: 0.1435 - val_accuracy: 0.9522\n",
      "Epoch 577/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0704 - accuracy: 0.9826 - val_loss: 0.1412 - val_accuracy: 0.9532\n",
      "Epoch 578/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0704 - accuracy: 0.9826 - val_loss: 0.1425 - val_accuracy: 0.9528\n",
      "Epoch 579/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0705 - accuracy: 0.9826 - val_loss: 0.1427 - val_accuracy: 0.9528\n",
      "Epoch 580/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0705 - accuracy: 0.9822 - val_loss: 0.1440 - val_accuracy: 0.9528\n",
      "Epoch 581/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0703 - accuracy: 0.9820 - val_loss: 0.1419 - val_accuracy: 0.9532\n",
      "Epoch 582/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0703 - accuracy: 0.9825 - val_loss: 0.1431 - val_accuracy: 0.9528\n",
      "Epoch 583/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0702 - accuracy: 0.9822 - val_loss: 0.1439 - val_accuracy: 0.9535\n",
      "Epoch 584/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0702 - accuracy: 0.9826 - val_loss: 0.1419 - val_accuracy: 0.9532\n",
      "Epoch 585/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0701 - accuracy: 0.9819 - val_loss: 0.1450 - val_accuracy: 0.9518\n",
      "Epoch 586/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0699 - accuracy: 0.9830 - val_loss: 0.1412 - val_accuracy: 0.9535\n",
      "Epoch 587/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0700 - accuracy: 0.9823 - val_loss: 0.1427 - val_accuracy: 0.9522\n",
      "Epoch 588/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0700 - accuracy: 0.9822 - val_loss: 0.1442 - val_accuracy: 0.9528\n",
      "Epoch 589/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0700 - accuracy: 0.9827 - val_loss: 0.1417 - val_accuracy: 0.9539\n",
      "Epoch 590/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0698 - accuracy: 0.9830 - val_loss: 0.1399 - val_accuracy: 0.9549\n",
      "Epoch 591/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0700 - accuracy: 0.9820 - val_loss: 0.1419 - val_accuracy: 0.9528\n",
      "Epoch 592/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0698 - accuracy: 0.9822 - val_loss: 0.1413 - val_accuracy: 0.9532\n",
      "Epoch 593/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0698 - accuracy: 0.9827 - val_loss: 0.1422 - val_accuracy: 0.9528\n",
      "Epoch 594/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0697 - accuracy: 0.9822 - val_loss: 0.1409 - val_accuracy: 0.9539\n",
      "Epoch 595/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0697 - accuracy: 0.9826 - val_loss: 0.1414 - val_accuracy: 0.9535\n",
      "Epoch 596/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0697 - accuracy: 0.9833 - val_loss: 0.1423 - val_accuracy: 0.9528\n",
      "Epoch 597/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0695 - accuracy: 0.9826 - val_loss: 0.1446 - val_accuracy: 0.9525\n",
      "Epoch 598/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0695 - accuracy: 0.9829 - val_loss: 0.1402 - val_accuracy: 0.9542\n",
      "Epoch 599/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.1409 - val_accuracy: 0.9539\n",
      "Epoch 600/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0695 - accuracy: 0.9826 - val_loss: 0.1394 - val_accuracy: 0.9555\n",
      "Epoch 601/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0695 - accuracy: 0.9829 - val_loss: 0.1421 - val_accuracy: 0.9525\n",
      "Epoch 602/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0693 - accuracy: 0.9820 - val_loss: 0.1435 - val_accuracy: 0.9518\n",
      "Epoch 603/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0693 - accuracy: 0.9826 - val_loss: 0.1440 - val_accuracy: 0.9518\n",
      "Epoch 604/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0692 - accuracy: 0.9827 - val_loss: 0.1432 - val_accuracy: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0692 - accuracy: 0.9825 - val_loss: 0.1399 - val_accuracy: 0.9552\n",
      "Epoch 606/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0692 - accuracy: 0.9827 - val_loss: 0.1412 - val_accuracy: 0.9539\n",
      "Epoch 607/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0691 - accuracy: 0.9829 - val_loss: 0.1429 - val_accuracy: 0.9532\n",
      "Epoch 608/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0690 - accuracy: 0.9826 - val_loss: 0.1407 - val_accuracy: 0.9542\n",
      "Epoch 609/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0690 - accuracy: 0.9833 - val_loss: 0.1404 - val_accuracy: 0.9539\n",
      "Epoch 610/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0690 - accuracy: 0.9829 - val_loss: 0.1446 - val_accuracy: 0.9515\n",
      "Epoch 611/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0688 - accuracy: 0.9827 - val_loss: 0.1397 - val_accuracy: 0.9542\n",
      "Epoch 612/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0688 - accuracy: 0.9829 - val_loss: 0.1393 - val_accuracy: 0.9549\n",
      "Epoch 613/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0688 - accuracy: 0.9819 - val_loss: 0.1394 - val_accuracy: 0.9549\n",
      "Epoch 614/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0688 - accuracy: 0.9825 - val_loss: 0.1426 - val_accuracy: 0.9532\n",
      "Epoch 615/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0687 - accuracy: 0.9827 - val_loss: 0.1414 - val_accuracy: 0.9532\n",
      "Epoch 616/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0686 - accuracy: 0.9833 - val_loss: 0.1413 - val_accuracy: 0.9535\n",
      "Epoch 617/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0686 - accuracy: 0.9823 - val_loss: 0.1407 - val_accuracy: 0.9542\n",
      "Epoch 618/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0686 - accuracy: 0.9827 - val_loss: 0.1410 - val_accuracy: 0.9542\n",
      "Epoch 619/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0684 - accuracy: 0.9827 - val_loss: 0.1398 - val_accuracy: 0.9542\n",
      "Epoch 620/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0684 - accuracy: 0.9825 - val_loss: 0.1398 - val_accuracy: 0.9542\n",
      "Epoch 621/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0684 - accuracy: 0.9826 - val_loss: 0.1407 - val_accuracy: 0.9539\n",
      "Epoch 622/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0684 - accuracy: 0.9827 - val_loss: 0.1396 - val_accuracy: 0.9542\n",
      "Epoch 623/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.1398 - val_accuracy: 0.9542\n",
      "Epoch 624/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0684 - accuracy: 0.9829 - val_loss: 0.1399 - val_accuracy: 0.9542\n",
      "Epoch 625/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0684 - accuracy: 0.9829 - val_loss: 0.1426 - val_accuracy: 0.9532\n",
      "Epoch 626/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.1413 - val_accuracy: 0.9532\n",
      "Epoch 627/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0681 - accuracy: 0.9830 - val_loss: 0.1407 - val_accuracy: 0.9542\n",
      "Epoch 628/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0680 - accuracy: 0.9827 - val_loss: 0.1400 - val_accuracy: 0.9542\n",
      "Epoch 629/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0681 - accuracy: 0.9827 - val_loss: 0.1456 - val_accuracy: 0.9511\n",
      "Epoch 630/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0681 - accuracy: 0.9827 - val_loss: 0.1404 - val_accuracy: 0.9539\n",
      "Epoch 631/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0679 - accuracy: 0.9831 - val_loss: 0.1404 - val_accuracy: 0.9535\n",
      "Epoch 632/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0678 - accuracy: 0.9829 - val_loss: 0.1402 - val_accuracy: 0.9539\n",
      "Epoch 633/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0678 - accuracy: 0.9837 - val_loss: 0.1422 - val_accuracy: 0.9528\n",
      "Epoch 634/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0677 - accuracy: 0.9831 - val_loss: 0.1411 - val_accuracy: 0.9525\n",
      "Epoch 635/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0678 - accuracy: 0.9827 - val_loss: 0.1413 - val_accuracy: 0.9532\n",
      "Epoch 636/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0677 - accuracy: 0.9833 - val_loss: 0.1438 - val_accuracy: 0.9522\n",
      "Epoch 637/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0675 - accuracy: 0.9823 - val_loss: 0.1392 - val_accuracy: 0.9542\n",
      "Epoch 638/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0673 - accuracy: 0.9830 - val_loss: 0.1478 - val_accuracy: 0.9501\n",
      "Epoch 639/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0678 - accuracy: 0.9833 - val_loss: 0.1397 - val_accuracy: 0.9542\n",
      "Epoch 640/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0675 - accuracy: 0.9829 - val_loss: 0.1397 - val_accuracy: 0.9542\n",
      "Epoch 641/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0673 - accuracy: 0.9830 - val_loss: 0.1382 - val_accuracy: 0.9552\n",
      "Epoch 642/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0676 - accuracy: 0.9818 - val_loss: 0.1412 - val_accuracy: 0.9532\n",
      "Epoch 643/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0674 - accuracy: 0.9830 - val_loss: 0.1414 - val_accuracy: 0.9528\n",
      "Epoch 644/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0673 - accuracy: 0.9835 - val_loss: 0.1427 - val_accuracy: 0.9532\n",
      "Epoch 645/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0674 - accuracy: 0.9830 - val_loss: 0.1406 - val_accuracy: 0.9532\n",
      "Epoch 646/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 0.1401 - val_accuracy: 0.9542\n",
      "Epoch 647/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0671 - accuracy: 0.9831 - val_loss: 0.1382 - val_accuracy: 0.9545\n",
      "Epoch 648/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0672 - accuracy: 0.9833 - val_loss: 0.1417 - val_accuracy: 0.9532\n",
      "Epoch 649/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0670 - accuracy: 0.9829 - val_loss: 0.1407 - val_accuracy: 0.9532\n",
      "Epoch 650/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0668 - accuracy: 0.9825 - val_loss: 0.1441 - val_accuracy: 0.9518\n",
      "Epoch 651/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0671 - accuracy: 0.9835 - val_loss: 0.1408 - val_accuracy: 0.9532\n",
      "Epoch 652/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0671 - accuracy: 0.9827 - val_loss: 0.1405 - val_accuracy: 0.9539\n",
      "Epoch 653/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0669 - accuracy: 0.9825 - val_loss: 0.1450 - val_accuracy: 0.9515\n",
      "Epoch 654/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0669 - accuracy: 0.9833 - val_loss: 0.1407 - val_accuracy: 0.9532\n",
      "Epoch 655/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0668 - accuracy: 0.9838 - val_loss: 0.1371 - val_accuracy: 0.9549\n",
      "Epoch 656/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0668 - accuracy: 0.9837 - val_loss: 0.1397 - val_accuracy: 0.9542\n",
      "Epoch 657/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0667 - accuracy: 0.9834 - val_loss: 0.1397 - val_accuracy: 0.9542\n",
      "Epoch 658/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0666 - accuracy: 0.9829 - val_loss: 0.1384 - val_accuracy: 0.9549\n",
      "Epoch 659/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0665 - accuracy: 0.9831 - val_loss: 0.1410 - val_accuracy: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0664 - accuracy: 0.9831 - val_loss: 0.1379 - val_accuracy: 0.9552\n",
      "Epoch 661/1000\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.0666 - accuracy: 0.9830 - val_loss: 0.1403 - val_accuracy: 0.9532\n",
      "Epoch 662/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0664 - accuracy: 0.9831 - val_loss: 0.1402 - val_accuracy: 0.9535\n",
      "Epoch 663/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0666 - accuracy: 0.9833 - val_loss: 0.1404 - val_accuracy: 0.9532\n",
      "Epoch 664/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0665 - accuracy: 0.9831 - val_loss: 0.1435 - val_accuracy: 0.9522\n",
      "Epoch 665/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0663 - accuracy: 0.9829 - val_loss: 0.1435 - val_accuracy: 0.9525\n",
      "Epoch 666/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0665 - accuracy: 0.9837 - val_loss: 0.1409 - val_accuracy: 0.9528\n",
      "Epoch 667/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0664 - accuracy: 0.9829 - val_loss: 0.1417 - val_accuracy: 0.9535\n",
      "Epoch 668/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0662 - accuracy: 0.9827 - val_loss: 0.1387 - val_accuracy: 0.9542\n",
      "Epoch 669/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0662 - accuracy: 0.9830 - val_loss: 0.1410 - val_accuracy: 0.9532\n",
      "Epoch 670/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0660 - accuracy: 0.9834 - val_loss: 0.1390 - val_accuracy: 0.9542\n",
      "Epoch 671/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0662 - accuracy: 0.9829 - val_loss: 0.1393 - val_accuracy: 0.9542\n",
      "Epoch 672/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0662 - accuracy: 0.9833 - val_loss: 0.1432 - val_accuracy: 0.9525\n",
      "Epoch 673/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0661 - accuracy: 0.9829 - val_loss: 0.1402 - val_accuracy: 0.9528\n",
      "Epoch 674/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0659 - accuracy: 0.9834 - val_loss: 0.1398 - val_accuracy: 0.9535\n",
      "Epoch 675/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0658 - accuracy: 0.9830 - val_loss: 0.1386 - val_accuracy: 0.9542\n",
      "Epoch 676/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0660 - accuracy: 0.9833 - val_loss: 0.1413 - val_accuracy: 0.9535\n",
      "Epoch 677/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0659 - accuracy: 0.9838 - val_loss: 0.1448 - val_accuracy: 0.9515\n",
      "Epoch 678/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0658 - accuracy: 0.9837 - val_loss: 0.1383 - val_accuracy: 0.9542\n",
      "Epoch 679/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0660 - accuracy: 0.9835 - val_loss: 0.1409 - val_accuracy: 0.9528\n",
      "Epoch 680/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0658 - accuracy: 0.9837 - val_loss: 0.1394 - val_accuracy: 0.9542\n",
      "Epoch 681/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0659 - accuracy: 0.9835 - val_loss: 0.1384 - val_accuracy: 0.9542\n",
      "Epoch 682/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0657 - accuracy: 0.9834 - val_loss: 0.1413 - val_accuracy: 0.9532\n",
      "Epoch 683/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0655 - accuracy: 0.9842 - val_loss: 0.1391 - val_accuracy: 0.9542\n",
      "Epoch 684/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0656 - accuracy: 0.9837 - val_loss: 0.1376 - val_accuracy: 0.9549\n",
      "Epoch 685/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0656 - accuracy: 0.9831 - val_loss: 0.1394 - val_accuracy: 0.9535\n",
      "Epoch 686/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0656 - accuracy: 0.9831 - val_loss: 0.1381 - val_accuracy: 0.9542\n",
      "Epoch 687/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0654 - accuracy: 0.9838 - val_loss: 0.1398 - val_accuracy: 0.9535\n",
      "Epoch 688/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0652 - accuracy: 0.9829 - val_loss: 0.1472 - val_accuracy: 0.9484\n",
      "Epoch 689/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0654 - accuracy: 0.9835 - val_loss: 0.1399 - val_accuracy: 0.9528\n",
      "Epoch 690/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0655 - accuracy: 0.9830 - val_loss: 0.1393 - val_accuracy: 0.9535\n",
      "Epoch 691/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0653 - accuracy: 0.9829 - val_loss: 0.1417 - val_accuracy: 0.9532\n",
      "Epoch 692/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0653 - accuracy: 0.9842 - val_loss: 0.1391 - val_accuracy: 0.9542\n",
      "Epoch 693/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0655 - accuracy: 0.9825 - val_loss: 0.1380 - val_accuracy: 0.9542\n",
      "Epoch 694/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0652 - accuracy: 0.9838 - val_loss: 0.1404 - val_accuracy: 0.9532\n",
      "Epoch 695/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0651 - accuracy: 0.9839 - val_loss: 0.1392 - val_accuracy: 0.9539\n",
      "Epoch 696/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0652 - accuracy: 0.9835 - val_loss: 0.1365 - val_accuracy: 0.9552\n",
      "Epoch 697/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0651 - accuracy: 0.9841 - val_loss: 0.1436 - val_accuracy: 0.9525\n",
      "Epoch 698/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0652 - accuracy: 0.9835 - val_loss: 0.1379 - val_accuracy: 0.9542\n",
      "Epoch 699/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0652 - accuracy: 0.9842 - val_loss: 0.1409 - val_accuracy: 0.9532\n",
      "Epoch 700/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0648 - accuracy: 0.9833 - val_loss: 0.1391 - val_accuracy: 0.9535\n",
      "Epoch 701/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0649 - accuracy: 0.9845 - val_loss: 0.1386 - val_accuracy: 0.9542\n",
      "Epoch 702/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0646 - accuracy: 0.9841 - val_loss: 0.1394 - val_accuracy: 0.9528\n",
      "Epoch 703/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0649 - accuracy: 0.9841 - val_loss: 0.1419 - val_accuracy: 0.9528\n",
      "Epoch 704/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0648 - accuracy: 0.9834 - val_loss: 0.1399 - val_accuracy: 0.9525\n",
      "Epoch 705/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0646 - accuracy: 0.9838 - val_loss: 0.1378 - val_accuracy: 0.9542\n",
      "Epoch 706/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0648 - accuracy: 0.9835 - val_loss: 0.1394 - val_accuracy: 0.9532\n",
      "Epoch 707/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0647 - accuracy: 0.9837 - val_loss: 0.1405 - val_accuracy: 0.9532\n",
      "Epoch 708/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0646 - accuracy: 0.9842 - val_loss: 0.1391 - val_accuracy: 0.9528\n",
      "Epoch 709/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0646 - accuracy: 0.9841 - val_loss: 0.1392 - val_accuracy: 0.9532\n",
      "Epoch 710/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0645 - accuracy: 0.9833 - val_loss: 0.1400 - val_accuracy: 0.9525\n",
      "Epoch 711/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0644 - accuracy: 0.9842 - val_loss: 0.1372 - val_accuracy: 0.9545\n",
      "Epoch 712/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0645 - accuracy: 0.9834 - val_loss: 0.1390 - val_accuracy: 0.9535\n",
      "Epoch 713/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0645 - accuracy: 0.9831 - val_loss: 0.1407 - val_accuracy: 0.9535\n",
      "Epoch 714/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0644 - accuracy: 0.9842 - val_loss: 0.1391 - val_accuracy: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0643 - accuracy: 0.9841 - val_loss: 0.1412 - val_accuracy: 0.9532\n",
      "Epoch 716/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0644 - accuracy: 0.9839 - val_loss: 0.1381 - val_accuracy: 0.9542\n",
      "Epoch 717/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0642 - accuracy: 0.9839 - val_loss: 0.1371 - val_accuracy: 0.9549\n",
      "Epoch 718/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0642 - accuracy: 0.9835 - val_loss: 0.1383 - val_accuracy: 0.9539\n",
      "Epoch 719/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0643 - accuracy: 0.9841 - val_loss: 0.1369 - val_accuracy: 0.9545\n",
      "Epoch 720/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0642 - accuracy: 0.9842 - val_loss: 0.1403 - val_accuracy: 0.9528\n",
      "Epoch 721/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0644 - accuracy: 0.9841 - val_loss: 0.1374 - val_accuracy: 0.9542\n",
      "Epoch 722/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0640 - accuracy: 0.9835 - val_loss: 0.1373 - val_accuracy: 0.9542\n",
      "Epoch 723/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0642 - accuracy: 0.9835 - val_loss: 0.1391 - val_accuracy: 0.9528\n",
      "Epoch 724/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0640 - accuracy: 0.9841 - val_loss: 0.1442 - val_accuracy: 0.9505\n",
      "Epoch 725/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0641 - accuracy: 0.9838 - val_loss: 0.1397 - val_accuracy: 0.9522\n",
      "Epoch 726/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0639 - accuracy: 0.9833 - val_loss: 0.1396 - val_accuracy: 0.9525\n",
      "Epoch 727/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 0.1370 - val_accuracy: 0.9545\n",
      "Epoch 728/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0639 - accuracy: 0.9839 - val_loss: 0.1383 - val_accuracy: 0.9539\n",
      "Epoch 729/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0638 - accuracy: 0.9838 - val_loss: 0.1433 - val_accuracy: 0.9522\n",
      "Epoch 730/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0639 - accuracy: 0.9837 - val_loss: 0.1378 - val_accuracy: 0.9535\n",
      "Epoch 731/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0638 - accuracy: 0.9842 - val_loss: 0.1408 - val_accuracy: 0.9532\n",
      "Epoch 732/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0637 - accuracy: 0.9841 - val_loss: 0.1384 - val_accuracy: 0.9535\n",
      "Epoch 733/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0638 - accuracy: 0.9837 - val_loss: 0.1416 - val_accuracy: 0.9525\n",
      "Epoch 734/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0636 - accuracy: 0.9837 - val_loss: 0.1387 - val_accuracy: 0.9528\n",
      "Epoch 735/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0635 - accuracy: 0.9835 - val_loss: 0.1390 - val_accuracy: 0.9525\n",
      "Epoch 736/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0636 - accuracy: 0.9839 - val_loss: 0.1377 - val_accuracy: 0.9535\n",
      "Epoch 737/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0636 - accuracy: 0.9838 - val_loss: 0.1402 - val_accuracy: 0.9532\n",
      "Epoch 738/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0634 - accuracy: 0.9838 - val_loss: 0.1390 - val_accuracy: 0.9532\n",
      "Epoch 739/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0634 - accuracy: 0.9837 - val_loss: 0.1376 - val_accuracy: 0.9539\n",
      "Epoch 740/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0633 - accuracy: 0.9845 - val_loss: 0.1431 - val_accuracy: 0.9525\n",
      "Epoch 741/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0635 - accuracy: 0.9837 - val_loss: 0.1384 - val_accuracy: 0.9535\n",
      "Epoch 742/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0635 - accuracy: 0.9845 - val_loss: 0.1404 - val_accuracy: 0.9528\n",
      "Epoch 743/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0635 - accuracy: 0.9841 - val_loss: 0.1392 - val_accuracy: 0.9528\n",
      "Epoch 744/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0633 - accuracy: 0.9849 - val_loss: 0.1426 - val_accuracy: 0.9528\n",
      "Epoch 745/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0633 - accuracy: 0.9841 - val_loss: 0.1373 - val_accuracy: 0.9539\n",
      "Epoch 746/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0633 - accuracy: 0.9835 - val_loss: 0.1384 - val_accuracy: 0.9528\n",
      "Epoch 747/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0632 - accuracy: 0.9837 - val_loss: 0.1411 - val_accuracy: 0.9528\n",
      "Epoch 748/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0632 - accuracy: 0.9845 - val_loss: 0.1388 - val_accuracy: 0.9525\n",
      "Epoch 749/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0632 - accuracy: 0.9838 - val_loss: 0.1361 - val_accuracy: 0.9545\n",
      "Epoch 750/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0633 - accuracy: 0.9834 - val_loss: 0.1374 - val_accuracy: 0.9539\n",
      "Epoch 751/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0632 - accuracy: 0.9839 - val_loss: 0.1389 - val_accuracy: 0.9525\n",
      "Epoch 752/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0629 - accuracy: 0.9842 - val_loss: 0.1404 - val_accuracy: 0.9528\n",
      "Epoch 753/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0632 - accuracy: 0.9845 - val_loss: 0.1379 - val_accuracy: 0.9539\n",
      "Epoch 754/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0632 - accuracy: 0.9838 - val_loss: 0.1384 - val_accuracy: 0.9528\n",
      "Epoch 755/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0629 - accuracy: 0.9844 - val_loss: 0.1372 - val_accuracy: 0.9539\n",
      "Epoch 756/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0629 - accuracy: 0.9845 - val_loss: 0.1410 - val_accuracy: 0.9525\n",
      "Epoch 757/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0628 - accuracy: 0.9839 - val_loss: 0.1385 - val_accuracy: 0.9525\n",
      "Epoch 758/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0629 - accuracy: 0.9845 - val_loss: 0.1405 - val_accuracy: 0.9528\n",
      "Epoch 759/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0626 - accuracy: 0.9842 - val_loss: 0.1389 - val_accuracy: 0.9528\n",
      "Epoch 760/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0628 - accuracy: 0.9844 - val_loss: 0.1392 - val_accuracy: 0.9525\n",
      "Epoch 761/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0626 - accuracy: 0.9846 - val_loss: 0.1427 - val_accuracy: 0.9525\n",
      "Epoch 762/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0628 - accuracy: 0.9846 - val_loss: 0.1396 - val_accuracy: 0.9528\n",
      "Epoch 763/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0627 - accuracy: 0.9839 - val_loss: 0.1376 - val_accuracy: 0.9535\n",
      "Epoch 764/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0627 - accuracy: 0.9835 - val_loss: 0.1364 - val_accuracy: 0.9542\n",
      "Epoch 765/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0626 - accuracy: 0.9838 - val_loss: 0.1379 - val_accuracy: 0.9528\n",
      "Epoch 766/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0625 - accuracy: 0.9844 - val_loss: 0.1369 - val_accuracy: 0.9539\n",
      "Epoch 767/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0623 - accuracy: 0.9842 - val_loss: 0.1373 - val_accuracy: 0.9539\n",
      "Epoch 768/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0626 - accuracy: 0.9841 - val_loss: 0.1369 - val_accuracy: 0.9539\n",
      "Epoch 769/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0624 - accuracy: 0.9838 - val_loss: 0.1376 - val_accuracy: 0.9535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0624 - accuracy: 0.9841 - val_loss: 0.1366 - val_accuracy: 0.9535\n",
      "Epoch 771/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0622 - accuracy: 0.9850 - val_loss: 0.1423 - val_accuracy: 0.9522\n",
      "Epoch 772/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0625 - accuracy: 0.9846 - val_loss: 0.1393 - val_accuracy: 0.9525\n",
      "Epoch 773/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0624 - accuracy: 0.9841 - val_loss: 0.1394 - val_accuracy: 0.9532\n",
      "Epoch 774/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0623 - accuracy: 0.9842 - val_loss: 0.1352 - val_accuracy: 0.9545\n",
      "Epoch 775/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0623 - accuracy: 0.9845 - val_loss: 0.1422 - val_accuracy: 0.9522\n",
      "Epoch 776/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0621 - accuracy: 0.9846 - val_loss: 0.1355 - val_accuracy: 0.9542\n",
      "Epoch 777/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0621 - accuracy: 0.9839 - val_loss: 0.1381 - val_accuracy: 0.9525\n",
      "Epoch 778/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0620 - accuracy: 0.9845 - val_loss: 0.1379 - val_accuracy: 0.9528\n",
      "Epoch 779/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0622 - accuracy: 0.9838 - val_loss: 0.1378 - val_accuracy: 0.9528\n",
      "Epoch 780/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0621 - accuracy: 0.9842 - val_loss: 0.1386 - val_accuracy: 0.9525\n",
      "Epoch 781/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0620 - accuracy: 0.9842 - val_loss: 0.1354 - val_accuracy: 0.9545\n",
      "Epoch 782/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0620 - accuracy: 0.9846 - val_loss: 0.1379 - val_accuracy: 0.9525\n",
      "Epoch 783/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0616 - accuracy: 0.9831 - val_loss: 0.1423 - val_accuracy: 0.9522\n",
      "Epoch 784/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0621 - accuracy: 0.9848 - val_loss: 0.1345 - val_accuracy: 0.9559\n",
      "Epoch 785/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0618 - accuracy: 0.9841 - val_loss: 0.1420 - val_accuracy: 0.9522\n",
      "Epoch 786/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0619 - accuracy: 0.9835 - val_loss: 0.1379 - val_accuracy: 0.9535\n",
      "Epoch 787/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0618 - accuracy: 0.9841 - val_loss: 0.1372 - val_accuracy: 0.9539\n",
      "Epoch 788/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0619 - accuracy: 0.9848 - val_loss: 0.1395 - val_accuracy: 0.9532\n",
      "Epoch 789/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0618 - accuracy: 0.9849 - val_loss: 0.1382 - val_accuracy: 0.9528\n",
      "Epoch 790/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0618 - accuracy: 0.9845 - val_loss: 0.1388 - val_accuracy: 0.9525\n",
      "Epoch 791/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0618 - accuracy: 0.9844 - val_loss: 0.1377 - val_accuracy: 0.9528\n",
      "Epoch 792/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0617 - accuracy: 0.9839 - val_loss: 0.1362 - val_accuracy: 0.9535\n",
      "Epoch 793/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0615 - accuracy: 0.9848 - val_loss: 0.1360 - val_accuracy: 0.9542\n",
      "Epoch 794/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0617 - accuracy: 0.9845 - val_loss: 0.1364 - val_accuracy: 0.9539\n",
      "Epoch 795/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0617 - accuracy: 0.9845 - val_loss: 0.1375 - val_accuracy: 0.9535\n",
      "Epoch 796/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0614 - accuracy: 0.9844 - val_loss: 0.1397 - val_accuracy: 0.9528\n",
      "Epoch 797/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0617 - accuracy: 0.9846 - val_loss: 0.1387 - val_accuracy: 0.9528\n",
      "Epoch 798/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0614 - accuracy: 0.9844 - val_loss: 0.1351 - val_accuracy: 0.9545\n",
      "Epoch 799/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0616 - accuracy: 0.9846 - val_loss: 0.1379 - val_accuracy: 0.9539\n",
      "Epoch 800/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0615 - accuracy: 0.9845 - val_loss: 0.1370 - val_accuracy: 0.9535\n",
      "Epoch 801/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0615 - accuracy: 0.9850 - val_loss: 0.1390 - val_accuracy: 0.9528\n",
      "Epoch 802/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0614 - accuracy: 0.9842 - val_loss: 0.1369 - val_accuracy: 0.9535\n",
      "Epoch 803/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0613 - accuracy: 0.9842 - val_loss: 0.1404 - val_accuracy: 0.9525\n",
      "Epoch 804/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0613 - accuracy: 0.9845 - val_loss: 0.1386 - val_accuracy: 0.9525\n",
      "Epoch 805/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0612 - accuracy: 0.9842 - val_loss: 0.1397 - val_accuracy: 0.9525\n",
      "Epoch 806/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0613 - accuracy: 0.9848 - val_loss: 0.1367 - val_accuracy: 0.9535\n",
      "Epoch 807/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0613 - accuracy: 0.9842 - val_loss: 0.1389 - val_accuracy: 0.9528\n",
      "Epoch 808/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0612 - accuracy: 0.9841 - val_loss: 0.1396 - val_accuracy: 0.9535\n",
      "Epoch 809/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0612 - accuracy: 0.9845 - val_loss: 0.1362 - val_accuracy: 0.9535\n",
      "Epoch 810/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0611 - accuracy: 0.9838 - val_loss: 0.1394 - val_accuracy: 0.9525\n",
      "Epoch 811/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0611 - accuracy: 0.9842 - val_loss: 0.1373 - val_accuracy: 0.9525\n",
      "Epoch 812/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0610 - accuracy: 0.9844 - val_loss: 0.1407 - val_accuracy: 0.9525\n",
      "Epoch 813/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0610 - accuracy: 0.9844 - val_loss: 0.1410 - val_accuracy: 0.9522\n",
      "Epoch 814/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0610 - accuracy: 0.9839 - val_loss: 0.1374 - val_accuracy: 0.9528\n",
      "Epoch 815/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0610 - accuracy: 0.9842 - val_loss: 0.1383 - val_accuracy: 0.9528\n",
      "Epoch 816/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0608 - accuracy: 0.9849 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 817/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0609 - accuracy: 0.9845 - val_loss: 0.1375 - val_accuracy: 0.9525\n",
      "Epoch 818/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0610 - accuracy: 0.9844 - val_loss: 0.1401 - val_accuracy: 0.9525\n",
      "Epoch 819/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0609 - accuracy: 0.9845 - val_loss: 0.1352 - val_accuracy: 0.9549\n",
      "Epoch 820/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0608 - accuracy: 0.9846 - val_loss: 0.1402 - val_accuracy: 0.9525\n",
      "Epoch 821/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0608 - accuracy: 0.9841 - val_loss: 0.1355 - val_accuracy: 0.9542\n",
      "Epoch 822/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0608 - accuracy: 0.9845 - val_loss: 0.1369 - val_accuracy: 0.9528\n",
      "Epoch 823/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0608 - accuracy: 0.9848 - val_loss: 0.1387 - val_accuracy: 0.9528\n",
      "Epoch 824/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0607 - accuracy: 0.9846 - val_loss: 0.1366 - val_accuracy: 0.9535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 825/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0607 - accuracy: 0.9842 - val_loss: 0.1372 - val_accuracy: 0.9532\n",
      "Epoch 826/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0606 - accuracy: 0.9849 - val_loss: 0.1383 - val_accuracy: 0.9535\n",
      "Epoch 827/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0606 - accuracy: 0.9838 - val_loss: 0.1384 - val_accuracy: 0.9528\n",
      "Epoch 828/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0606 - accuracy: 0.9850 - val_loss: 0.1382 - val_accuracy: 0.9535\n",
      "Epoch 829/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0604 - accuracy: 0.9853 - val_loss: 0.1349 - val_accuracy: 0.9545\n",
      "Epoch 830/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0604 - accuracy: 0.9846 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 831/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0605 - accuracy: 0.9849 - val_loss: 0.1373 - val_accuracy: 0.9528\n",
      "Epoch 832/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0603 - accuracy: 0.9852 - val_loss: 0.1383 - val_accuracy: 0.9528\n",
      "Epoch 833/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0604 - accuracy: 0.9854 - val_loss: 0.1376 - val_accuracy: 0.9528\n",
      "Epoch 834/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0602 - accuracy: 0.9849 - val_loss: 0.1431 - val_accuracy: 0.9501\n",
      "Epoch 835/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0605 - accuracy: 0.9841 - val_loss: 0.1383 - val_accuracy: 0.9525\n",
      "Epoch 836/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0603 - accuracy: 0.9844 - val_loss: 0.1399 - val_accuracy: 0.9528\n",
      "Epoch 837/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0601 - accuracy: 0.9846 - val_loss: 0.1458 - val_accuracy: 0.9494\n",
      "Epoch 838/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0604 - accuracy: 0.9848 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 839/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0603 - accuracy: 0.9848 - val_loss: 0.1390 - val_accuracy: 0.9532\n",
      "Epoch 840/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0602 - accuracy: 0.9857 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 841/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0604 - accuracy: 0.9844 - val_loss: 0.1366 - val_accuracy: 0.9535\n",
      "Epoch 842/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0601 - accuracy: 0.9850 - val_loss: 0.1397 - val_accuracy: 0.9528\n",
      "Epoch 843/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0601 - accuracy: 0.9854 - val_loss: 0.1369 - val_accuracy: 0.9528\n",
      "Epoch 844/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0600 - accuracy: 0.9853 - val_loss: 0.1358 - val_accuracy: 0.9539\n",
      "Epoch 845/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0600 - accuracy: 0.9852 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 846/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0601 - accuracy: 0.9845 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 847/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0598 - accuracy: 0.9856 - val_loss: 0.1402 - val_accuracy: 0.9522\n",
      "Epoch 848/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 849/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0599 - accuracy: 0.9853 - val_loss: 0.1365 - val_accuracy: 0.9532\n",
      "Epoch 850/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0600 - accuracy: 0.9845 - val_loss: 0.1356 - val_accuracy: 0.9539\n",
      "Epoch 851/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0599 - accuracy: 0.9850 - val_loss: 0.1369 - val_accuracy: 0.9528\n",
      "Epoch 852/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0597 - accuracy: 0.9844 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 853/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0598 - accuracy: 0.9850 - val_loss: 0.1368 - val_accuracy: 0.9532\n",
      "Epoch 854/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0598 - accuracy: 0.9842 - val_loss: 0.1383 - val_accuracy: 0.9532\n",
      "Epoch 855/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0597 - accuracy: 0.9849 - val_loss: 0.1389 - val_accuracy: 0.9532\n",
      "Epoch 856/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0599 - accuracy: 0.9844 - val_loss: 0.1351 - val_accuracy: 0.9542\n",
      "Epoch 857/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0597 - accuracy: 0.9852 - val_loss: 0.1449 - val_accuracy: 0.9494\n",
      "Epoch 858/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0596 - accuracy: 0.9854 - val_loss: 0.1372 - val_accuracy: 0.9528\n",
      "Epoch 859/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0595 - accuracy: 0.9848 - val_loss: 0.1347 - val_accuracy: 0.9545\n",
      "Epoch 860/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0597 - accuracy: 0.9853 - val_loss: 0.1365 - val_accuracy: 0.9532\n",
      "Epoch 861/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0596 - accuracy: 0.9850 - val_loss: 0.1394 - val_accuracy: 0.9528\n",
      "Epoch 862/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0595 - accuracy: 0.9856 - val_loss: 0.1401 - val_accuracy: 0.9525\n",
      "Epoch 863/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0596 - accuracy: 0.9846 - val_loss: 0.1392 - val_accuracy: 0.9528\n",
      "Epoch 864/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0593 - accuracy: 0.9852 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 865/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0595 - accuracy: 0.9852 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 866/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0595 - accuracy: 0.9846 - val_loss: 0.1342 - val_accuracy: 0.9549\n",
      "Epoch 867/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0594 - accuracy: 0.9848 - val_loss: 0.1415 - val_accuracy: 0.9522\n",
      "Epoch 868/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0595 - accuracy: 0.9849 - val_loss: 0.1370 - val_accuracy: 0.9535\n",
      "Epoch 869/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0593 - accuracy: 0.9849 - val_loss: 0.1345 - val_accuracy: 0.9545\n",
      "Epoch 870/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0593 - accuracy: 0.9850 - val_loss: 0.1365 - val_accuracy: 0.9532\n",
      "Epoch 871/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0593 - accuracy: 0.9844 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 872/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0592 - accuracy: 0.9856 - val_loss: 0.1367 - val_accuracy: 0.9528\n",
      "Epoch 873/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0592 - accuracy: 0.9845 - val_loss: 0.1361 - val_accuracy: 0.9535\n",
      "Epoch 874/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0591 - accuracy: 0.9846 - val_loss: 0.1353 - val_accuracy: 0.9539\n",
      "Epoch 875/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0591 - accuracy: 0.9848 - val_loss: 0.1397 - val_accuracy: 0.9525\n",
      "Epoch 876/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0593 - accuracy: 0.9849 - val_loss: 0.1377 - val_accuracy: 0.9532\n",
      "Epoch 877/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0590 - accuracy: 0.9854 - val_loss: 0.1357 - val_accuracy: 0.9539\n",
      "Epoch 878/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0590 - accuracy: 0.9850 - val_loss: 0.1403 - val_accuracy: 0.9525\n",
      "Epoch 879/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0591 - accuracy: 0.9852 - val_loss: 0.1369 - val_accuracy: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0593 - accuracy: 0.9848 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 881/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0592 - accuracy: 0.9852 - val_loss: 0.1389 - val_accuracy: 0.9532\n",
      "Epoch 882/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0591 - accuracy: 0.9857 - val_loss: 0.1355 - val_accuracy: 0.9542\n",
      "Epoch 883/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0590 - accuracy: 0.9848 - val_loss: 0.1365 - val_accuracy: 0.9528\n",
      "Epoch 884/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0591 - accuracy: 0.9852 - val_loss: 0.1394 - val_accuracy: 0.9525\n",
      "Epoch 885/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.1381 - val_accuracy: 0.9532\n",
      "Epoch 886/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0589 - accuracy: 0.9848 - val_loss: 0.1390 - val_accuracy: 0.9528\n",
      "Epoch 887/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0588 - accuracy: 0.9856 - val_loss: 0.1398 - val_accuracy: 0.9525\n",
      "Epoch 888/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0587 - accuracy: 0.9852 - val_loss: 0.1368 - val_accuracy: 0.9532\n",
      "Epoch 889/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0587 - accuracy: 0.9848 - val_loss: 0.1381 - val_accuracy: 0.9535\n",
      "Epoch 890/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0587 - accuracy: 0.9854 - val_loss: 0.1394 - val_accuracy: 0.9525\n",
      "Epoch 891/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0588 - accuracy: 0.9853 - val_loss: 0.1372 - val_accuracy: 0.9535\n",
      "Epoch 892/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0586 - accuracy: 0.9860 - val_loss: 0.1376 - val_accuracy: 0.9532\n",
      "Epoch 893/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0587 - accuracy: 0.9853 - val_loss: 0.1375 - val_accuracy: 0.9535\n",
      "Epoch 894/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0587 - accuracy: 0.9857 - val_loss: 0.1347 - val_accuracy: 0.9549\n",
      "Epoch 895/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0586 - accuracy: 0.9859 - val_loss: 0.1408 - val_accuracy: 0.9522\n",
      "Epoch 896/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0587 - accuracy: 0.9852 - val_loss: 0.1380 - val_accuracy: 0.9539\n",
      "Epoch 897/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0586 - accuracy: 0.9853 - val_loss: 0.1397 - val_accuracy: 0.9525\n",
      "Epoch 898/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0585 - accuracy: 0.9857 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 899/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0585 - accuracy: 0.9856 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 900/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0585 - accuracy: 0.9849 - val_loss: 0.1355 - val_accuracy: 0.9542\n",
      "Epoch 901/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0585 - accuracy: 0.9852 - val_loss: 0.1369 - val_accuracy: 0.9539\n",
      "Epoch 902/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0584 - accuracy: 0.9850 - val_loss: 0.1361 - val_accuracy: 0.9535\n",
      "Epoch 903/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0584 - accuracy: 0.9854 - val_loss: 0.1386 - val_accuracy: 0.9528\n",
      "Epoch 904/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0584 - accuracy: 0.9852 - val_loss: 0.1356 - val_accuracy: 0.9539\n",
      "Epoch 905/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0585 - accuracy: 0.9849 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 906/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 0.1387 - val_accuracy: 0.9528\n",
      "Epoch 907/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0582 - accuracy: 0.9849 - val_loss: 0.1368 - val_accuracy: 0.9528\n",
      "Epoch 908/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0583 - accuracy: 0.9859 - val_loss: 0.1348 - val_accuracy: 0.9542\n",
      "Epoch 909/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0582 - accuracy: 0.9854 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 910/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 0.1385 - val_accuracy: 0.9528\n",
      "Epoch 911/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0582 - accuracy: 0.9853 - val_loss: 0.1378 - val_accuracy: 0.9539\n",
      "Epoch 912/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - 0s 40us/step - loss: 0.0582 - accuracy: 0.9850 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 913/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0581 - accuracy: 0.9863 - val_loss: 0.1361 - val_accuracy: 0.9535\n",
      "Epoch 914/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0581 - accuracy: 0.9856 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 915/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0580 - accuracy: 0.9857 - val_loss: 0.1359 - val_accuracy: 0.9539\n",
      "Epoch 916/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0581 - accuracy: 0.9846 - val_loss: 0.1404 - val_accuracy: 0.9525\n",
      "Epoch 917/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0581 - accuracy: 0.9859 - val_loss: 0.1334 - val_accuracy: 0.9555\n",
      "Epoch 918/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0581 - accuracy: 0.9853 - val_loss: 0.1375 - val_accuracy: 0.9539\n",
      "Epoch 919/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0580 - accuracy: 0.9853 - val_loss: 0.1350 - val_accuracy: 0.9542\n",
      "Epoch 920/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0578 - accuracy: 0.9857 - val_loss: 0.1384 - val_accuracy: 0.9535\n",
      "Epoch 921/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0580 - accuracy: 0.9852 - val_loss: 0.1375 - val_accuracy: 0.9532\n",
      "Epoch 922/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 0.1413 - val_accuracy: 0.9518\n",
      "Epoch 923/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0580 - accuracy: 0.9857 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 924/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0579 - accuracy: 0.9849 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 925/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0579 - accuracy: 0.9852 - val_loss: 0.1356 - val_accuracy: 0.9539\n",
      "Epoch 926/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0577 - accuracy: 0.9859 - val_loss: 0.1382 - val_accuracy: 0.9532\n",
      "Epoch 927/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0577 - accuracy: 0.9852 - val_loss: 0.1358 - val_accuracy: 0.9539\n",
      "Epoch 928/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0578 - accuracy: 0.9852 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 929/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0578 - accuracy: 0.9850 - val_loss: 0.1372 - val_accuracy: 0.9539\n",
      "Epoch 930/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0576 - accuracy: 0.9856 - val_loss: 0.1410 - val_accuracy: 0.9518\n",
      "Epoch 931/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0578 - accuracy: 0.9854 - val_loss: 0.1355 - val_accuracy: 0.9535\n",
      "Epoch 932/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0577 - accuracy: 0.9859 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 933/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0576 - accuracy: 0.9854 - val_loss: 0.1333 - val_accuracy: 0.9555\n",
      "Epoch 934/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0577 - accuracy: 0.9857 - val_loss: 0.1355 - val_accuracy: 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0575 - accuracy: 0.9853 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 936/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0576 - accuracy: 0.9854 - val_loss: 0.1340 - val_accuracy: 0.9549\n",
      "Epoch 937/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0575 - accuracy: 0.9852 - val_loss: 0.1373 - val_accuracy: 0.9542\n",
      "Epoch 938/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0575 - accuracy: 0.9856 - val_loss: 0.1362 - val_accuracy: 0.9532\n",
      "Epoch 939/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0575 - accuracy: 0.9854 - val_loss: 0.1365 - val_accuracy: 0.9535\n",
      "Epoch 940/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0574 - accuracy: 0.9863 - val_loss: 0.1351 - val_accuracy: 0.9542\n",
      "Epoch 941/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0574 - accuracy: 0.9856 - val_loss: 0.1376 - val_accuracy: 0.9535\n",
      "Epoch 942/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0573 - accuracy: 0.9861 - val_loss: 0.1347 - val_accuracy: 0.9539\n",
      "Epoch 943/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0573 - accuracy: 0.9860 - val_loss: 0.1326 - val_accuracy: 0.9559\n",
      "Epoch 944/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0573 - accuracy: 0.9859 - val_loss: 0.1371 - val_accuracy: 0.9539\n",
      "Epoch 945/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0574 - accuracy: 0.9850 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 946/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0573 - accuracy: 0.9854 - val_loss: 0.1356 - val_accuracy: 0.9525\n",
      "Epoch 947/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0571 - accuracy: 0.9857 - val_loss: 0.1407 - val_accuracy: 0.9511\n",
      "Epoch 948/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0573 - accuracy: 0.9856 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 949/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0572 - accuracy: 0.9854 - val_loss: 0.1369 - val_accuracy: 0.9539\n",
      "Epoch 950/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0569 - accuracy: 0.9848 - val_loss: 0.1405 - val_accuracy: 0.9522\n",
      "Epoch 951/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0573 - accuracy: 0.9857 - val_loss: 0.1339 - val_accuracy: 0.9549\n",
      "Epoch 952/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0572 - accuracy: 0.9856 - val_loss: 0.1334 - val_accuracy: 0.9545\n",
      "Epoch 953/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0571 - accuracy: 0.9856 - val_loss: 0.1389 - val_accuracy: 0.9525\n",
      "Epoch 954/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0570 - accuracy: 0.9860 - val_loss: 0.1361 - val_accuracy: 0.9539\n",
      "Epoch 955/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0570 - accuracy: 0.9868 - val_loss: 0.1349 - val_accuracy: 0.9535\n",
      "Epoch 956/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0570 - accuracy: 0.9852 - val_loss: 0.1392 - val_accuracy: 0.9525\n",
      "Epoch 957/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0571 - accuracy: 0.9861 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 958/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0569 - accuracy: 0.9852 - val_loss: 0.1367 - val_accuracy: 0.9535\n",
      "Epoch 959/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0570 - accuracy: 0.9853 - val_loss: 0.1374 - val_accuracy: 0.9532\n",
      "Epoch 960/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0570 - accuracy: 0.9859 - val_loss: 0.1376 - val_accuracy: 0.9532\n",
      "Epoch 961/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0569 - accuracy: 0.9859 - val_loss: 0.1353 - val_accuracy: 0.9535\n",
      "Epoch 962/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0568 - accuracy: 0.9865 - val_loss: 0.1371 - val_accuracy: 0.9528\n",
      "Epoch 963/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0569 - accuracy: 0.9853 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 964/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0569 - accuracy: 0.9861 - val_loss: 0.1383 - val_accuracy: 0.9525\n",
      "Epoch 965/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0568 - accuracy: 0.9864 - val_loss: 0.1329 - val_accuracy: 0.9555\n",
      "Epoch 966/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0568 - accuracy: 0.9860 - val_loss: 0.1392 - val_accuracy: 0.9522\n",
      "Epoch 967/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0568 - accuracy: 0.9865 - val_loss: 0.1354 - val_accuracy: 0.9535\n",
      "Epoch 968/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0567 - accuracy: 0.9857 - val_loss: 0.1338 - val_accuracy: 0.9542\n",
      "Epoch 969/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0567 - accuracy: 0.9853 - val_loss: 0.1347 - val_accuracy: 0.9539\n",
      "Epoch 970/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0566 - accuracy: 0.9859 - val_loss: 0.1394 - val_accuracy: 0.9522\n",
      "Epoch 971/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0567 - accuracy: 0.9854 - val_loss: 0.1358 - val_accuracy: 0.9539\n",
      "Epoch 972/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0568 - accuracy: 0.9861 - val_loss: 0.1347 - val_accuracy: 0.9542\n",
      "Epoch 973/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.98 - 0s 40us/step - loss: 0.0567 - accuracy: 0.9856 - val_loss: 0.1394 - val_accuracy: 0.9522\n",
      "Epoch 974/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0567 - accuracy: 0.9856 - val_loss: 0.1345 - val_accuracy: 0.9539\n",
      "Epoch 975/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0565 - accuracy: 0.9859 - val_loss: 0.1389 - val_accuracy: 0.9522\n",
      "Epoch 976/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0565 - accuracy: 0.9857 - val_loss: 0.1368 - val_accuracy: 0.9535\n",
      "Epoch 977/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0566 - accuracy: 0.9857 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 978/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0564 - accuracy: 0.9868 - val_loss: 0.1360 - val_accuracy: 0.9539\n",
      "Epoch 979/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0566 - accuracy: 0.9863 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 980/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0565 - accuracy: 0.9859 - val_loss: 0.1358 - val_accuracy: 0.9532\n",
      "Epoch 981/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0565 - accuracy: 0.9864 - val_loss: 0.1369 - val_accuracy: 0.9532\n",
      "Epoch 982/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0563 - accuracy: 0.9863 - val_loss: 0.1359 - val_accuracy: 0.9528\n",
      "Epoch 983/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0563 - accuracy: 0.9867 - val_loss: 0.1347 - val_accuracy: 0.9528\n",
      "Epoch 984/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0563 - accuracy: 0.9861 - val_loss: 0.1358 - val_accuracy: 0.9539\n",
      "Epoch 985/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0563 - accuracy: 0.9863 - val_loss: 0.1390 - val_accuracy: 0.9525\n",
      "Epoch 986/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0564 - accuracy: 0.9859 - val_loss: 0.1371 - val_accuracy: 0.9532\n",
      "Epoch 987/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0563 - accuracy: 0.9867 - val_loss: 0.1351 - val_accuracy: 0.9535\n",
      "Epoch 988/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0563 - accuracy: 0.9864 - val_loss: 0.1339 - val_accuracy: 0.9542\n",
      "Epoch 989/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0562 - accuracy: 0.9863 - val_loss: 0.1392 - val_accuracy: 0.9518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0562 - accuracy: 0.9859 - val_loss: 0.1341 - val_accuracy: 0.9545\n",
      "Epoch 991/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0562 - accuracy: 0.9860 - val_loss: 0.1354 - val_accuracy: 0.9535\n",
      "Epoch 992/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0561 - accuracy: 0.9861 - val_loss: 0.1344 - val_accuracy: 0.9542\n",
      "Epoch 993/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0562 - accuracy: 0.9869 - val_loss: 0.1354 - val_accuracy: 0.9532\n",
      "Epoch 994/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0561 - accuracy: 0.9864 - val_loss: 0.1355 - val_accuracy: 0.9528\n",
      "Epoch 995/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 0.1358 - val_accuracy: 0.9532\n",
      "Epoch 996/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0562 - accuracy: 0.9859 - val_loss: 0.1348 - val_accuracy: 0.9535\n",
      "Epoch 997/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0561 - accuracy: 0.9861 - val_loss: 0.1380 - val_accuracy: 0.9525\n",
      "Epoch 998/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0561 - accuracy: 0.9869 - val_loss: 0.1371 - val_accuracy: 0.9528\n",
      "Epoch 999/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0561 - accuracy: 0.9864 - val_loss: 0.1381 - val_accuracy: 0.9528\n",
      "Epoch 1000/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0560 - accuracy: 0.9861 - val_loss: 0.1346 - val_accuracy: 0.9532\n",
      "Test score: 0.1345715648098051\n",
      "Test accuracy: 0.9531727433204651\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=1000, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + Sigmoid + SGD Optimizer + 1000 (512-128-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 354,182\n",
      "Trainable params: 354,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/1000\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 0.1357 - val_accuracy: 0.9532\n",
      "Epoch 2/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0558 - accuracy: 0.9865 - val_loss: 0.1316 - val_accuracy: 0.9552\n",
      "Epoch 3/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0561 - accuracy: 0.9861 - val_loss: 0.1356 - val_accuracy: 0.9532\n",
      "Epoch 4/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 0.1369 - val_accuracy: 0.9532\n",
      "Epoch 5/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0559 - accuracy: 0.9869 - val_loss: 0.1402 - val_accuracy: 0.9525\n",
      "Epoch 6/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0560 - accuracy: 0.9860 - val_loss: 0.1380 - val_accuracy: 0.9525\n",
      "Epoch 7/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0558 - accuracy: 0.9865 - val_loss: 0.1347 - val_accuracy: 0.9539\n",
      "Epoch 8/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0558 - accuracy: 0.9861 - val_loss: 0.1354 - val_accuracy: 0.9542\n",
      "Epoch 9/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0558 - accuracy: 0.9861 - val_loss: 0.1365 - val_accuracy: 0.9532\n",
      "Epoch 10/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0557 - accuracy: 0.9867 - val_loss: 0.1340 - val_accuracy: 0.9539\n",
      "Epoch 11/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0558 - accuracy: 0.9863 - val_loss: 0.1338 - val_accuracy: 0.9542\n",
      "Epoch 12/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0557 - accuracy: 0.9854 - val_loss: 0.1331 - val_accuracy: 0.9545\n",
      "Epoch 13/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0558 - accuracy: 0.9860 - val_loss: 0.1337 - val_accuracy: 0.9549\n",
      "Epoch 14/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0556 - accuracy: 0.9868 - val_loss: 0.1370 - val_accuracy: 0.9528\n",
      "Epoch 15/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0556 - accuracy: 0.9864 - val_loss: 0.1339 - val_accuracy: 0.9542\n",
      "Epoch 16/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0556 - accuracy: 0.9864 - val_loss: 0.1378 - val_accuracy: 0.9525\n",
      "Epoch 17/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0556 - accuracy: 0.9864 - val_loss: 0.1351 - val_accuracy: 0.9532\n",
      "Epoch 18/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0556 - accuracy: 0.9860 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 19/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0554 - accuracy: 0.9864 - val_loss: 0.1392 - val_accuracy: 0.9518\n",
      "Epoch 20/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0556 - accuracy: 0.9867 - val_loss: 0.1376 - val_accuracy: 0.9525\n",
      "Epoch 21/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0555 - accuracy: 0.9860 - val_loss: 0.1365 - val_accuracy: 0.9532\n",
      "Epoch 22/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0555 - accuracy: 0.9864 - val_loss: 0.1375 - val_accuracy: 0.9525\n",
      "Epoch 23/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0556 - accuracy: 0.9861 - val_loss: 0.1353 - val_accuracy: 0.9539\n",
      "Epoch 24/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0555 - accuracy: 0.9865 - val_loss: 0.1342 - val_accuracy: 0.9539\n",
      "Epoch 25/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0554 - accuracy: 0.9865 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 26/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0553 - accuracy: 0.9864 - val_loss: 0.1343 - val_accuracy: 0.9535\n",
      "Epoch 27/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0553 - accuracy: 0.9869 - val_loss: 0.1346 - val_accuracy: 0.9539\n",
      "Epoch 28/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0554 - accuracy: 0.9861 - val_loss: 0.1315 - val_accuracy: 0.9555\n",
      "Epoch 29/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0554 - accuracy: 0.9856 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 30/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0553 - accuracy: 0.9861 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 31/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0554 - accuracy: 0.9865 - val_loss: 0.1349 - val_accuracy: 0.9532\n",
      "Epoch 32/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0551 - accuracy: 0.9871 - val_loss: 0.1386 - val_accuracy: 0.9518\n",
      "Epoch 33/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0554 - accuracy: 0.9857 - val_loss: 0.1360 - val_accuracy: 0.9535\n",
      "Epoch 34/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0552 - accuracy: 0.9859 - val_loss: 0.1366 - val_accuracy: 0.9528\n",
      "Epoch 35/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0551 - accuracy: 0.9871 - val_loss: 0.1333 - val_accuracy: 0.9542\n",
      "Epoch 36/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0553 - accuracy: 0.9867 - val_loss: 0.1377 - val_accuracy: 0.9522\n",
      "Epoch 37/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.1365 - val_accuracy: 0.9535\n",
      "Epoch 38/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0551 - accuracy: 0.9860 - val_loss: 0.1366 - val_accuracy: 0.9528\n",
      "Epoch 39/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0550 - accuracy: 0.9861 - val_loss: 0.1365 - val_accuracy: 0.9528\n",
      "Epoch 40/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0551 - accuracy: 0.9864 - val_loss: 0.1324 - val_accuracy: 0.9549\n",
      "Epoch 41/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0550 - accuracy: 0.9868 - val_loss: 0.1340 - val_accuracy: 0.9535\n",
      "Epoch 42/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0550 - accuracy: 0.9864 - val_loss: 0.1364 - val_accuracy: 0.9528\n",
      "Epoch 43/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0549 - accuracy: 0.9860 - val_loss: 0.1378 - val_accuracy: 0.9522\n",
      "Epoch 44/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0550 - accuracy: 0.9867 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 45/1000\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.0550 - accuracy: 0.9863 - val_loss: 0.1342 - val_accuracy: 0.9539\n",
      "Epoch 46/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0550 - accuracy: 0.9865 - val_loss: 0.1363 - val_accuracy: 0.9528\n",
      "Epoch 47/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0546 - accuracy: 0.9871 - val_loss: 0.1410 - val_accuracy: 0.9515\n",
      "Epoch 48/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0551 - accuracy: 0.9865 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 49/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0549 - accuracy: 0.9863 - val_loss: 0.1322 - val_accuracy: 0.9549\n",
      "Epoch 50/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0548 - accuracy: 0.9861 - val_loss: 0.1368 - val_accuracy: 0.9528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0549 - accuracy: 0.9859 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 52/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0548 - accuracy: 0.9864 - val_loss: 0.1341 - val_accuracy: 0.9535\n",
      "Epoch 53/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0549 - accuracy: 0.9865 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 54/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0548 - accuracy: 0.9865 - val_loss: 0.1383 - val_accuracy: 0.9518\n",
      "Epoch 55/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0546 - accuracy: 0.9864 - val_loss: 0.1340 - val_accuracy: 0.9539\n",
      "Epoch 56/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0548 - accuracy: 0.9869 - val_loss: 0.1349 - val_accuracy: 0.9539\n",
      "Epoch 57/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0547 - accuracy: 0.9861 - val_loss: 0.1365 - val_accuracy: 0.9528\n",
      "Epoch 58/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0547 - accuracy: 0.9864 - val_loss: 0.1343 - val_accuracy: 0.9535\n",
      "Epoch 59/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0547 - accuracy: 0.9867 - val_loss: 0.1355 - val_accuracy: 0.9535\n",
      "Epoch 60/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0547 - accuracy: 0.9867 - val_loss: 0.1371 - val_accuracy: 0.9525\n",
      "Epoch 61/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0546 - accuracy: 0.9865 - val_loss: 0.1339 - val_accuracy: 0.9535\n",
      "Epoch 62/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0544 - accuracy: 0.9865 - val_loss: 0.1388 - val_accuracy: 0.9522\n",
      "Epoch 63/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0547 - accuracy: 0.9871 - val_loss: 0.1346 - val_accuracy: 0.9539\n",
      "Epoch 64/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0545 - accuracy: 0.9863 - val_loss: 0.1314 - val_accuracy: 0.9552\n",
      "Epoch 65/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0545 - accuracy: 0.9868 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 66/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0545 - accuracy: 0.9865 - val_loss: 0.1371 - val_accuracy: 0.9525\n",
      "Epoch 67/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0546 - accuracy: 0.9868 - val_loss: 0.1342 - val_accuracy: 0.9542\n",
      "Epoch 68/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0545 - accuracy: 0.9868 - val_loss: 0.1341 - val_accuracy: 0.9542\n",
      "Epoch 69/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0544 - accuracy: 0.9871 - val_loss: 0.1390 - val_accuracy: 0.9522\n",
      "Epoch 70/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0545 - accuracy: 0.9864 - val_loss: 0.1377 - val_accuracy: 0.9522\n",
      "Epoch 71/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0546 - accuracy: 0.9857 - val_loss: 0.1347 - val_accuracy: 0.9542\n",
      "Epoch 72/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0543 - accuracy: 0.9863 - val_loss: 0.1320 - val_accuracy: 0.9552\n",
      "Epoch 73/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.1321 - val_accuracy: 0.9549\n",
      "Epoch 74/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0544 - accuracy: 0.9867 - val_loss: 0.1412 - val_accuracy: 0.9508\n",
      "Epoch 75/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0545 - accuracy: 0.9872 - val_loss: 0.1341 - val_accuracy: 0.9542\n",
      "Epoch 76/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0544 - accuracy: 0.9860 - val_loss: 0.1344 - val_accuracy: 0.9542\n",
      "Epoch 77/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0543 - accuracy: 0.9861 - val_loss: 0.1339 - val_accuracy: 0.9542\n",
      "Epoch 78/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0542 - accuracy: 0.9861 - val_loss: 0.1354 - val_accuracy: 0.9532\n",
      "Epoch 79/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0541 - accuracy: 0.9869 - val_loss: 0.1364 - val_accuracy: 0.9528\n",
      "Epoch 80/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0543 - accuracy: 0.9868 - val_loss: 0.1333 - val_accuracy: 0.9539\n",
      "Epoch 81/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0542 - accuracy: 0.9865 - val_loss: 0.1367 - val_accuracy: 0.9528\n",
      "Epoch 82/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0542 - accuracy: 0.9871 - val_loss: 0.1373 - val_accuracy: 0.9525\n",
      "Epoch 83/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0541 - accuracy: 0.9869 - val_loss: 0.1349 - val_accuracy: 0.9542\n",
      "Epoch 84/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0541 - accuracy: 0.9869 - val_loss: 0.1368 - val_accuracy: 0.9525\n",
      "Epoch 85/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0542 - accuracy: 0.9868 - val_loss: 0.1343 - val_accuracy: 0.9542\n",
      "Epoch 86/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0541 - accuracy: 0.9864 - val_loss: 0.1338 - val_accuracy: 0.9545\n",
      "Epoch 87/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0539 - accuracy: 0.9863 - val_loss: 0.1328 - val_accuracy: 0.9545\n",
      "Epoch 88/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0541 - accuracy: 0.9865 - val_loss: 0.1318 - val_accuracy: 0.9552\n",
      "Epoch 89/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0539 - accuracy: 0.9876 - val_loss: 0.1342 - val_accuracy: 0.9545\n",
      "Epoch 90/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0540 - accuracy: 0.9861 - val_loss: 0.1333 - val_accuracy: 0.9539\n",
      "Epoch 91/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0539 - accuracy: 0.9871 - val_loss: 0.1334 - val_accuracy: 0.9539\n",
      "Epoch 92/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0540 - accuracy: 0.9869 - val_loss: 0.1359 - val_accuracy: 0.9535\n",
      "Epoch 93/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0540 - accuracy: 0.9869 - val_loss: 0.1326 - val_accuracy: 0.9542\n",
      "Epoch 94/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0539 - accuracy: 0.9864 - val_loss: 0.1342 - val_accuracy: 0.9542\n",
      "Epoch 95/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0540 - accuracy: 0.9864 - val_loss: 0.1338 - val_accuracy: 0.9549\n",
      "Epoch 96/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0539 - accuracy: 0.9876 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 97/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0539 - accuracy: 0.9869 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 98/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0539 - accuracy: 0.9869 - val_loss: 0.1334 - val_accuracy: 0.9545\n",
      "Epoch 99/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0539 - accuracy: 0.9868 - val_loss: 0.1353 - val_accuracy: 0.9539\n",
      "Epoch 100/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0539 - accuracy: 0.9871 - val_loss: 0.1336 - val_accuracy: 0.9545\n",
      "Epoch 101/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0538 - accuracy: 0.9867 - val_loss: 0.1367 - val_accuracy: 0.9528\n",
      "Epoch 102/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0538 - accuracy: 0.9869 - val_loss: 0.1349 - val_accuracy: 0.9535\n",
      "Epoch 103/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0537 - accuracy: 0.9860 - val_loss: 0.1326 - val_accuracy: 0.9545\n",
      "Epoch 104/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0538 - accuracy: 0.9865 - val_loss: 0.1320 - val_accuracy: 0.9549\n",
      "Epoch 105/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0539 - accuracy: 0.9867 - val_loss: 0.1360 - val_accuracy: 0.9528\n",
      "Epoch 106/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0537 - accuracy: 0.9865 - val_loss: 0.1360 - val_accuracy: 0.9528\n",
      "Epoch 107/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.1341 - val_accuracy: 0.9545\n",
      "Epoch 108/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0537 - accuracy: 0.9860 - val_loss: 0.1330 - val_accuracy: 0.9539\n",
      "Epoch 109/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0537 - accuracy: 0.9869 - val_loss: 0.1372 - val_accuracy: 0.9522\n",
      "Epoch 110/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0536 - accuracy: 0.9860 - val_loss: 0.1373 - val_accuracy: 0.9525\n",
      "Epoch 111/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0535 - accuracy: 0.9871 - val_loss: 0.1331 - val_accuracy: 0.9542\n",
      "Epoch 112/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0537 - accuracy: 0.9868 - val_loss: 0.1317 - val_accuracy: 0.9549\n",
      "Epoch 113/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0537 - accuracy: 0.9871 - val_loss: 0.1336 - val_accuracy: 0.9545\n",
      "Epoch 114/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0536 - accuracy: 0.9865 - val_loss: 0.1340 - val_accuracy: 0.9545\n",
      "Epoch 115/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0536 - accuracy: 0.9865 - val_loss: 0.1357 - val_accuracy: 0.9532\n",
      "Epoch 116/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0536 - accuracy: 0.9864 - val_loss: 0.1360 - val_accuracy: 0.9528\n",
      "Epoch 117/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0536 - accuracy: 0.9871 - val_loss: 0.1333 - val_accuracy: 0.9539\n",
      "Epoch 118/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0534 - accuracy: 0.9859 - val_loss: 0.1350 - val_accuracy: 0.9532\n",
      "Epoch 119/1000\n",
      "7352/7352 [==============================] - 0s 46us/step - loss: 0.0535 - accuracy: 0.9871 - val_loss: 0.1371 - val_accuracy: 0.9525\n",
      "Epoch 120/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0535 - accuracy: 0.9869 - val_loss: 0.1364 - val_accuracy: 0.9522\n",
      "Epoch 121/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0535 - accuracy: 0.9871 - val_loss: 0.1359 - val_accuracy: 0.9528\n",
      "Epoch 122/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0534 - accuracy: 0.9874 - val_loss: 0.1348 - val_accuracy: 0.9539\n",
      "Epoch 123/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0535 - accuracy: 0.9867 - val_loss: 0.1377 - val_accuracy: 0.9522\n",
      "Epoch 124/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0534 - accuracy: 0.9874 - val_loss: 0.1348 - val_accuracy: 0.9539\n",
      "Epoch 125/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0534 - accuracy: 0.9865 - val_loss: 0.1388 - val_accuracy: 0.9522\n",
      "Epoch 126/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0534 - accuracy: 0.9869 - val_loss: 0.1343 - val_accuracy: 0.9549\n",
      "Epoch 127/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0533 - accuracy: 0.9871 - val_loss: 0.1354 - val_accuracy: 0.9535\n",
      "Epoch 128/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0532 - accuracy: 0.9871 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 129/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0533 - accuracy: 0.9869 - val_loss: 0.1374 - val_accuracy: 0.9525\n",
      "Epoch 130/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0532 - accuracy: 0.9865 - val_loss: 0.1368 - val_accuracy: 0.9522\n",
      "Epoch 131/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 132/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0532 - accuracy: 0.9868 - val_loss: 0.1333 - val_accuracy: 0.9545\n",
      "Epoch 133/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0531 - accuracy: 0.9875 - val_loss: 0.1350 - val_accuracy: 0.9532\n",
      "Epoch 134/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0531 - accuracy: 0.9874 - val_loss: 0.1365 - val_accuracy: 0.9522\n",
      "Epoch 135/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0533 - accuracy: 0.9869 - val_loss: 0.1345 - val_accuracy: 0.9539\n",
      "Epoch 136/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0531 - accuracy: 0.9869 - val_loss: 0.1352 - val_accuracy: 0.9532\n",
      "Epoch 137/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0531 - accuracy: 0.9871 - val_loss: 0.1332 - val_accuracy: 0.9545\n",
      "Epoch 138/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0530 - accuracy: 0.9869 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 139/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0531 - accuracy: 0.9874 - val_loss: 0.1352 - val_accuracy: 0.9532\n",
      "Epoch 140/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0531 - accuracy: 0.9868 - val_loss: 0.1351 - val_accuracy: 0.9532\n",
      "Epoch 141/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0531 - accuracy: 0.9871 - val_loss: 0.1355 - val_accuracy: 0.9539\n",
      "Epoch 142/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0531 - accuracy: 0.9874 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 143/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0531 - accuracy: 0.9874 - val_loss: 0.1331 - val_accuracy: 0.9542\n",
      "Epoch 144/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0531 - accuracy: 0.9871 - val_loss: 0.1352 - val_accuracy: 0.9532\n",
      "Epoch 145/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.1341 - val_accuracy: 0.9545\n",
      "Epoch 146/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.1361 - val_accuracy: 0.9522\n",
      "Epoch 147/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.1357 - val_accuracy: 0.9528\n",
      "Epoch 148/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0529 - accuracy: 0.9871 - val_loss: 0.1337 - val_accuracy: 0.9549\n",
      "Epoch 149/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.1329 - val_accuracy: 0.9539\n",
      "Epoch 150/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.1387 - val_accuracy: 0.9522\n",
      "Epoch 151/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0529 - accuracy: 0.9868 - val_loss: 0.1332 - val_accuracy: 0.9545\n",
      "Epoch 152/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.1335 - val_accuracy: 0.9545\n",
      "Epoch 153/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0528 - accuracy: 0.9869 - val_loss: 0.1353 - val_accuracy: 0.9535\n",
      "Epoch 154/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0530 - accuracy: 0.9868 - val_loss: 0.1331 - val_accuracy: 0.9545\n",
      "Epoch 155/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0528 - accuracy: 0.9868 - val_loss: 0.1340 - val_accuracy: 0.9545\n",
      "Epoch 156/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0527 - accuracy: 0.9875 - val_loss: 0.1310 - val_accuracy: 0.9549\n",
      "Epoch 157/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0527 - accuracy: 0.9868 - val_loss: 0.1335 - val_accuracy: 0.9552\n",
      "Epoch 158/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0528 - accuracy: 0.9878 - val_loss: 0.1342 - val_accuracy: 0.9539\n",
      "Epoch 159/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.1363 - val_accuracy: 0.9525\n",
      "Epoch 160/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0526 - accuracy: 0.9868 - val_loss: 0.1332 - val_accuracy: 0.9545\n",
      "Epoch 161/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.1369 - val_accuracy: 0.9528\n",
      "Epoch 162/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0527 - accuracy: 0.9872 - val_loss: 0.1354 - val_accuracy: 0.9532\n",
      "Epoch 163/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.1327 - val_accuracy: 0.9542\n",
      "Epoch 164/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0526 - accuracy: 0.9868 - val_loss: 0.1338 - val_accuracy: 0.9552\n",
      "Epoch 165/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0526 - accuracy: 0.9871 - val_loss: 0.1335 - val_accuracy: 0.9555\n",
      "Epoch 166/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0526 - accuracy: 0.9871 - val_loss: 0.1360 - val_accuracy: 0.9535\n",
      "Epoch 167/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0525 - accuracy: 0.9868 - val_loss: 0.1368 - val_accuracy: 0.9535\n",
      "Epoch 168/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0526 - accuracy: 0.9874 - val_loss: 0.1336 - val_accuracy: 0.9555\n",
      "Epoch 169/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0526 - accuracy: 0.9874 - val_loss: 0.1340 - val_accuracy: 0.9545\n",
      "Epoch 170/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0525 - accuracy: 0.9867 - val_loss: 0.1327 - val_accuracy: 0.9542\n",
      "Epoch 171/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.1340 - val_accuracy: 0.9549\n",
      "Epoch 172/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0523 - accuracy: 0.9871 - val_loss: 0.1335 - val_accuracy: 0.9555\n",
      "Epoch 173/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0523 - accuracy: 0.9871 - val_loss: 0.1342 - val_accuracy: 0.9549\n",
      "Epoch 174/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0525 - accuracy: 0.9869 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 175/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0524 - accuracy: 0.9868 - val_loss: 0.1323 - val_accuracy: 0.9545\n",
      "Epoch 176/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0525 - accuracy: 0.9875 - val_loss: 0.1368 - val_accuracy: 0.9532\n",
      "Epoch 177/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0522 - accuracy: 0.9879 - val_loss: 0.1379 - val_accuracy: 0.9522\n",
      "Epoch 178/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0524 - accuracy: 0.9872 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 179/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0522 - accuracy: 0.9882 - val_loss: 0.1356 - val_accuracy: 0.9539\n",
      "Epoch 180/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0522 - accuracy: 0.9879 - val_loss: 0.1394 - val_accuracy: 0.9522\n",
      "Epoch 181/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0523 - accuracy: 0.9871 - val_loss: 0.1317 - val_accuracy: 0.9549\n",
      "Epoch 182/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0523 - accuracy: 0.9864 - val_loss: 0.1358 - val_accuracy: 0.9528\n",
      "Epoch 183/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0523 - accuracy: 0.9878 - val_loss: 0.1328 - val_accuracy: 0.9552\n",
      "Epoch 184/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0523 - accuracy: 0.9872 - val_loss: 0.1330 - val_accuracy: 0.9549\n",
      "Epoch 185/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0522 - accuracy: 0.9876 - val_loss: 0.1312 - val_accuracy: 0.9549\n",
      "Epoch 186/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0523 - accuracy: 0.9867 - val_loss: 0.1342 - val_accuracy: 0.9542\n",
      "Epoch 187/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0522 - accuracy: 0.9871 - val_loss: 0.1352 - val_accuracy: 0.9532\n",
      "Epoch 188/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0521 - accuracy: 0.9871 - val_loss: 0.1344 - val_accuracy: 0.9545\n",
      "Epoch 189/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 190/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0521 - accuracy: 0.9876 - val_loss: 0.1344 - val_accuracy: 0.9549\n",
      "Epoch 191/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.1398 - val_accuracy: 0.9518\n",
      "Epoch 192/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.1356 - val_accuracy: 0.9528\n",
      "Epoch 193/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0522 - accuracy: 0.9875 - val_loss: 0.1321 - val_accuracy: 0.9539\n",
      "Epoch 194/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0522 - accuracy: 0.9868 - val_loss: 0.1343 - val_accuracy: 0.9545\n",
      "Epoch 195/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0520 - accuracy: 0.9871 - val_loss: 0.1376 - val_accuracy: 0.9522\n",
      "Epoch 196/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0520 - accuracy: 0.9871 - val_loss: 0.1303 - val_accuracy: 0.9559\n",
      "Epoch 197/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0521 - accuracy: 0.9876 - val_loss: 0.1361 - val_accuracy: 0.9532\n",
      "Epoch 198/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0518 - accuracy: 0.9879 - val_loss: 0.1312 - val_accuracy: 0.9555\n",
      "Epoch 199/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0520 - accuracy: 0.9867 - val_loss: 0.1367 - val_accuracy: 0.9539\n",
      "Epoch 200/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0520 - accuracy: 0.9868 - val_loss: 0.1399 - val_accuracy: 0.9518\n",
      "Epoch 201/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0522 - accuracy: 0.9871 - val_loss: 0.1321 - val_accuracy: 0.9545\n",
      "Epoch 202/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0520 - accuracy: 0.9868 - val_loss: 0.1326 - val_accuracy: 0.9552\n",
      "Epoch 203/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0520 - accuracy: 0.9867 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 204/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.1353 - val_accuracy: 0.9539\n",
      "Epoch 205/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0521 - accuracy: 0.9878 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 206/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0519 - accuracy: 0.9874 - val_loss: 0.1364 - val_accuracy: 0.9525\n",
      "Epoch 207/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 208/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0519 - accuracy: 0.9874 - val_loss: 0.1341 - val_accuracy: 0.9549\n",
      "Epoch 209/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0519 - accuracy: 0.9876 - val_loss: 0.1339 - val_accuracy: 0.9549\n",
      "Epoch 210/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0518 - accuracy: 0.9879 - val_loss: 0.1351 - val_accuracy: 0.9535\n",
      "Epoch 211/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0518 - accuracy: 0.9880 - val_loss: 0.1370 - val_accuracy: 0.9528\n",
      "Epoch 212/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.98 - 0s 39us/step - loss: 0.0518 - accuracy: 0.9868 - val_loss: 0.1324 - val_accuracy: 0.9552\n",
      "Epoch 213/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 0.1309 - val_accuracy: 0.9562\n",
      "Epoch 214/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0516 - accuracy: 0.9874 - val_loss: 0.1369 - val_accuracy: 0.9528\n",
      "Epoch 215/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0518 - accuracy: 0.9867 - val_loss: 0.1328 - val_accuracy: 0.9552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0518 - accuracy: 0.9868 - val_loss: 0.1368 - val_accuracy: 0.9532\n",
      "Epoch 217/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0517 - accuracy: 0.9872 - val_loss: 0.1328 - val_accuracy: 0.9559\n",
      "Epoch 218/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0517 - accuracy: 0.9872 - val_loss: 0.1355 - val_accuracy: 0.9539\n",
      "Epoch 219/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0516 - accuracy: 0.9876 - val_loss: 0.1351 - val_accuracy: 0.9542\n",
      "Epoch 220/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0518 - accuracy: 0.9868 - val_loss: 0.1336 - val_accuracy: 0.9549\n",
      "Epoch 221/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0516 - accuracy: 0.9876 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 222/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0516 - accuracy: 0.9875 - val_loss: 0.1321 - val_accuracy: 0.9549\n",
      "Epoch 223/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0514 - accuracy: 0.9875 - val_loss: 0.1311 - val_accuracy: 0.9555\n",
      "Epoch 224/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0516 - accuracy: 0.9872 - val_loss: 0.1354 - val_accuracy: 0.9535\n",
      "Epoch 225/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0515 - accuracy: 0.9871 - val_loss: 0.1412 - val_accuracy: 0.9522\n",
      "Epoch 226/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0517 - accuracy: 0.9869 - val_loss: 0.1360 - val_accuracy: 0.9542\n",
      "Epoch 227/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0514 - accuracy: 0.9884 - val_loss: 0.1313 - val_accuracy: 0.9559\n",
      "Epoch 228/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0515 - accuracy: 0.9871 - val_loss: 0.1333 - val_accuracy: 0.9555\n",
      "Epoch 229/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0515 - accuracy: 0.9878 - val_loss: 0.1319 - val_accuracy: 0.9549\n",
      "Epoch 230/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0515 - accuracy: 0.9874 - val_loss: 0.1368 - val_accuracy: 0.9525\n",
      "Epoch 231/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0514 - accuracy: 0.9868 - val_loss: 0.1359 - val_accuracy: 0.9528\n",
      "Epoch 232/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0514 - accuracy: 0.9872 - val_loss: 0.1308 - val_accuracy: 0.9559\n",
      "Epoch 233/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0514 - accuracy: 0.9878 - val_loss: 0.1350 - val_accuracy: 0.9542\n",
      "Epoch 234/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0515 - accuracy: 0.9878 - val_loss: 0.1331 - val_accuracy: 0.9559\n",
      "Epoch 235/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0515 - accuracy: 0.9879 - val_loss: 0.1348 - val_accuracy: 0.9549\n",
      "Epoch 236/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0514 - accuracy: 0.9874 - val_loss: 0.1338 - val_accuracy: 0.9552\n",
      "Epoch 237/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0514 - accuracy: 0.9876 - val_loss: 0.1313 - val_accuracy: 0.9559\n",
      "Epoch 238/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0514 - accuracy: 0.9874 - val_loss: 0.1330 - val_accuracy: 0.9555\n",
      "Epoch 239/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.1376 - val_accuracy: 0.9528\n",
      "Epoch 240/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0514 - accuracy: 0.9871 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 241/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0512 - accuracy: 0.9875 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 242/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.1311 - val_accuracy: 0.9559\n",
      "Epoch 243/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0511 - accuracy: 0.9879 - val_loss: 0.1315 - val_accuracy: 0.9555\n",
      "Epoch 244/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0512 - accuracy: 0.9880 - val_loss: 0.1344 - val_accuracy: 0.9552\n",
      "Epoch 245/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0512 - accuracy: 0.9876 - val_loss: 0.1323 - val_accuracy: 0.9552\n",
      "Epoch 246/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0512 - accuracy: 0.9876 - val_loss: 0.1350 - val_accuracy: 0.9542\n",
      "Epoch 247/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0512 - accuracy: 0.9872 - val_loss: 0.1390 - val_accuracy: 0.9525\n",
      "Epoch 248/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0513 - accuracy: 0.9878 - val_loss: 0.1331 - val_accuracy: 0.9545\n",
      "Epoch 249/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.1315 - val_accuracy: 0.9552\n",
      "Epoch 250/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0512 - accuracy: 0.9878 - val_loss: 0.1350 - val_accuracy: 0.9545\n",
      "Epoch 251/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0511 - accuracy: 0.9879 - val_loss: 0.1360 - val_accuracy: 0.9539\n",
      "Epoch 252/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0510 - accuracy: 0.9882 - val_loss: 0.1321 - val_accuracy: 0.9552\n",
      "Epoch 253/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0511 - accuracy: 0.9878 - val_loss: 0.1330 - val_accuracy: 0.9555\n",
      "Epoch 254/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0511 - accuracy: 0.9880 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 255/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0512 - accuracy: 0.9874 - val_loss: 0.1343 - val_accuracy: 0.9542\n",
      "Epoch 256/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0512 - accuracy: 0.9878 - val_loss: 0.1346 - val_accuracy: 0.9549\n",
      "Epoch 257/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0510 - accuracy: 0.9876 - val_loss: 0.1300 - val_accuracy: 0.9562\n",
      "Epoch 258/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0511 - accuracy: 0.9876 - val_loss: 0.1318 - val_accuracy: 0.9552\n",
      "Epoch 259/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0509 - accuracy: 0.9878 - val_loss: 0.1367 - val_accuracy: 0.9528\n",
      "Epoch 260/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 261/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0511 - accuracy: 0.9878 - val_loss: 0.1353 - val_accuracy: 0.9542\n",
      "Epoch 262/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.1328 - val_accuracy: 0.9559\n",
      "Epoch 263/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0510 - accuracy: 0.9880 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 264/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0510 - accuracy: 0.9875 - val_loss: 0.1336 - val_accuracy: 0.9555\n",
      "Epoch 265/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0509 - accuracy: 0.9878 - val_loss: 0.1344 - val_accuracy: 0.9552\n",
      "Epoch 266/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0510 - accuracy: 0.9878 - val_loss: 0.1350 - val_accuracy: 0.9542\n",
      "Epoch 267/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0508 - accuracy: 0.9880 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 268/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0508 - accuracy: 0.9876 - val_loss: 0.1378 - val_accuracy: 0.9525\n",
      "Epoch 269/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0510 - accuracy: 0.9879 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 270/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0508 - accuracy: 0.9876 - val_loss: 0.1330 - val_accuracy: 0.9552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0508 - accuracy: 0.9876 - val_loss: 0.1355 - val_accuracy: 0.9535\n",
      "Epoch 272/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0507 - accuracy: 0.9880 - val_loss: 0.1393 - val_accuracy: 0.9522\n",
      "Epoch 273/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0508 - accuracy: 0.9886 - val_loss: 0.1395 - val_accuracy: 0.9508\n",
      "Epoch 274/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0509 - accuracy: 0.9879 - val_loss: 0.1353 - val_accuracy: 0.9542\n",
      "Epoch 275/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0508 - accuracy: 0.9879 - val_loss: 0.1334 - val_accuracy: 0.9552\n",
      "Epoch 276/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0507 - accuracy: 0.9878 - val_loss: 0.1316 - val_accuracy: 0.9552\n",
      "Epoch 277/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0508 - accuracy: 0.9875 - val_loss: 0.1341 - val_accuracy: 0.9555\n",
      "Epoch 278/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0508 - accuracy: 0.9871 - val_loss: 0.1346 - val_accuracy: 0.9549\n",
      "Epoch 279/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0507 - accuracy: 0.9879 - val_loss: 0.1362 - val_accuracy: 0.9535\n",
      "Epoch 280/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0505 - accuracy: 0.9874 - val_loss: 0.1412 - val_accuracy: 0.9522\n",
      "Epoch 281/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0506 - accuracy: 0.9878 - val_loss: 0.1320 - val_accuracy: 0.9552\n",
      "Epoch 282/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0507 - accuracy: 0.9882 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 283/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0507 - accuracy: 0.9875 - val_loss: 0.1317 - val_accuracy: 0.9555\n",
      "Epoch 284/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0506 - accuracy: 0.9875 - val_loss: 0.1315 - val_accuracy: 0.9549\n",
      "Epoch 285/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0505 - accuracy: 0.9879 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 286/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0507 - accuracy: 0.9874 - val_loss: 0.1343 - val_accuracy: 0.9549\n",
      "Epoch 287/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0506 - accuracy: 0.9875 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 288/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0505 - accuracy: 0.9875 - val_loss: 0.1323 - val_accuracy: 0.9552\n",
      "Epoch 289/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0505 - accuracy: 0.9883 - val_loss: 0.1348 - val_accuracy: 0.9542\n",
      "Epoch 290/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0506 - accuracy: 0.9879 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 291/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0505 - accuracy: 0.9879 - val_loss: 0.1340 - val_accuracy: 0.9555\n",
      "Epoch 292/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0505 - accuracy: 0.9879 - val_loss: 0.1315 - val_accuracy: 0.9559\n",
      "Epoch 293/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0506 - accuracy: 0.9875 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 294/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0505 - accuracy: 0.9871 - val_loss: 0.1321 - val_accuracy: 0.9562\n",
      "Epoch 295/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0505 - accuracy: 0.9880 - val_loss: 0.1338 - val_accuracy: 0.9552\n",
      "Epoch 296/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0504 - accuracy: 0.9879 - val_loss: 0.1303 - val_accuracy: 0.9559\n",
      "Epoch 297/1000\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.0504 - accuracy: 0.9887 - val_loss: 0.1379 - val_accuracy: 0.9525\n",
      "Epoch 298/1000\n",
      "7352/7352 [==============================] - 0s 48us/step - loss: 0.0504 - accuracy: 0.9882 - val_loss: 0.1335 - val_accuracy: 0.9552\n",
      "Epoch 299/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.1321 - val_accuracy: 0.9552\n",
      "Epoch 300/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0502 - accuracy: 0.9883 - val_loss: 0.1358 - val_accuracy: 0.9532\n",
      "Epoch 301/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0504 - accuracy: 0.9878 - val_loss: 0.1345 - val_accuracy: 0.9542\n",
      "Epoch 302/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0503 - accuracy: 0.9880 - val_loss: 0.1339 - val_accuracy: 0.9552\n",
      "Epoch 303/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.1349 - val_accuracy: 0.9545\n",
      "Epoch 304/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0504 - accuracy: 0.9883 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 305/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0503 - accuracy: 0.9880 - val_loss: 0.1318 - val_accuracy: 0.9552\n",
      "Epoch 306/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0504 - accuracy: 0.9880 - val_loss: 0.1314 - val_accuracy: 0.9552\n",
      "Epoch 307/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0504 - accuracy: 0.9882 - val_loss: 0.1343 - val_accuracy: 0.9545\n",
      "Epoch 308/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0502 - accuracy: 0.9879 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 309/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0502 - accuracy: 0.9883 - val_loss: 0.1330 - val_accuracy: 0.9552\n",
      "Epoch 310/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0501 - accuracy: 0.9883 - val_loss: 0.1363 - val_accuracy: 0.9539\n",
      "Epoch 311/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0502 - accuracy: 0.9875 - val_loss: 0.1343 - val_accuracy: 0.9559\n",
      "Epoch 312/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0502 - accuracy: 0.9883 - val_loss: 0.1378 - val_accuracy: 0.9528\n",
      "Epoch 313/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.1327 - val_accuracy: 0.9552\n",
      "Epoch 314/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 0.1347 - val_accuracy: 0.9545\n",
      "Epoch 315/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0502 - accuracy: 0.9879 - val_loss: 0.1370 - val_accuracy: 0.9539\n",
      "Epoch 316/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.1355 - val_accuracy: 0.9542\n",
      "Epoch 317/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0501 - accuracy: 0.9876 - val_loss: 0.1324 - val_accuracy: 0.9552\n",
      "Epoch 318/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0501 - accuracy: 0.9882 - val_loss: 0.1360 - val_accuracy: 0.9532\n",
      "Epoch 319/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0501 - accuracy: 0.9878 - val_loss: 0.1360 - val_accuracy: 0.9532\n",
      "Epoch 320/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0501 - accuracy: 0.9874 - val_loss: 0.1326 - val_accuracy: 0.9552\n",
      "Epoch 321/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0500 - accuracy: 0.9879 - val_loss: 0.1341 - val_accuracy: 0.9552\n",
      "Epoch 322/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0500 - accuracy: 0.9879 - val_loss: 0.1329 - val_accuracy: 0.9552\n",
      "Epoch 323/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0499 - accuracy: 0.9878 - val_loss: 0.1298 - val_accuracy: 0.9555\n",
      "Epoch 324/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0500 - accuracy: 0.9883 - val_loss: 0.1343 - val_accuracy: 0.9555\n",
      "Epoch 325/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0499 - accuracy: 0.9878 - val_loss: 0.1323 - val_accuracy: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0500 - accuracy: 0.9880 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 327/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0500 - accuracy: 0.9879 - val_loss: 0.1328 - val_accuracy: 0.9552\n",
      "Epoch 328/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0500 - accuracy: 0.9883 - val_loss: 0.1330 - val_accuracy: 0.9552\n",
      "Epoch 329/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0499 - accuracy: 0.9882 - val_loss: 0.1345 - val_accuracy: 0.9545\n",
      "Epoch 330/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0499 - accuracy: 0.9883 - val_loss: 0.1328 - val_accuracy: 0.9559\n",
      "Epoch 331/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0498 - accuracy: 0.9883 - val_loss: 0.1338 - val_accuracy: 0.9552\n",
      "Epoch 332/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0498 - accuracy: 0.9879 - val_loss: 0.1314 - val_accuracy: 0.9552\n",
      "Epoch 333/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0498 - accuracy: 0.9872 - val_loss: 0.1343 - val_accuracy: 0.9559\n",
      "Epoch 334/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0498 - accuracy: 0.9879 - val_loss: 0.1333 - val_accuracy: 0.9559\n",
      "Epoch 335/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0497 - accuracy: 0.9883 - val_loss: 0.1322 - val_accuracy: 0.9559\n",
      "Epoch 336/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0499 - accuracy: 0.9876 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 337/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0498 - accuracy: 0.9879 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 338/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0497 - accuracy: 0.9879 - val_loss: 0.1382 - val_accuracy: 0.9528\n",
      "Epoch 339/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0499 - accuracy: 0.9882 - val_loss: 0.1316 - val_accuracy: 0.9562\n",
      "Epoch 340/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0498 - accuracy: 0.9876 - val_loss: 0.1348 - val_accuracy: 0.9555\n",
      "Epoch 341/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0498 - accuracy: 0.9876 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 342/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.1342 - val_accuracy: 0.9552\n",
      "Epoch 343/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0497 - accuracy: 0.9886 - val_loss: 0.1317 - val_accuracy: 0.9559\n",
      "Epoch 344/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.1341 - val_accuracy: 0.9555\n",
      "Epoch 345/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 346/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 347/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0496 - accuracy: 0.9882 - val_loss: 0.1316 - val_accuracy: 0.9562\n",
      "Epoch 348/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0496 - accuracy: 0.9880 - val_loss: 0.1329 - val_accuracy: 0.9559\n",
      "Epoch 349/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.1333 - val_accuracy: 0.9559\n",
      "Epoch 350/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0495 - accuracy: 0.9884 - val_loss: 0.1340 - val_accuracy: 0.9555\n",
      "Epoch 351/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0496 - accuracy: 0.9879 - val_loss: 0.1362 - val_accuracy: 0.9539\n",
      "Epoch 352/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0496 - accuracy: 0.9878 - val_loss: 0.1339 - val_accuracy: 0.9555\n",
      "Epoch 353/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0496 - accuracy: 0.9879 - val_loss: 0.1343 - val_accuracy: 0.9555\n",
      "Epoch 354/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0495 - accuracy: 0.9875 - val_loss: 0.1362 - val_accuracy: 0.9535\n",
      "Epoch 355/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0495 - accuracy: 0.9880 - val_loss: 0.1364 - val_accuracy: 0.9535\n",
      "Epoch 356/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0494 - accuracy: 0.9883 - val_loss: 0.1409 - val_accuracy: 0.9525\n",
      "Epoch 357/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0497 - accuracy: 0.9874 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 358/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0495 - accuracy: 0.9886 - val_loss: 0.1316 - val_accuracy: 0.9562\n",
      "Epoch 359/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0495 - accuracy: 0.9880 - val_loss: 0.1317 - val_accuracy: 0.9559\n",
      "Epoch 360/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0494 - accuracy: 0.9880 - val_loss: 0.1324 - val_accuracy: 0.9559\n",
      "Epoch 361/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0494 - accuracy: 0.9880 - val_loss: 0.1319 - val_accuracy: 0.9559\n",
      "Epoch 362/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0494 - accuracy: 0.9874 - val_loss: 0.1345 - val_accuracy: 0.9559\n",
      "Epoch 363/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0494 - accuracy: 0.9875 - val_loss: 0.1337 - val_accuracy: 0.9555\n",
      "Epoch 364/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0494 - accuracy: 0.9883 - val_loss: 0.1320 - val_accuracy: 0.9552\n",
      "Epoch 365/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.98 - 0s 39us/step - loss: 0.0492 - accuracy: 0.9879 - val_loss: 0.1303 - val_accuracy: 0.9555\n",
      "Epoch 366/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0494 - accuracy: 0.9886 - val_loss: 0.1351 - val_accuracy: 0.9528\n",
      "Epoch 367/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0493 - accuracy: 0.9887 - val_loss: 0.1369 - val_accuracy: 0.9525\n",
      "Epoch 368/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0493 - accuracy: 0.9878 - val_loss: 0.1332 - val_accuracy: 0.9555\n",
      "Epoch 369/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0492 - accuracy: 0.9882 - val_loss: 0.1378 - val_accuracy: 0.9525\n",
      "Epoch 370/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0494 - accuracy: 0.9879 - val_loss: 0.1393 - val_accuracy: 0.9518\n",
      "Epoch 371/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 0.1393 - val_accuracy: 0.9518\n",
      "Epoch 372/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0493 - accuracy: 0.9883 - val_loss: 0.1335 - val_accuracy: 0.9559\n",
      "Epoch 373/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0494 - accuracy: 0.9880 - val_loss: 0.1334 - val_accuracy: 0.9555\n",
      "Epoch 374/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0493 - accuracy: 0.9884 - val_loss: 0.1341 - val_accuracy: 0.9552\n",
      "Epoch 375/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0493 - accuracy: 0.9886 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 376/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.98 - 0s 39us/step - loss: 0.0493 - accuracy: 0.9878 - val_loss: 0.1329 - val_accuracy: 0.9555\n",
      "Epoch 377/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0492 - accuracy: 0.9884 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 378/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 0.1330 - val_accuracy: 0.9559\n",
      "Epoch 379/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0491 - accuracy: 0.9882 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 380/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0491 - accuracy: 0.9882 - val_loss: 0.1300 - val_accuracy: 0.9562\n",
      "Epoch 381/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0493 - accuracy: 0.9880 - val_loss: 0.1325 - val_accuracy: 0.9552\n",
      "Epoch 382/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0491 - accuracy: 0.9876 - val_loss: 0.1335 - val_accuracy: 0.9559\n",
      "Epoch 383/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0491 - accuracy: 0.9882 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 384/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0492 - accuracy: 0.9879 - val_loss: 0.1331 - val_accuracy: 0.9562\n",
      "Epoch 385/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0491 - accuracy: 0.9880 - val_loss: 0.1330 - val_accuracy: 0.9562\n",
      "Epoch 386/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0491 - accuracy: 0.9879 - val_loss: 0.1368 - val_accuracy: 0.9532\n",
      "Epoch 387/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0492 - accuracy: 0.9880 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 388/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0490 - accuracy: 0.9878 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 389/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0491 - accuracy: 0.9883 - val_loss: 0.1330 - val_accuracy: 0.9559\n",
      "Epoch 390/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0491 - accuracy: 0.9878 - val_loss: 0.1345 - val_accuracy: 0.9559\n",
      "Epoch 391/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0490 - accuracy: 0.9888 - val_loss: 0.1351 - val_accuracy: 0.9542\n",
      "Epoch 392/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0491 - accuracy: 0.9879 - val_loss: 0.1320 - val_accuracy: 0.9559\n",
      "Epoch 393/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0490 - accuracy: 0.9880 - val_loss: 0.1377 - val_accuracy: 0.9525\n",
      "Epoch 394/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0491 - accuracy: 0.9879 - val_loss: 0.1327 - val_accuracy: 0.9555\n",
      "Epoch 395/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0490 - accuracy: 0.9879 - val_loss: 0.1305 - val_accuracy: 0.9559\n",
      "Epoch 396/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0490 - accuracy: 0.9880 - val_loss: 0.1374 - val_accuracy: 0.9525\n",
      "Epoch 397/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0489 - accuracy: 0.9884 - val_loss: 0.1333 - val_accuracy: 0.9559\n",
      "Epoch 398/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0489 - accuracy: 0.9880 - val_loss: 0.1304 - val_accuracy: 0.9559\n",
      "Epoch 399/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0490 - accuracy: 0.9878 - val_loss: 0.1311 - val_accuracy: 0.9552\n",
      "Epoch 400/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0489 - accuracy: 0.9882 - val_loss: 0.1373 - val_accuracy: 0.9525\n",
      "Epoch 401/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0489 - accuracy: 0.9884 - val_loss: 0.1360 - val_accuracy: 0.9535\n",
      "Epoch 402/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0489 - accuracy: 0.9875 - val_loss: 0.1334 - val_accuracy: 0.9562\n",
      "Epoch 403/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0489 - accuracy: 0.9884 - val_loss: 0.1342 - val_accuracy: 0.9559\n",
      "Epoch 404/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0490 - accuracy: 0.9876 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 405/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0490 - accuracy: 0.9880 - val_loss: 0.1340 - val_accuracy: 0.9559\n",
      "Epoch 406/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0488 - accuracy: 0.9887 - val_loss: 0.1328 - val_accuracy: 0.9559\n",
      "Epoch 407/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0489 - accuracy: 0.9887 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 408/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0489 - accuracy: 0.9878 - val_loss: 0.1344 - val_accuracy: 0.9549\n",
      "Epoch 409/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0489 - accuracy: 0.9886 - val_loss: 0.1346 - val_accuracy: 0.9552\n",
      "Epoch 410/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0488 - accuracy: 0.9883 - val_loss: 0.1369 - val_accuracy: 0.9528\n",
      "Epoch 411/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0488 - accuracy: 0.9878 - val_loss: 0.1335 - val_accuracy: 0.9562\n",
      "Epoch 412/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0488 - accuracy: 0.9884 - val_loss: 0.1308 - val_accuracy: 0.9559\n",
      "Epoch 413/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0488 - accuracy: 0.9874 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 414/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0487 - accuracy: 0.9880 - val_loss: 0.1332 - val_accuracy: 0.9559\n",
      "Epoch 415/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0487 - accuracy: 0.9882 - val_loss: 0.1336 - val_accuracy: 0.9559\n",
      "Epoch 416/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0485 - accuracy: 0.9880 - val_loss: 0.1302 - val_accuracy: 0.9566\n",
      "Epoch 417/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0486 - accuracy: 0.9887 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 418/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0487 - accuracy: 0.9878 - val_loss: 0.1344 - val_accuracy: 0.9545\n",
      "Epoch 419/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0487 - accuracy: 0.9883 - val_loss: 0.1301 - val_accuracy: 0.9566\n",
      "Epoch 420/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0488 - accuracy: 0.9876 - val_loss: 0.1313 - val_accuracy: 0.9559\n",
      "Epoch 421/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0487 - accuracy: 0.9884 - val_loss: 0.1322 - val_accuracy: 0.9559\n",
      "Epoch 422/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0486 - accuracy: 0.9882 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 423/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0487 - accuracy: 0.9883 - val_loss: 0.1336 - val_accuracy: 0.9559\n",
      "Epoch 424/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0486 - accuracy: 0.9882 - val_loss: 0.1339 - val_accuracy: 0.9562\n",
      "Epoch 425/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0485 - accuracy: 0.9884 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 426/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 0.1345 - val_accuracy: 0.9552\n",
      "Epoch 427/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0484 - accuracy: 0.9879 - val_loss: 0.1336 - val_accuracy: 0.9562\n",
      "Epoch 428/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0485 - accuracy: 0.9884 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 429/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0485 - accuracy: 0.9882 - val_loss: 0.1336 - val_accuracy: 0.9562\n",
      "Epoch 430/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0484 - accuracy: 0.9884 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 431/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0483 - accuracy: 0.9887 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 432/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0483 - accuracy: 0.9893 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 433/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0484 - accuracy: 0.9882 - val_loss: 0.1335 - val_accuracy: 0.9562\n",
      "Epoch 434/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0484 - accuracy: 0.9884 - val_loss: 0.1333 - val_accuracy: 0.9559\n",
      "Epoch 435/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0485 - accuracy: 0.9882 - val_loss: 0.1338 - val_accuracy: 0.9562\n",
      "Epoch 436/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0484 - accuracy: 0.9880 - val_loss: 0.1317 - val_accuracy: 0.9559\n",
      "Epoch 437/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0483 - accuracy: 0.9884 - val_loss: 0.1362 - val_accuracy: 0.9535\n",
      "Epoch 438/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0484 - accuracy: 0.9884 - val_loss: 0.1332 - val_accuracy: 0.9566\n",
      "Epoch 439/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0484 - accuracy: 0.9875 - val_loss: 0.1339 - val_accuracy: 0.9559\n",
      "Epoch 440/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0483 - accuracy: 0.9878 - val_loss: 0.1373 - val_accuracy: 0.9525\n",
      "Epoch 441/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0484 - accuracy: 0.9886 - val_loss: 0.1304 - val_accuracy: 0.9566\n",
      "Epoch 442/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0483 - accuracy: 0.9884 - val_loss: 0.1322 - val_accuracy: 0.9559\n",
      "Epoch 443/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0484 - accuracy: 0.9878 - val_loss: 0.1312 - val_accuracy: 0.9559\n",
      "Epoch 444/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0482 - accuracy: 0.9883 - val_loss: 0.1318 - val_accuracy: 0.9559\n",
      "Epoch 445/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0482 - accuracy: 0.9886 - val_loss: 0.1345 - val_accuracy: 0.9555\n",
      "Epoch 446/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0484 - accuracy: 0.9882 - val_loss: 0.1351 - val_accuracy: 0.9542\n",
      "Epoch 447/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0481 - accuracy: 0.9886 - val_loss: 0.1307 - val_accuracy: 0.9559\n",
      "Epoch 448/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0483 - accuracy: 0.9882 - val_loss: 0.1307 - val_accuracy: 0.9559\n",
      "Epoch 449/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0482 - accuracy: 0.9883 - val_loss: 0.1303 - val_accuracy: 0.9566\n",
      "Epoch 450/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0484 - accuracy: 0.9878 - val_loss: 0.1322 - val_accuracy: 0.9562\n",
      "Epoch 451/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0482 - accuracy: 0.9883 - val_loss: 0.1342 - val_accuracy: 0.9559\n",
      "Epoch 452/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0483 - accuracy: 0.9882 - val_loss: 0.1334 - val_accuracy: 0.9562\n",
      "Epoch 453/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0481 - accuracy: 0.9884 - val_loss: 0.1357 - val_accuracy: 0.9532\n",
      "Epoch 454/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.1321 - val_accuracy: 0.9562\n",
      "Epoch 455/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0482 - accuracy: 0.9888 - val_loss: 0.1324 - val_accuracy: 0.9562\n",
      "Epoch 456/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0481 - accuracy: 0.9884 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 457/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0481 - accuracy: 0.9886 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 458/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0482 - accuracy: 0.9879 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 459/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0479 - accuracy: 0.9887 - val_loss: 0.1302 - val_accuracy: 0.9569\n",
      "Epoch 460/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0480 - accuracy: 0.9882 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 461/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.1356 - val_accuracy: 0.9539\n",
      "Epoch 462/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0482 - accuracy: 0.9878 - val_loss: 0.1324 - val_accuracy: 0.9559\n",
      "Epoch 463/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0480 - accuracy: 0.9882 - val_loss: 0.1375 - val_accuracy: 0.9528\n",
      "Epoch 464/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0481 - accuracy: 0.9887 - val_loss: 0.1343 - val_accuracy: 0.9552\n",
      "Epoch 465/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0479 - accuracy: 0.9886 - val_loss: 0.1325 - val_accuracy: 0.9562\n",
      "Epoch 466/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0481 - accuracy: 0.9882 - val_loss: 0.1324 - val_accuracy: 0.9562\n",
      "Epoch 467/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 0.1329 - val_accuracy: 0.9566\n",
      "Epoch 468/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0480 - accuracy: 0.9882 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 469/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 470/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 0.1316 - val_accuracy: 0.9559\n",
      "Epoch 471/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0481 - accuracy: 0.9882 - val_loss: 0.1322 - val_accuracy: 0.9562\n",
      "Epoch 472/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0480 - accuracy: 0.9882 - val_loss: 0.1303 - val_accuracy: 0.9555\n",
      "Epoch 473/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 474/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0479 - accuracy: 0.9879 - val_loss: 0.1319 - val_accuracy: 0.9562\n",
      "Epoch 475/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0480 - accuracy: 0.9883 - val_loss: 0.1326 - val_accuracy: 0.9559\n",
      "Epoch 476/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0479 - accuracy: 0.9882 - val_loss: 0.1315 - val_accuracy: 0.9559\n",
      "Epoch 477/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0480 - accuracy: 0.9884 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 478/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 0.1332 - val_accuracy: 0.9562\n",
      "Epoch 479/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 0.1319 - val_accuracy: 0.9562\n",
      "Epoch 480/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0478 - accuracy: 0.9880 - val_loss: 0.1313 - val_accuracy: 0.9555\n",
      "Epoch 481/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0478 - accuracy: 0.9884 - val_loss: 0.1349 - val_accuracy: 0.9535\n",
      "Epoch 482/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0478 - accuracy: 0.9880 - val_loss: 0.1331 - val_accuracy: 0.9562\n",
      "Epoch 483/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0478 - accuracy: 0.9883 - val_loss: 0.1325 - val_accuracy: 0.9562\n",
      "Epoch 484/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0477 - accuracy: 0.9888 - val_loss: 0.1348 - val_accuracy: 0.9552\n",
      "Epoch 485/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 0.1313 - val_accuracy: 0.9562\n",
      "Epoch 486/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0479 - accuracy: 0.9878 - val_loss: 0.1334 - val_accuracy: 0.9566\n",
      "Epoch 487/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0479 - accuracy: 0.9884 - val_loss: 0.1327 - val_accuracy: 0.9566\n",
      "Epoch 488/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0478 - accuracy: 0.9886 - val_loss: 0.1352 - val_accuracy: 0.9535\n",
      "Epoch 489/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0477 - accuracy: 0.9888 - val_loss: 0.1334 - val_accuracy: 0.9562\n",
      "Epoch 490/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0477 - accuracy: 0.9882 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 491/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0475 - accuracy: 0.9891 - val_loss: 0.1422 - val_accuracy: 0.9518\n",
      "Epoch 492/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0477 - accuracy: 0.9878 - val_loss: 0.1370 - val_accuracy: 0.9528\n",
      "Epoch 493/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0478 - accuracy: 0.9883 - val_loss: 0.1367 - val_accuracy: 0.9532\n",
      "Epoch 494/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0477 - accuracy: 0.9883 - val_loss: 0.1342 - val_accuracy: 0.9555\n",
      "Epoch 495/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0477 - accuracy: 0.9886 - val_loss: 0.1332 - val_accuracy: 0.9562\n",
      "Epoch 496/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0476 - accuracy: 0.9888 - val_loss: 0.1382 - val_accuracy: 0.9525\n",
      "Epoch 497/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.1325 - val_accuracy: 0.9566\n",
      "Epoch 498/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0476 - accuracy: 0.9884 - val_loss: 0.1329 - val_accuracy: 0.9566\n",
      "Epoch 499/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 0.1361 - val_accuracy: 0.9535\n",
      "Epoch 500/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0476 - accuracy: 0.9887 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 501/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0477 - accuracy: 0.9880 - val_loss: 0.1337 - val_accuracy: 0.9562\n",
      "Epoch 502/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0475 - accuracy: 0.9886 - val_loss: 0.1302 - val_accuracy: 0.9566\n",
      "Epoch 503/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 504/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0475 - accuracy: 0.9884 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 505/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.1289 - val_accuracy: 0.9559\n",
      "Epoch 506/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0477 - accuracy: 0.9880 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 507/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.1310 - val_accuracy: 0.9562\n",
      "Epoch 508/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0475 - accuracy: 0.9883 - val_loss: 0.1333 - val_accuracy: 0.9562\n",
      "Epoch 509/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0474 - accuracy: 0.9880 - val_loss: 0.1357 - val_accuracy: 0.9539\n",
      "Epoch 510/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0475 - accuracy: 0.9884 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 511/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0475 - accuracy: 0.9883 - val_loss: 0.1313 - val_accuracy: 0.9559\n",
      "Epoch 512/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0474 - accuracy: 0.9878 - val_loss: 0.1354 - val_accuracy: 0.9539\n",
      "Epoch 513/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0475 - accuracy: 0.9886 - val_loss: 0.1329 - val_accuracy: 0.9562\n",
      "Epoch 514/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0474 - accuracy: 0.9886 - val_loss: 0.1389 - val_accuracy: 0.9528\n",
      "Epoch 515/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0474 - accuracy: 0.9894 - val_loss: 0.1331 - val_accuracy: 0.9562\n",
      "Epoch 516/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0473 - accuracy: 0.9886 - val_loss: 0.1348 - val_accuracy: 0.9539\n",
      "Epoch 517/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0474 - accuracy: 0.9884 - val_loss: 0.1312 - val_accuracy: 0.9562\n",
      "Epoch 518/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0473 - accuracy: 0.9883 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 519/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0474 - accuracy: 0.9887 - val_loss: 0.1313 - val_accuracy: 0.9559\n",
      "Epoch 520/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0473 - accuracy: 0.9880 - val_loss: 0.1355 - val_accuracy: 0.9539\n",
      "Epoch 521/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0474 - accuracy: 0.9884 - val_loss: 0.1337 - val_accuracy: 0.9562\n",
      "Epoch 522/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0473 - accuracy: 0.9883 - val_loss: 0.1310 - val_accuracy: 0.9562\n",
      "Epoch 523/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0473 - accuracy: 0.9884 - val_loss: 0.1344 - val_accuracy: 0.9555\n",
      "Epoch 524/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0473 - accuracy: 0.9887 - val_loss: 0.1351 - val_accuracy: 0.9539\n",
      "Epoch 525/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0474 - accuracy: 0.9879 - val_loss: 0.1330 - val_accuracy: 0.9562\n",
      "Epoch 526/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0473 - accuracy: 0.9891 - val_loss: 0.1333 - val_accuracy: 0.9562\n",
      "Epoch 527/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0473 - accuracy: 0.9886 - val_loss: 0.1338 - val_accuracy: 0.9562\n",
      "Epoch 528/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0472 - accuracy: 0.9883 - val_loss: 0.1306 - val_accuracy: 0.9559\n",
      "Epoch 529/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0473 - accuracy: 0.9887 - val_loss: 0.1341 - val_accuracy: 0.9559\n",
      "Epoch 530/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0473 - accuracy: 0.9888 - val_loss: 0.1341 - val_accuracy: 0.9559\n",
      "Epoch 531/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0472 - accuracy: 0.9883 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 532/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0472 - accuracy: 0.9891 - val_loss: 0.1332 - val_accuracy: 0.9562\n",
      "Epoch 533/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0473 - accuracy: 0.9884 - val_loss: 0.1335 - val_accuracy: 0.9562\n",
      "Epoch 534/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0472 - accuracy: 0.9891 - val_loss: 0.1388 - val_accuracy: 0.9528\n",
      "Epoch 535/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0473 - accuracy: 0.9890 - val_loss: 0.1342 - val_accuracy: 0.9555\n",
      "Epoch 536/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0472 - accuracy: 0.9884 - val_loss: 0.1312 - val_accuracy: 0.9566\n",
      "Epoch 537/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0470 - accuracy: 0.9894 - val_loss: 0.1309 - val_accuracy: 0.9562\n",
      "Epoch 538/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0472 - accuracy: 0.9884 - val_loss: 0.1329 - val_accuracy: 0.9562\n",
      "Epoch 539/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0471 - accuracy: 0.9886 - val_loss: 0.1336 - val_accuracy: 0.9562\n",
      "Epoch 540/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0472 - accuracy: 0.9888 - val_loss: 0.1332 - val_accuracy: 0.9562\n",
      "Epoch 541/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0471 - accuracy: 0.9883 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 542/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0471 - accuracy: 0.9887 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 543/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0470 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9545\n",
      "Epoch 544/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0470 - accuracy: 0.9891 - val_loss: 0.1347 - val_accuracy: 0.9542\n",
      "Epoch 545/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0471 - accuracy: 0.9883 - val_loss: 0.1329 - val_accuracy: 0.9562\n",
      "Epoch 546/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0471 - accuracy: 0.9887 - val_loss: 0.1318 - val_accuracy: 0.9562\n",
      "Epoch 547/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0470 - accuracy: 0.9887 - val_loss: 0.1308 - val_accuracy: 0.9562\n",
      "Epoch 548/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0470 - accuracy: 0.9886 - val_loss: 0.1315 - val_accuracy: 0.9566\n",
      "Epoch 549/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.1339 - val_accuracy: 0.9559\n",
      "Epoch 550/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0470 - accuracy: 0.9882 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 551/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0471 - accuracy: 0.9888 - val_loss: 0.1360 - val_accuracy: 0.9535\n",
      "Epoch 552/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 553/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0470 - accuracy: 0.9886 - val_loss: 0.1334 - val_accuracy: 0.9562\n",
      "Epoch 554/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0469 - accuracy: 0.9884 - val_loss: 0.1332 - val_accuracy: 0.9562\n",
      "Epoch 555/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0470 - accuracy: 0.9886 - val_loss: 0.1331 - val_accuracy: 0.9562\n",
      "Epoch 556/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0470 - accuracy: 0.9879 - val_loss: 0.1312 - val_accuracy: 0.9566\n",
      "Epoch 557/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0470 - accuracy: 0.9891 - val_loss: 0.1341 - val_accuracy: 0.9559\n",
      "Epoch 558/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0469 - accuracy: 0.9884 - val_loss: 0.1318 - val_accuracy: 0.9559\n",
      "Epoch 559/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 0.1338 - val_accuracy: 0.9559\n",
      "Epoch 560/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0469 - accuracy: 0.9883 - val_loss: 0.1311 - val_accuracy: 0.9566\n",
      "Epoch 561/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0468 - accuracy: 0.9888 - val_loss: 0.1335 - val_accuracy: 0.9562\n",
      "Epoch 562/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0467 - accuracy: 0.9878 - val_loss: 0.1315 - val_accuracy: 0.9566\n",
      "Epoch 563/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0468 - accuracy: 0.9887 - val_loss: 0.1297 - val_accuracy: 0.9562\n",
      "Epoch 564/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0469 - accuracy: 0.9886 - val_loss: 0.1339 - val_accuracy: 0.9559\n",
      "Epoch 565/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0467 - accuracy: 0.9890 - val_loss: 0.1309 - val_accuracy: 0.9562\n",
      "Epoch 566/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0468 - accuracy: 0.9883 - val_loss: 0.1340 - val_accuracy: 0.9559\n",
      "Epoch 567/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0468 - accuracy: 0.9887 - val_loss: 0.1353 - val_accuracy: 0.9539\n",
      "Epoch 568/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0467 - accuracy: 0.9883 - val_loss: 0.1372 - val_accuracy: 0.9528\n",
      "Epoch 569/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0468 - accuracy: 0.9886 - val_loss: 0.1334 - val_accuracy: 0.9559\n",
      "Epoch 570/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0468 - accuracy: 0.9890 - val_loss: 0.1329 - val_accuracy: 0.9559\n",
      "Epoch 571/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0467 - accuracy: 0.9888 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 572/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0467 - accuracy: 0.9887 - val_loss: 0.1297 - val_accuracy: 0.9566\n",
      "Epoch 573/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0467 - accuracy: 0.9895 - val_loss: 0.1373 - val_accuracy: 0.9528\n",
      "Epoch 574/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0468 - accuracy: 0.9887 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 575/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 576/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0468 - accuracy: 0.9879 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 577/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0467 - accuracy: 0.9884 - val_loss: 0.1329 - val_accuracy: 0.9562\n",
      "Epoch 578/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0467 - accuracy: 0.9888 - val_loss: 0.1328 - val_accuracy: 0.9562\n",
      "Epoch 579/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0467 - accuracy: 0.9886 - val_loss: 0.1348 - val_accuracy: 0.9539\n",
      "Epoch 580/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0467 - accuracy: 0.9883 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 581/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0465 - accuracy: 0.9893 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 582/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.1320 - val_accuracy: 0.9566\n",
      "Epoch 583/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0466 - accuracy: 0.9884 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 584/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 0.1349 - val_accuracy: 0.9539\n",
      "Epoch 585/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0464 - accuracy: 0.9888 - val_loss: 0.1293 - val_accuracy: 0.9562\n",
      "Epoch 586/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0466 - accuracy: 0.9888 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 587/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 0.1306 - val_accuracy: 0.9566\n",
      "Epoch 588/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9545\n",
      "Epoch 589/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0465 - accuracy: 0.9883 - val_loss: 0.1333 - val_accuracy: 0.9559\n",
      "Epoch 590/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.1299 - val_accuracy: 0.9566\n",
      "Epoch 591/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0466 - accuracy: 0.9883 - val_loss: 0.1350 - val_accuracy: 0.9542\n",
      "Epoch 592/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.1336 - val_accuracy: 0.9559\n",
      "Epoch 593/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0464 - accuracy: 0.9887 - val_loss: 0.1299 - val_accuracy: 0.9566\n",
      "Epoch 594/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0464 - accuracy: 0.9888 - val_loss: 0.1314 - val_accuracy: 0.9566\n",
      "Epoch 595/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 596/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0465 - accuracy: 0.9883 - val_loss: 0.1315 - val_accuracy: 0.9566\n",
      "Epoch 597/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0464 - accuracy: 0.9883 - val_loss: 0.1348 - val_accuracy: 0.9542\n",
      "Epoch 598/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.98 - 0s 31us/step - loss: 0.0464 - accuracy: 0.9888 - val_loss: 0.1372 - val_accuracy: 0.9528\n",
      "Epoch 599/1000\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.0463 - accuracy: 0.9893 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 600/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0464 - accuracy: 0.9887 - val_loss: 0.1310 - val_accuracy: 0.9566\n",
      "Epoch 601/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0462 - accuracy: 0.9891 - val_loss: 0.1368 - val_accuracy: 0.9535\n",
      "Epoch 602/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0464 - accuracy: 0.9883 - val_loss: 0.1348 - val_accuracy: 0.9552\n",
      "Epoch 603/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0464 - accuracy: 0.9886 - val_loss: 0.1320 - val_accuracy: 0.9562\n",
      "Epoch 604/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0464 - accuracy: 0.9886 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 605/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0463 - accuracy: 0.9886 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 606/1000\n",
      "7352/7352 [==============================] - 0s 28us/step - loss: 0.0463 - accuracy: 0.9888 - val_loss: 0.1351 - val_accuracy: 0.9535\n",
      "Epoch 607/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 608/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0464 - accuracy: 0.9883 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 609/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0463 - accuracy: 0.9880 - val_loss: 0.1302 - val_accuracy: 0.9566\n",
      "Epoch 610/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0464 - accuracy: 0.9888 - val_loss: 0.1326 - val_accuracy: 0.9562\n",
      "Epoch 611/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0463 - accuracy: 0.9891 - val_loss: 0.1339 - val_accuracy: 0.9552\n",
      "Epoch 612/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0464 - accuracy: 0.9890 - val_loss: 0.1350 - val_accuracy: 0.9542\n",
      "Epoch 613/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0462 - accuracy: 0.9893 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 614/1000\n",
      "7352/7352 [==============================] - 0s 34us/step - loss: 0.0462 - accuracy: 0.9887 - val_loss: 0.1313 - val_accuracy: 0.9569\n",
      "Epoch 615/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.1330 - val_accuracy: 0.9562\n",
      "Epoch 616/1000\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.0461 - accuracy: 0.9886 - val_loss: 0.1353 - val_accuracy: 0.9535\n",
      "Epoch 617/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0462 - accuracy: 0.9888 - val_loss: 0.1320 - val_accuracy: 0.9562\n",
      "Epoch 618/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0463 - accuracy: 0.9886 - val_loss: 0.1332 - val_accuracy: 0.9559\n",
      "Epoch 619/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0462 - accuracy: 0.9884 - val_loss: 0.1331 - val_accuracy: 0.9562\n",
      "Epoch 620/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0461 - accuracy: 0.9884 - val_loss: 0.1330 - val_accuracy: 0.9562\n",
      "Epoch 621/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0461 - accuracy: 0.9886 - val_loss: 0.1331 - val_accuracy: 0.9562\n",
      "Epoch 622/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0462 - accuracy: 0.9887 - val_loss: 0.1338 - val_accuracy: 0.9555\n",
      "Epoch 623/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0462 - accuracy: 0.9886 - val_loss: 0.1297 - val_accuracy: 0.9562\n",
      "Epoch 624/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0459 - accuracy: 0.9891 - val_loss: 0.1403 - val_accuracy: 0.9525\n",
      "Epoch 625/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0463 - accuracy: 0.9890 - val_loss: 0.1318 - val_accuracy: 0.9566\n",
      "Epoch 626/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 0.1324 - val_accuracy: 0.9562\n",
      "Epoch 627/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.1282 - val_accuracy: 0.9555\n",
      "Epoch 628/1000\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.0464 - accuracy: 0.9888 - val_loss: 0.1325 - val_accuracy: 0.9559\n",
      "Epoch 629/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 0.1379 - val_accuracy: 0.9528\n",
      "Epoch 630/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0462 - accuracy: 0.9884 - val_loss: 0.1316 - val_accuracy: 0.9566\n",
      "Epoch 631/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0460 - accuracy: 0.9886 - val_loss: 0.1326 - val_accuracy: 0.9559\n",
      "Epoch 632/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0460 - accuracy: 0.9886 - val_loss: 0.1312 - val_accuracy: 0.9569\n",
      "Epoch 633/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0460 - accuracy: 0.9886 - val_loss: 0.1306 - val_accuracy: 0.9566\n",
      "Epoch 634/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: 0.1307 - val_accuracy: 0.9566\n",
      "Epoch 635/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0462 - accuracy: 0.9884 - val_loss: 0.1332 - val_accuracy: 0.9559\n",
      "Epoch 636/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 0.1324 - val_accuracy: 0.9552\n",
      "Epoch 637/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0460 - accuracy: 0.9884 - val_loss: 0.1346 - val_accuracy: 0.9549\n",
      "Epoch 638/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0461 - accuracy: 0.9890 - val_loss: 0.1352 - val_accuracy: 0.9535\n",
      "Epoch 639/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.1342 - val_accuracy: 0.9555\n",
      "Epoch 640/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0458 - accuracy: 0.9886 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 641/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.1313 - val_accuracy: 0.9566\n",
      "Epoch 642/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 643/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0460 - accuracy: 0.9887 - val_loss: 0.1334 - val_accuracy: 0.9555\n",
      "Epoch 644/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0459 - accuracy: 0.9888 - val_loss: 0.1357 - val_accuracy: 0.9535\n",
      "Epoch 645/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.98 - 0s 39us/step - loss: 0.0459 - accuracy: 0.9886 - val_loss: 0.1333 - val_accuracy: 0.9555\n",
      "Epoch 646/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0459 - accuracy: 0.9883 - val_loss: 0.1300 - val_accuracy: 0.9566\n",
      "Epoch 647/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0460 - accuracy: 0.9884 - val_loss: 0.1318 - val_accuracy: 0.9566\n",
      "Epoch 648/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0459 - accuracy: 0.9886 - val_loss: 0.1305 - val_accuracy: 0.9566\n",
      "Epoch 649/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0459 - accuracy: 0.9891 - val_loss: 0.1323 - val_accuracy: 0.9559\n",
      "Epoch 650/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0459 - accuracy: 0.9886 - val_loss: 0.1330 - val_accuracy: 0.9562\n",
      "Epoch 651/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.98 - 0s 40us/step - loss: 0.0459 - accuracy: 0.9884 - val_loss: 0.1345 - val_accuracy: 0.9545\n",
      "Epoch 652/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0458 - accuracy: 0.9883 - val_loss: 0.1297 - val_accuracy: 0.9562\n",
      "Epoch 653/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0458 - accuracy: 0.9890 - val_loss: 0.1301 - val_accuracy: 0.9569\n",
      "Epoch 654/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0459 - accuracy: 0.9888 - val_loss: 0.1320 - val_accuracy: 0.9566\n",
      "Epoch 655/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0459 - accuracy: 0.9890 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 656/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0457 - accuracy: 0.9888 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 657/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.1324 - val_accuracy: 0.9559\n",
      "Epoch 658/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 0.1313 - val_accuracy: 0.9569\n",
      "Epoch 659/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0458 - accuracy: 0.9883 - val_loss: 0.1312 - val_accuracy: 0.9562\n",
      "Epoch 660/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0456 - accuracy: 0.9884 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 661/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0457 - accuracy: 0.9887 - val_loss: 0.1388 - val_accuracy: 0.9525\n",
      "Epoch 662/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.1301 - val_accuracy: 0.9569\n",
      "Epoch 663/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.1338 - val_accuracy: 0.9555\n",
      "Epoch 664/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.1305 - val_accuracy: 0.9569\n",
      "Epoch 665/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 0.1350 - val_accuracy: 0.9539\n",
      "Epoch 666/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.98 - 0s 39us/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9552\n",
      "Epoch 667/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0458 - accuracy: 0.9883 - val_loss: 0.1338 - val_accuracy: 0.9555\n",
      "Epoch 668/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0456 - accuracy: 0.9887 - val_loss: 0.1329 - val_accuracy: 0.9562\n",
      "Epoch 669/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0456 - accuracy: 0.9890 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 670/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0456 - accuracy: 0.9890 - val_loss: 0.1305 - val_accuracy: 0.9566\n",
      "Epoch 671/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.1329 - val_accuracy: 0.9559\n",
      "Epoch 672/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0456 - accuracy: 0.9888 - val_loss: 0.1322 - val_accuracy: 0.9559\n",
      "Epoch 673/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0457 - accuracy: 0.9887 - val_loss: 0.1300 - val_accuracy: 0.9569\n",
      "Epoch 674/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0456 - accuracy: 0.9891 - val_loss: 0.1335 - val_accuracy: 0.9555\n",
      "Epoch 675/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0456 - accuracy: 0.9886 - val_loss: 0.1355 - val_accuracy: 0.9535\n",
      "Epoch 676/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0456 - accuracy: 0.9891 - val_loss: 0.1320 - val_accuracy: 0.9562\n",
      "Epoch 677/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9888 - val_loss: 0.1310 - val_accuracy: 0.9569\n",
      "Epoch 678/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9893 - val_loss: 0.1353 - val_accuracy: 0.9535\n",
      "Epoch 679/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0456 - accuracy: 0.9886 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 680/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9890 - val_loss: 0.1323 - val_accuracy: 0.9559\n",
      "Epoch 681/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0456 - accuracy: 0.9890 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 682/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9884 - val_loss: 0.1320 - val_accuracy: 0.9562\n",
      "Epoch 683/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9887 - val_loss: 0.1338 - val_accuracy: 0.9555\n",
      "Epoch 684/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0455 - accuracy: 0.9891 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 685/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0454 - accuracy: 0.9891 - val_loss: 0.1315 - val_accuracy: 0.9569\n",
      "Epoch 686/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0454 - accuracy: 0.9887 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 687/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0455 - accuracy: 0.9888 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 688/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0454 - accuracy: 0.9887 - val_loss: 0.1307 - val_accuracy: 0.9569\n",
      "Epoch 689/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0455 - accuracy: 0.9887 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 690/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 0.1324 - val_accuracy: 0.9562\n",
      "Epoch 691/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0455 - accuracy: 0.9890 - val_loss: 0.1321 - val_accuracy: 0.9562\n",
      "Epoch 692/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0454 - accuracy: 0.9887 - val_loss: 0.1360 - val_accuracy: 0.9535\n",
      "Epoch 693/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0455 - accuracy: 0.9883 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 694/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0454 - accuracy: 0.9891 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 695/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.1336 - val_accuracy: 0.9555\n",
      "Epoch 696/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0454 - accuracy: 0.9888 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 697/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0454 - accuracy: 0.9886 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 698/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0455 - accuracy: 0.9890 - val_loss: 0.1317 - val_accuracy: 0.9566\n",
      "Epoch 699/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0452 - accuracy: 0.9893 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 700/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0453 - accuracy: 0.9894 - val_loss: 0.1338 - val_accuracy: 0.9552\n",
      "Epoch 701/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0453 - accuracy: 0.9890 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 702/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0454 - accuracy: 0.9888 - val_loss: 0.1366 - val_accuracy: 0.9532\n",
      "Epoch 703/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0454 - accuracy: 0.9888 - val_loss: 0.1332 - val_accuracy: 0.9555\n",
      "Epoch 704/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 0.1315 - val_accuracy: 0.9569\n",
      "Epoch 705/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 706/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0452 - accuracy: 0.9888 - val_loss: 0.1365 - val_accuracy: 0.9535\n",
      "Epoch 707/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0453 - accuracy: 0.9888 - val_loss: 0.1346 - val_accuracy: 0.9545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0453 - accuracy: 0.9887 - val_loss: 0.1321 - val_accuracy: 0.9562\n",
      "Epoch 709/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0453 - accuracy: 0.9888 - val_loss: 0.1349 - val_accuracy: 0.9539\n",
      "Epoch 710/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0452 - accuracy: 0.9888 - val_loss: 0.1303 - val_accuracy: 0.9569\n",
      "Epoch 711/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0452 - accuracy: 0.9887 - val_loss: 0.1343 - val_accuracy: 0.9552\n",
      "Epoch 712/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0452 - accuracy: 0.9888 - val_loss: 0.1302 - val_accuracy: 0.9566\n",
      "Epoch 713/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0450 - accuracy: 0.9890 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 714/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.1349 - val_accuracy: 0.9539\n",
      "Epoch 715/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0452 - accuracy: 0.9886 - val_loss: 0.1317 - val_accuracy: 0.9562\n",
      "Epoch 716/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0452 - accuracy: 0.9891 - val_loss: 0.1323 - val_accuracy: 0.9559\n",
      "Epoch 717/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0451 - accuracy: 0.9888 - val_loss: 0.1305 - val_accuracy: 0.9569\n",
      "Epoch 718/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0451 - accuracy: 0.9886 - val_loss: 0.1355 - val_accuracy: 0.9532\n",
      "Epoch 719/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0453 - accuracy: 0.9888 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 720/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0451 - accuracy: 0.9888 - val_loss: 0.1356 - val_accuracy: 0.9532\n",
      "Epoch 721/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0450 - accuracy: 0.9893 - val_loss: 0.1379 - val_accuracy: 0.9525\n",
      "Epoch 722/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0451 - accuracy: 0.9891 - val_loss: 0.1351 - val_accuracy: 0.9535\n",
      "Epoch 723/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0451 - accuracy: 0.9882 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 724/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0451 - accuracy: 0.9890 - val_loss: 0.1333 - val_accuracy: 0.9552\n",
      "Epoch 725/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0451 - accuracy: 0.9886 - val_loss: 0.1346 - val_accuracy: 0.9542\n",
      "Epoch 726/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0450 - accuracy: 0.9886 - val_loss: 0.1301 - val_accuracy: 0.9566\n",
      "Epoch 727/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0452 - accuracy: 0.9884 - val_loss: 0.1306 - val_accuracy: 0.9569\n",
      "Epoch 728/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0450 - accuracy: 0.9890 - val_loss: 0.1333 - val_accuracy: 0.9555\n",
      "Epoch 729/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0450 - accuracy: 0.9895 - val_loss: 0.1363 - val_accuracy: 0.9535\n",
      "Epoch 730/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0451 - accuracy: 0.9893 - val_loss: 0.1304 - val_accuracy: 0.9566\n",
      "Epoch 731/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0451 - accuracy: 0.9891 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 732/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0450 - accuracy: 0.9886 - val_loss: 0.1333 - val_accuracy: 0.9552\n",
      "Epoch 733/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0451 - accuracy: 0.9895 - val_loss: 0.1341 - val_accuracy: 0.9552\n",
      "Epoch 734/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0449 - accuracy: 0.9888 - val_loss: 0.1321 - val_accuracy: 0.9559\n",
      "Epoch 735/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0449 - accuracy: 0.9891 - val_loss: 0.1332 - val_accuracy: 0.9552\n",
      "Epoch 736/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.1337 - val_accuracy: 0.9555\n",
      "Epoch 737/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0450 - accuracy: 0.9891 - val_loss: 0.1346 - val_accuracy: 0.9545\n",
      "Epoch 738/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0450 - accuracy: 0.9893 - val_loss: 0.1358 - val_accuracy: 0.9532\n",
      "Epoch 739/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0450 - accuracy: 0.9887 - val_loss: 0.1319 - val_accuracy: 0.9559\n",
      "Epoch 740/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.1336 - val_accuracy: 0.9555\n",
      "Epoch 741/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0448 - accuracy: 0.9888 - val_loss: 0.1294 - val_accuracy: 0.9562\n",
      "Epoch 742/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.1318 - val_accuracy: 0.9562\n",
      "Epoch 743/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0449 - accuracy: 0.9893 - val_loss: 0.1318 - val_accuracy: 0.9562\n",
      "Epoch 744/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0449 - accuracy: 0.9888 - val_loss: 0.1302 - val_accuracy: 0.9572\n",
      "Epoch 745/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0450 - accuracy: 0.9887 - val_loss: 0.1354 - val_accuracy: 0.9535\n",
      "Epoch 746/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.1317 - val_accuracy: 0.9562\n",
      "Epoch 747/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0450 - accuracy: 0.9884 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 748/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.1316 - val_accuracy: 0.9562\n",
      "Epoch 749/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0448 - accuracy: 0.9897 - val_loss: 0.1292 - val_accuracy: 0.9569\n",
      "Epoch 750/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0449 - accuracy: 0.9886 - val_loss: 0.1313 - val_accuracy: 0.9562\n",
      "Epoch 751/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0447 - accuracy: 0.9887 - val_loss: 0.1355 - val_accuracy: 0.9535\n",
      "Epoch 752/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.1301 - val_accuracy: 0.9569\n",
      "Epoch 753/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0448 - accuracy: 0.9893 - val_loss: 0.1303 - val_accuracy: 0.9572\n",
      "Epoch 754/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0449 - accuracy: 0.9891 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 755/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0447 - accuracy: 0.9894 - val_loss: 0.1295 - val_accuracy: 0.9566\n",
      "Epoch 756/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0447 - accuracy: 0.9898 - val_loss: 0.1351 - val_accuracy: 0.9539\n",
      "Epoch 757/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 758/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0447 - accuracy: 0.9883 - val_loss: 0.1299 - val_accuracy: 0.9572\n",
      "Epoch 759/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0448 - accuracy: 0.9895 - val_loss: 0.1304 - val_accuracy: 0.9569\n",
      "Epoch 760/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0449 - accuracy: 0.9894 - val_loss: 0.1308 - val_accuracy: 0.9566\n",
      "Epoch 761/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0446 - accuracy: 0.9887 - val_loss: 0.1353 - val_accuracy: 0.9535\n",
      "Epoch 762/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0446 - accuracy: 0.9886 - val_loss: 0.1309 - val_accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 763/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.1317 - val_accuracy: 0.9562\n",
      "Epoch 764/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0446 - accuracy: 0.9893 - val_loss: 0.1304 - val_accuracy: 0.9569\n",
      "Epoch 765/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0446 - accuracy: 0.9887 - val_loss: 0.1363 - val_accuracy: 0.9532\n",
      "Epoch 766/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0447 - accuracy: 0.9887 - val_loss: 0.1325 - val_accuracy: 0.9552\n",
      "Epoch 767/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0447 - accuracy: 0.9891 - val_loss: 0.1305 - val_accuracy: 0.9569\n",
      "Epoch 768/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0446 - accuracy: 0.9894 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 769/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0446 - accuracy: 0.9887 - val_loss: 0.1287 - val_accuracy: 0.9559\n",
      "Epoch 770/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0448 - accuracy: 0.9891 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 771/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0447 - accuracy: 0.9886 - val_loss: 0.1295 - val_accuracy: 0.9566\n",
      "Epoch 772/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0447 - accuracy: 0.9890 - val_loss: 0.1329 - val_accuracy: 0.9555\n",
      "Epoch 773/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0446 - accuracy: 0.9897 - val_loss: 0.1308 - val_accuracy: 0.9566\n",
      "Epoch 774/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0445 - accuracy: 0.9891 - val_loss: 0.1307 - val_accuracy: 0.9566\n",
      "Epoch 775/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0446 - accuracy: 0.9886 - val_loss: 0.1334 - val_accuracy: 0.9552\n",
      "Epoch 776/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0446 - accuracy: 0.9891 - val_loss: 0.1310 - val_accuracy: 0.9566\n",
      "Epoch 777/1000\n",
      "7352/7352 [==============================] - 0s 33us/step - loss: 0.0445 - accuracy: 0.9888 - val_loss: 0.1323 - val_accuracy: 0.9552\n",
      "Epoch 778/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 0.1301 - val_accuracy: 0.9569\n",
      "Epoch 779/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0446 - accuracy: 0.9893 - val_loss: 0.1318 - val_accuracy: 0.9559\n",
      "Epoch 780/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 0.1334 - val_accuracy: 0.9552\n",
      "Epoch 781/1000\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.0445 - accuracy: 0.9887 - val_loss: 0.1319 - val_accuracy: 0.9559\n",
      "Epoch 782/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0443 - accuracy: 0.9894 - val_loss: 0.1370 - val_accuracy: 0.9539\n",
      "Epoch 783/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0444 - accuracy: 0.9894 - val_loss: 0.1283 - val_accuracy: 0.9552\n",
      "Epoch 784/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0445 - accuracy: 0.9890 - val_loss: 0.1319 - val_accuracy: 0.9559\n",
      "Epoch 785/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0445 - accuracy: 0.9891 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 786/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0445 - accuracy: 0.9890 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 787/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0445 - accuracy: 0.9894 - val_loss: 0.1313 - val_accuracy: 0.9566\n",
      "Epoch 788/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0444 - accuracy: 0.9890 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 789/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0444 - accuracy: 0.9890 - val_loss: 0.1325 - val_accuracy: 0.9552\n",
      "Epoch 790/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0445 - accuracy: 0.9891 - val_loss: 0.1292 - val_accuracy: 0.9569\n",
      "Epoch 791/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0444 - accuracy: 0.9899 - val_loss: 0.1338 - val_accuracy: 0.9552\n",
      "Epoch 792/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0444 - accuracy: 0.9895 - val_loss: 0.1347 - val_accuracy: 0.9542\n",
      "Epoch 793/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0442 - accuracy: 0.9895 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 794/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0444 - accuracy: 0.9894 - val_loss: 0.1322 - val_accuracy: 0.9559\n",
      "Epoch 795/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0444 - accuracy: 0.9886 - val_loss: 0.1293 - val_accuracy: 0.9569\n",
      "Epoch 796/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0444 - accuracy: 0.9890 - val_loss: 0.1306 - val_accuracy: 0.9569\n",
      "Epoch 797/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.1344 - val_accuracy: 0.9542\n",
      "Epoch 798/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0444 - accuracy: 0.9887 - val_loss: 0.1313 - val_accuracy: 0.9562\n",
      "Epoch 799/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.1364 - val_accuracy: 0.9532\n",
      "Epoch 800/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0444 - accuracy: 0.9891 - val_loss: 0.1305 - val_accuracy: 0.9569\n",
      "Epoch 801/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0444 - accuracy: 0.9890 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 802/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0444 - accuracy: 0.9888 - val_loss: 0.1317 - val_accuracy: 0.9562\n",
      "Epoch 803/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0444 - accuracy: 0.9893 - val_loss: 0.1341 - val_accuracy: 0.9545\n",
      "Epoch 804/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0443 - accuracy: 0.9890 - val_loss: 0.1312 - val_accuracy: 0.9562\n",
      "Epoch 805/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0441 - accuracy: 0.9895 - val_loss: 0.1290 - val_accuracy: 0.9562\n",
      "Epoch 806/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0444 - accuracy: 0.9895 - val_loss: 0.1343 - val_accuracy: 0.9549\n",
      "Epoch 807/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0443 - accuracy: 0.9886 - val_loss: 0.1343 - val_accuracy: 0.9545\n",
      "Epoch 808/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0441 - accuracy: 0.9894 - val_loss: 0.1277 - val_accuracy: 0.9555\n",
      "Epoch 809/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0444 - accuracy: 0.9886 - val_loss: 0.1308 - val_accuracy: 0.9566\n",
      "Epoch 810/1000\n",
      "7352/7352 [==============================] - 0s 35us/step - loss: 0.0444 - accuracy: 0.9890 - val_loss: 0.1352 - val_accuracy: 0.9542\n",
      "Epoch 811/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0441 - accuracy: 0.9897 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 812/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9889 ETA: 0s - loss: 0.0445 - accuracy: 0. - 0s 39us/step - loss: 0.0442 - accuracy: 0.9893 - val_loss: 0.1351 - val_accuracy: 0.9542\n",
      "Epoch 813/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0443 - accuracy: 0.9887 - val_loss: 0.1341 - val_accuracy: 0.9545\n",
      "Epoch 814/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0443 - accuracy: 0.9890 - val_loss: 0.1344 - val_accuracy: 0.9545\n",
      "Epoch 815/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0442 - accuracy: 0.9888 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 816/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0442 - accuracy: 0.9893 - val_loss: 0.1332 - val_accuracy: 0.9555\n",
      "Epoch 817/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0443 - accuracy: 0.9888 - val_loss: 0.1341 - val_accuracy: 0.9555\n",
      "Epoch 818/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0440 - accuracy: 0.9898 - val_loss: 0.1384 - val_accuracy: 0.9525\n",
      "Epoch 819/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0441 - accuracy: 0.9894 - val_loss: 0.1383 - val_accuracy: 0.9522\n",
      "Epoch 820/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0442 - accuracy: 0.9893 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 821/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0443 - accuracy: 0.9895 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 822/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0441 - accuracy: 0.9893 - val_loss: 0.1356 - val_accuracy: 0.9535\n",
      "Epoch 823/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.1322 - val_accuracy: 0.9552\n",
      "Epoch 824/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0441 - accuracy: 0.9893 - val_loss: 0.1295 - val_accuracy: 0.9566\n",
      "Epoch 825/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0442 - accuracy: 0.9898 - val_loss: 0.1324 - val_accuracy: 0.9552\n",
      "Epoch 826/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0438 - accuracy: 0.9891 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 827/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0441 - accuracy: 0.9894 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 828/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0440 - accuracy: 0.9886 - val_loss: 0.1319 - val_accuracy: 0.9562\n",
      "Epoch 829/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0441 - accuracy: 0.9890 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 830/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0440 - accuracy: 0.9891 - val_loss: 0.1298 - val_accuracy: 0.9569\n",
      "Epoch 831/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0441 - accuracy: 0.9890 - val_loss: 0.1356 - val_accuracy: 0.9539\n",
      "Epoch 832/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0441 - accuracy: 0.9891 - val_loss: 0.1325 - val_accuracy: 0.9552\n",
      "Epoch 833/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0441 - accuracy: 0.9888 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 834/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0441 - accuracy: 0.9893 - val_loss: 0.1328 - val_accuracy: 0.9552\n",
      "Epoch 835/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0441 - accuracy: 0.9888 - val_loss: 0.1327 - val_accuracy: 0.9552\n",
      "Epoch 836/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0440 - accuracy: 0.9895 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 837/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0440 - accuracy: 0.9888 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 838/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0439 - accuracy: 0.9894 - val_loss: 0.1374 - val_accuracy: 0.9525\n",
      "Epoch 839/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0439 - accuracy: 0.9891 - val_loss: 0.1345 - val_accuracy: 0.9542\n",
      "Epoch 840/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0440 - accuracy: 0.9886 - val_loss: 0.1303 - val_accuracy: 0.9569\n",
      "Epoch 841/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0440 - accuracy: 0.9890 - val_loss: 0.1331 - val_accuracy: 0.9552\n",
      "Epoch 842/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0440 - accuracy: 0.9890 - val_loss: 0.1327 - val_accuracy: 0.9552\n",
      "Epoch 843/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0440 - accuracy: 0.9893 - val_loss: 0.1312 - val_accuracy: 0.9562\n",
      "Epoch 844/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0439 - accuracy: 0.9891 - val_loss: 0.1344 - val_accuracy: 0.9549\n",
      "Epoch 845/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0440 - accuracy: 0.9888 - val_loss: 0.1342 - val_accuracy: 0.9549\n",
      "Epoch 846/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0439 - accuracy: 0.9893 - val_loss: 0.1329 - val_accuracy: 0.9555\n",
      "Epoch 847/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0439 - accuracy: 0.9891 - val_loss: 0.1344 - val_accuracy: 0.9549\n",
      "Epoch 848/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0439 - accuracy: 0.9887 - val_loss: 0.1324 - val_accuracy: 0.9549\n",
      "Epoch 849/1000\n",
      "7352/7352 [==============================] - 0s 32us/step - loss: 0.0440 - accuracy: 0.9894 - val_loss: 0.1321 - val_accuracy: 0.9559\n",
      "Epoch 850/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0439 - accuracy: 0.9891 - val_loss: 0.1309 - val_accuracy: 0.9569\n",
      "Epoch 851/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0439 - accuracy: 0.9894 - val_loss: 0.1351 - val_accuracy: 0.9545\n",
      "Epoch 852/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.1302 - val_accuracy: 0.9572\n",
      "Epoch 853/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.98 - 0s 40us/step - loss: 0.0439 - accuracy: 0.9897 - val_loss: 0.1335 - val_accuracy: 0.9552\n",
      "Epoch 854/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0439 - accuracy: 0.9888 - val_loss: 0.1365 - val_accuracy: 0.9535\n",
      "Epoch 855/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0439 - accuracy: 0.9894 - val_loss: 0.1337 - val_accuracy: 0.9555\n",
      "Epoch 856/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0438 - accuracy: 0.9887 - val_loss: 0.1294 - val_accuracy: 0.9572\n",
      "Epoch 857/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0438 - accuracy: 0.9893 - val_loss: 0.1365 - val_accuracy: 0.9542\n",
      "Epoch 858/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0440 - accuracy: 0.9890 - val_loss: 0.1352 - val_accuracy: 0.9539\n",
      "Epoch 859/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0438 - accuracy: 0.9891 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 860/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0439 - accuracy: 0.9890 - val_loss: 0.1331 - val_accuracy: 0.9552\n",
      "Epoch 861/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 0.1325 - val_accuracy: 0.9555\n",
      "Epoch 862/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0438 - accuracy: 0.9894 - val_loss: 0.1308 - val_accuracy: 0.9566\n",
      "Epoch 863/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0438 - accuracy: 0.9895 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 864/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.1340 - val_accuracy: 0.9549\n",
      "Epoch 865/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.1293 - val_accuracy: 0.9572\n",
      "Epoch 866/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.1309 - val_accuracy: 0.9569\n",
      "Epoch 867/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.1309 - val_accuracy: 0.9566\n",
      "Epoch 868/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0437 - accuracy: 0.9891 - val_loss: 0.1346 - val_accuracy: 0.9545\n",
      "Epoch 869/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0437 - accuracy: 0.9894 - val_loss: 0.1310 - val_accuracy: 0.9569\n",
      "Epoch 870/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0437 - accuracy: 0.9890 - val_loss: 0.1308 - val_accuracy: 0.9569\n",
      "Epoch 871/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0436 - accuracy: 0.9891 - val_loss: 0.1339 - val_accuracy: 0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 872/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0437 - accuracy: 0.9887 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 873/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0437 - accuracy: 0.9897 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 874/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 0.1363 - val_accuracy: 0.9539\n",
      "Epoch 875/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.1289 - val_accuracy: 0.9569\n",
      "Epoch 876/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.1301 - val_accuracy: 0.9572\n",
      "Epoch 877/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0436 - accuracy: 0.9897 - val_loss: 0.1318 - val_accuracy: 0.9562\n",
      "Epoch 878/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 879/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0436 - accuracy: 0.9888 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 880/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0437 - accuracy: 0.9897 - val_loss: 0.1329 - val_accuracy: 0.9555\n",
      "Epoch 881/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0436 - accuracy: 0.9895 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 882/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.1304 - val_accuracy: 0.9572\n",
      "Epoch 883/1000\n",
      "7352/7352 [==============================] - 0s 29us/step - loss: 0.0436 - accuracy: 0.9891 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 884/1000\n",
      "7352/7352 [==============================] - 0s 30us/step - loss: 0.0435 - accuracy: 0.9891 - val_loss: 0.1296 - val_accuracy: 0.9569\n",
      "Epoch 885/1000\n",
      "7352/7352 [==============================] - 0s 31us/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 0.1299 - val_accuracy: 0.9572\n",
      "Epoch 886/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0436 - accuracy: 0.9898 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 887/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0435 - accuracy: 0.9893 - val_loss: 0.1316 - val_accuracy: 0.9566\n",
      "Epoch 888/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 0.1331 - val_accuracy: 0.9559\n",
      "Epoch 889/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0435 - accuracy: 0.9893 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 890/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 0.1303 - val_accuracy: 0.9569\n",
      "Epoch 891/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0434 - accuracy: 0.9897 - val_loss: 0.1361 - val_accuracy: 0.9535\n",
      "Epoch 892/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0435 - accuracy: 0.9897 - val_loss: 0.1306 - val_accuracy: 0.9569\n",
      "Epoch 893/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.1303 - val_accuracy: 0.9569\n",
      "Epoch 894/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0435 - accuracy: 0.9888 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 895/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0435 - accuracy: 0.9891 - val_loss: 0.1327 - val_accuracy: 0.9555\n",
      "Epoch 896/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0435 - accuracy: 0.9891 - val_loss: 0.1316 - val_accuracy: 0.9562\n",
      "Epoch 897/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.1303 - val_accuracy: 0.9569\n",
      "Epoch 898/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.1340 - val_accuracy: 0.9549\n",
      "Epoch 899/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0435 - accuracy: 0.9890 - val_loss: 0.1308 - val_accuracy: 0.9569\n",
      "Epoch 900/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0435 - accuracy: 0.9895 - val_loss: 0.1308 - val_accuracy: 0.9566\n",
      "Epoch 901/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0433 - accuracy: 0.9894 - val_loss: 0.1298 - val_accuracy: 0.9569\n",
      "Epoch 902/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0436 - accuracy: 0.9894 - val_loss: 0.1326 - val_accuracy: 0.9552\n",
      "Epoch 903/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.1362 - val_accuracy: 0.9535\n",
      "Epoch 904/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 905/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0434 - accuracy: 0.9902 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 906/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.1285 - val_accuracy: 0.9562\n",
      "Epoch 907/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0434 - accuracy: 0.9897 - val_loss: 0.1315 - val_accuracy: 0.9562\n",
      "Epoch 908/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0434 - accuracy: 0.9895 - val_loss: 0.1335 - val_accuracy: 0.9555\n",
      "Epoch 909/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0434 - accuracy: 0.9890 - val_loss: 0.1318 - val_accuracy: 0.9562\n",
      "Epoch 910/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0434 - accuracy: 0.9891 - val_loss: 0.1326 - val_accuracy: 0.9555\n",
      "Epoch 911/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0434 - accuracy: 0.9890 - val_loss: 0.1329 - val_accuracy: 0.9555\n",
      "Epoch 912/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0434 - accuracy: 0.9895 - val_loss: 0.1312 - val_accuracy: 0.9562\n",
      "Epoch 913/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0433 - accuracy: 0.9891 - val_loss: 0.1339 - val_accuracy: 0.9552\n",
      "Epoch 914/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0433 - accuracy: 0.9895 - val_loss: 0.1315 - val_accuracy: 0.9562\n",
      "Epoch 915/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0434 - accuracy: 0.9894 - val_loss: 0.1340 - val_accuracy: 0.9552\n",
      "Epoch 916/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.1315 - val_accuracy: 0.9562\n",
      "Epoch 917/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0433 - accuracy: 0.9894 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 918/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0433 - accuracy: 0.9884 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 919/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0433 - accuracy: 0.9894 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 920/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 0.1313 - val_accuracy: 0.9562\n",
      "Epoch 921/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0434 - accuracy: 0.9891 - val_loss: 0.1315 - val_accuracy: 0.9562\n",
      "Epoch 922/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0432 - accuracy: 0.9894 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 923/1000\n",
      "7352/7352 [==============================] - 0s 37us/step - loss: 0.0432 - accuracy: 0.9895 - val_loss: 0.1380 - val_accuracy: 0.9528\n",
      "Epoch 924/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 0.1301 - val_accuracy: 0.9569\n",
      "Epoch 925/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0434 - accuracy: 0.9893 - val_loss: 0.1300 - val_accuracy: 0.9572\n",
      "Epoch 926/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0433 - accuracy: 0.9899 - val_loss: 0.1311 - val_accuracy: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0432 - accuracy: 0.9895 - val_loss: 0.1330 - val_accuracy: 0.9555\n",
      "Epoch 928/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0432 - accuracy: 0.9891 - val_loss: 0.1298 - val_accuracy: 0.9569\n",
      "Epoch 929/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0433 - accuracy: 0.9894 - val_loss: 0.1327 - val_accuracy: 0.9555\n",
      "Epoch 930/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0431 - accuracy: 0.9890 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 931/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0431 - accuracy: 0.9894 - val_loss: 0.1283 - val_accuracy: 0.9562\n",
      "Epoch 932/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0433 - accuracy: 0.9893 - val_loss: 0.1298 - val_accuracy: 0.9569\n",
      "Epoch 933/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0431 - accuracy: 0.9888 - val_loss: 0.1313 - val_accuracy: 0.9562\n",
      "Epoch 934/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0432 - accuracy: 0.9894 - val_loss: 0.1341 - val_accuracy: 0.9549\n",
      "Epoch 935/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0432 - accuracy: 0.9894 - val_loss: 0.1337 - val_accuracy: 0.9552\n",
      "Epoch 936/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0431 - accuracy: 0.9893 - val_loss: 0.1318 - val_accuracy: 0.9562\n",
      "Epoch 937/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0432 - accuracy: 0.9888 - val_loss: 0.1345 - val_accuracy: 0.9545\n",
      "Epoch 938/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0432 - accuracy: 0.9897 - val_loss: 0.1332 - val_accuracy: 0.9555\n",
      "Epoch 939/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0431 - accuracy: 0.9893 - val_loss: 0.1297 - val_accuracy: 0.9569\n",
      "Epoch 940/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0431 - accuracy: 0.9893 - val_loss: 0.1343 - val_accuracy: 0.9545\n",
      "Epoch 941/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.1278 - val_accuracy: 0.9562\n",
      "Epoch 942/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0432 - accuracy: 0.9888 - val_loss: 0.1305 - val_accuracy: 0.9569\n",
      "Epoch 943/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0431 - accuracy: 0.9898 - val_loss: 0.1284 - val_accuracy: 0.9562\n",
      "Epoch 944/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0432 - accuracy: 0.9893 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 945/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0431 - accuracy: 0.9888 - val_loss: 0.1311 - val_accuracy: 0.9562\n",
      "Epoch 946/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.1332 - val_accuracy: 0.9555\n",
      "Epoch 947/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0431 - accuracy: 0.9894 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 948/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0431 - accuracy: 0.9894 - val_loss: 0.1364 - val_accuracy: 0.9535\n",
      "Epoch 949/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.1285 - val_accuracy: 0.9562\n",
      "Epoch 950/1000\n",
      "7352/7352 [==============================] - 0s 36us/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.1325 - val_accuracy: 0.9555\n",
      "Epoch 951/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0431 - accuracy: 0.9894 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 952/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.1337 - val_accuracy: 0.9552\n",
      "Epoch 953/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.1300 - val_accuracy: 0.9569\n",
      "Epoch 954/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 955/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0430 - accuracy: 0.9894 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 956/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0430 - accuracy: 0.9902 - val_loss: 0.1314 - val_accuracy: 0.9562\n",
      "Epoch 957/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0430 - accuracy: 0.9897 - val_loss: 0.1337 - val_accuracy: 0.9552\n",
      "Epoch 958/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0429 - accuracy: 0.9894 - val_loss: 0.1310 - val_accuracy: 0.9566\n",
      "Epoch 959/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0430 - accuracy: 0.9891 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 960/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0429 - accuracy: 0.9897 - val_loss: 0.1342 - val_accuracy: 0.9549\n",
      "Epoch 961/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0429 - accuracy: 0.9898 - val_loss: 0.1332 - val_accuracy: 0.9555\n",
      "Epoch 962/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0428 - accuracy: 0.9894 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 963/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0429 - accuracy: 0.9898 - val_loss: 0.1316 - val_accuracy: 0.9562\n",
      "Epoch 964/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.1319 - val_accuracy: 0.9555\n",
      "Epoch 965/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0429 - accuracy: 0.9898 - val_loss: 0.1317 - val_accuracy: 0.9559\n",
      "Epoch 966/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.1335 - val_accuracy: 0.9552\n",
      "Epoch 967/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0430 - accuracy: 0.9893 - val_loss: 0.1329 - val_accuracy: 0.9552\n",
      "Epoch 968/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.1319 - val_accuracy: 0.9562\n",
      "Epoch 969/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.1349 - val_accuracy: 0.9545\n",
      "Epoch 970/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0429 - accuracy: 0.9898 - val_loss: 0.1328 - val_accuracy: 0.9555\n",
      "Epoch 971/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.1330 - val_accuracy: 0.9555\n",
      "Epoch 972/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.1325 - val_accuracy: 0.9555\n",
      "Epoch 973/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0430 - accuracy: 0.9895 - val_loss: 0.1313 - val_accuracy: 0.9562\n",
      "Epoch 974/1000\n",
      "7352/7352 [==============================] - 0s 41us/step - loss: 0.0428 - accuracy: 0.9888 - val_loss: 0.1304 - val_accuracy: 0.9566\n",
      "Epoch 975/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0429 - accuracy: 0.9897 - val_loss: 0.1325 - val_accuracy: 0.9555\n",
      "Epoch 976/1000\n",
      "7352/7352 [==============================] - 0s 40us/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.1327 - val_accuracy: 0.9555\n",
      "Epoch 977/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0429 - accuracy: 0.9895 - val_loss: 0.1347 - val_accuracy: 0.9542\n",
      "Epoch 978/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0428 - accuracy: 0.9894 - val_loss: 0.1324 - val_accuracy: 0.9559\n",
      "Epoch 979/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0428 - accuracy: 0.9888 - val_loss: 0.1292 - val_accuracy: 0.9572\n",
      "Epoch 980/1000\n",
      "7352/7352 [==============================] - 0s 38us/step - loss: 0.0427 - accuracy: 0.9894 - val_loss: 0.1351 - val_accuracy: 0.9545\n",
      "Epoch 981/1000\n",
      "7352/7352 [==============================] - 0s 39us/step - loss: 0.0427 - accuracy: 0.9893 - val_loss: 0.1309 - val_accuracy: 0.9566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.1361 - val_accuracy: 0.9542\n",
      "Epoch 983/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.1349 - val_accuracy: 0.9545\n",
      "Epoch 984/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0428 - accuracy: 0.9894 - val_loss: 0.1322 - val_accuracy: 0.9555\n",
      "Epoch 985/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.1301 - val_accuracy: 0.9566\n",
      "Epoch 986/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0429 - accuracy: 0.9893 - val_loss: 0.1304 - val_accuracy: 0.9566\n",
      "Epoch 987/1000\n",
      "7352/7352 [==============================] - 0s 45us/step - loss: 0.0428 - accuracy: 0.9893 - val_loss: 0.1320 - val_accuracy: 0.9555\n",
      "Epoch 988/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.1286 - val_accuracy: 0.9569\n",
      "Epoch 989/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.1307 - val_accuracy: 0.9566\n",
      "Epoch 990/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0427 - accuracy: 0.9894 - val_loss: 0.1331 - val_accuracy: 0.9555\n",
      "Epoch 991/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0425 - accuracy: 0.9898 - val_loss: 0.1409 - val_accuracy: 0.9522\n",
      "Epoch 992/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0428 - accuracy: 0.9894 - val_loss: 0.1344 - val_accuracy: 0.9549\n",
      "Epoch 993/1000\n",
      "7352/7352 [==============================] - 0s 42us/step - loss: 0.0427 - accuracy: 0.9897 - val_loss: 0.1310 - val_accuracy: 0.9562\n",
      "Epoch 994/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.1304 - val_accuracy: 0.9566\n",
      "Epoch 995/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0425 - accuracy: 0.9899 - val_loss: 0.1317 - val_accuracy: 0.9562\n",
      "Epoch 996/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0427 - accuracy: 0.9899 - val_loss: 0.1324 - val_accuracy: 0.9555\n",
      "Epoch 997/1000\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.0427 - accuracy: 0.9895 - val_loss: 0.1345 - val_accuracy: 0.9545\n",
      "Epoch 998/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0425 - accuracy: 0.9898 - val_loss: 0.1348 - val_accuracy: 0.9545\n",
      "Epoch 999/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0426 - accuracy: 0.9897 - val_loss: 0.1336 - val_accuracy: 0.9552\n",
      "Epoch 1000/1000\n",
      "7352/7352 [==============================] - 0s 43us/step - loss: 0.0425 - accuracy: 0.9895 - val_loss: 0.1352 - val_accuracy: 0.9549\n",
      "Test score: 0.13524737611680357\n",
      "Test accuracy: 0.9548693299293518\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = Sequential()\n",
    "\n",
    "model_sigmoid.add(Dense(512,activation='sigmoid',input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_sigmoid.summary()\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=1000, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## MLP + Sigmoid + Adam Optimizer + 1000 (512-128-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 354,182\n",
      "Trainable params: 354,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 6s 778us/step - loss: 1.0653 - accuracy: 0.6279 - val_loss: 0.6263 - val_accuracy: 0.8347\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 0.4189 - accuracy: 0.8836 - val_loss: 0.3264 - val_accuracy: 0.9114\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.2395 - accuracy: 0.9251 - val_loss: 0.2441 - val_accuracy: 0.9125\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.1671 - accuracy: 0.9474 - val_loss: 0.1952 - val_accuracy: 0.9304\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.1323 - accuracy: 0.9565 - val_loss: 0.1652 - val_accuracy: 0.9467\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.1142 - accuracy: 0.9610 - val_loss: 0.1492 - val_accuracy: 0.9494\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0921 - accuracy: 0.9705 - val_loss: 0.1614 - val_accuracy: 0.9416\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0896 - accuracy: 0.9695 - val_loss: 0.1739 - val_accuracy: 0.9321\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0694 - accuracy: 0.9776 - val_loss: 0.1550 - val_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0638 - accuracy: 0.9786 - val_loss: 0.1508 - val_accuracy: 0.9450\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0634 - accuracy: 0.9780 - val_loss: 0.1341 - val_accuracy: 0.9498\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.97 - 1s 92us/step - loss: 0.0717 - accuracy: 0.9739 - val_loss: 0.2386 - val_accuracy: 0.9101\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0701 - accuracy: 0.9752 - val_loss: 0.1557 - val_accuracy: 0.9450\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0526 - accuracy: 0.9808 - val_loss: 0.1694 - val_accuracy: 0.9382\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.1707 - val_accuracy: 0.9399\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0470 - accuracy: 0.9845 - val_loss: 0.1794 - val_accuracy: 0.9379\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.1442 - val_accuracy: 0.9494\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0544 - accuracy: 0.9814 - val_loss: 0.1708 - val_accuracy: 0.9410\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.1616 - val_accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0438 - accuracy: 0.9846 - val_loss: 0.1477 - val_accuracy: 0.9464\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_sigmoid.summary()\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + ReLU + SGD +1 1000 (512-128-6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 354,182\n",
      "Trainable params: 354,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/1000\n",
      "7352/7352 [==============================] - 1s 197us/step - loss: 0.8228 - accuracy: 0.7020 - val_loss: 0.6022 - val_accuracy: 0.7384\n",
      "Epoch 2/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.4711 - accuracy: 0.8324 - val_loss: 0.4563 - val_accuracy: 0.8242\n",
      "Epoch 3/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.3472 - accuracy: 0.8811 - val_loss: 0.5000 - val_accuracy: 0.8018\n",
      "Epoch 4/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.3321 - accuracy: 0.8774 - val_loss: 0.3606 - val_accuracy: 0.8480\n",
      "Epoch 5/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.2922 - accuracy: 0.8868 - val_loss: 0.3774 - val_accuracy: 0.8436\n",
      "Epoch 6/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.2554 - accuracy: 0.9094 - val_loss: 0.2659 - val_accuracy: 0.9203\n",
      "Epoch 7/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.2275 - accuracy: 0.9187 - val_loss: 0.3865 - val_accuracy: 0.8361\n",
      "Epoch 8/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.2095 - accuracy: 0.9279 - val_loss: 0.4979 - val_accuracy: 0.8147\n",
      "Epoch 9/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.1973 - accuracy: 0.9338 - val_loss: 0.4952 - val_accuracy: 0.8144\n",
      "Epoch 10/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.2225 - accuracy: 0.9180 - val_loss: 0.2072 - val_accuracy: 0.9332\n",
      "Epoch 11/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.1854 - accuracy: 0.9339 - val_loss: 0.3268 - val_accuracy: 0.8595\n",
      "Epoch 12/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.1883 - accuracy: 0.9290 - val_loss: 0.2276 - val_accuracy: 0.9165\n",
      "Epoch 13/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1739 - accuracy: 0.9365 - val_loss: 0.1986 - val_accuracy: 0.9264\n",
      "Epoch 14/1000\n",
      "7352/7352 [==============================] - 1s 74us/step - loss: 0.1656 - accuracy: 0.9385 - val_loss: 0.2134 - val_accuracy: 0.9104\n",
      "Epoch 15/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.1545 - accuracy: 0.9450 - val_loss: 0.2598 - val_accuracy: 0.8802\n",
      "Epoch 16/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.1396 - accuracy: 0.9508 - val_loss: 0.1988 - val_accuracy: 0.9199\n",
      "Epoch 17/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.1381 - accuracy: 0.9513 - val_loss: 0.2672 - val_accuracy: 0.8782\n",
      "Epoch 18/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.1392 - accuracy: 0.9497 - val_loss: 0.1879 - val_accuracy: 0.9260\n",
      "Epoch 19/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.1234 - accuracy: 0.9577 - val_loss: 0.1674 - val_accuracy: 0.9477\n",
      "Epoch 20/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.1543 - accuracy: 0.9397 - val_loss: 0.1621 - val_accuracy: 0.9494\n",
      "Epoch 21/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1282 - accuracy: 0.9550 - val_loss: 0.1969 - val_accuracy: 0.9125\n",
      "Epoch 22/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.1124 - accuracy: 0.9631 - val_loss: 0.1648 - val_accuracy: 0.9447\n",
      "Epoch 23/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1249 - accuracy: 0.9578 - val_loss: 0.1987 - val_accuracy: 0.9220\n",
      "Epoch 24/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.1027 - accuracy: 0.9682 - val_loss: 0.1655 - val_accuracy: 0.9376\n",
      "Epoch 25/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1652 - accuracy: 0.9438 - val_loss: 0.1512 - val_accuracy: 0.9518\n",
      "Epoch 26/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1081 - accuracy: 0.9618 - val_loss: 0.1491 - val_accuracy: 0.9477\n",
      "Epoch 27/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1209 - accuracy: 0.9569 - val_loss: 0.2081 - val_accuracy: 0.9050\n",
      "Epoch 28/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.1056 - accuracy: 0.9648 - val_loss: 0.1644 - val_accuracy: 0.9342\n",
      "Epoch 29/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.1198 - accuracy: 0.9559 - val_loss: 0.1589 - val_accuracy: 0.9430\n",
      "Epoch 30/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.1034 - accuracy: 0.9646 - val_loss: 0.1357 - val_accuracy: 0.9545\n",
      "Epoch 31/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.1043 - accuracy: 0.9634 - val_loss: 0.1691 - val_accuracy: 0.9372\n",
      "Epoch 32/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.1127 - accuracy: 0.9595 - val_loss: 0.1440 - val_accuracy: 0.9481\n",
      "Epoch 33/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1050 - accuracy: 0.9642 - val_loss: 0.1359 - val_accuracy: 0.9525\n",
      "Epoch 34/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0936 - accuracy: 0.9694 - val_loss: 0.1815 - val_accuracy: 0.9226\n",
      "Epoch 35/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.1023 - accuracy: 0.9626 - val_loss: 0.1313 - val_accuracy: 0.9539\n",
      "Epoch 36/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0840 - accuracy: 0.9732 - val_loss: 0.1298 - val_accuracy: 0.9566\n",
      "Epoch 37/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0824 - accuracy: 0.9740 - val_loss: 0.2264 - val_accuracy: 0.9050\n",
      "Epoch 38/1000\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0989 - accuracy: 0.9644 - val_loss: 0.1323 - val_accuracy: 0.9559\n",
      "Epoch 39/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0993 - accuracy: 0.9649 - val_loss: 0.1309 - val_accuracy: 0.9559\n",
      "Epoch 40/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0805 - accuracy: 0.9732 - val_loss: 0.1370 - val_accuracy: 0.9508\n",
      "Epoch 41/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0829 - accuracy: 0.9703 - val_loss: 0.6966 - val_accuracy: 0.7879\n",
      "Epoch 42/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.1002 - accuracy: 0.9663 - val_loss: 0.1269 - val_accuracy: 0.9559\n",
      "Epoch 43/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0762 - accuracy: 0.9736 - val_loss: 0.1551 - val_accuracy: 0.9372\n",
      "Epoch 44/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0752 - accuracy: 0.9754 - val_loss: 0.1329 - val_accuracy: 0.9528\n",
      "Epoch 45/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.1054 - accuracy: 0.9618 - val_loss: 0.1326 - val_accuracy: 0.9515\n",
      "Epoch 46/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.1418 - val_accuracy: 0.9467\n",
      "Epoch 47/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.1873 - val_accuracy: 0.9233\n",
      "Epoch 48/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 0.1269 - val_accuracy: 0.9555\n",
      "Epoch 49/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0700 - accuracy: 0.9770 - val_loss: 0.1499 - val_accuracy: 0.9440\n",
      "Epoch 50/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.1066 - accuracy: 0.9625 - val_loss: 0.1544 - val_accuracy: 0.9379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0746 - accuracy: 0.9721 - val_loss: 0.1226 - val_accuracy: 0.9566\n",
      "Epoch 52/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0893 - accuracy: 0.9668 - val_loss: 0.1202 - val_accuracy: 0.9583\n",
      "Epoch 53/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0705 - accuracy: 0.9784 - val_loss: 0.1518 - val_accuracy: 0.9410\n",
      "Epoch 54/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.97 - 1s 85us/step - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.1365 - val_accuracy: 0.9488\n",
      "Epoch 55/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 0.1199 - val_accuracy: 0.9600\n",
      "Epoch 56/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0645 - accuracy: 0.9800 - val_loss: 0.1382 - val_accuracy: 0.9477\n",
      "Epoch 57/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0695 - accuracy: 0.9761 - val_loss: 0.1586 - val_accuracy: 0.9369\n",
      "Epoch 58/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0661 - accuracy: 0.9771 - val_loss: 0.1297 - val_accuracy: 0.9525\n",
      "Epoch 59/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0643 - accuracy: 0.9776 - val_loss: 0.1353 - val_accuracy: 0.9498\n",
      "Epoch 60/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 0.1375 - val_accuracy: 0.9474\n",
      "Epoch 61/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0650 - accuracy: 0.9769 - val_loss: 0.1192 - val_accuracy: 0.9603\n",
      "Epoch 62/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0724 - accuracy: 0.9750 - val_loss: 0.1327 - val_accuracy: 0.9511\n",
      "Epoch 63/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0700 - accuracy: 0.9765 - val_loss: 0.1434 - val_accuracy: 0.9460\n",
      "Epoch 64/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0618 - accuracy: 0.9774 - val_loss: 0.1244 - val_accuracy: 0.9545\n",
      "Epoch 65/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0637 - accuracy: 0.9791 - val_loss: 0.1405 - val_accuracy: 0.9481\n",
      "Epoch 66/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.1788 - val_accuracy: 0.9298\n",
      "Epoch 67/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0608 - accuracy: 0.9784 - val_loss: 0.1220 - val_accuracy: 0.9559\n",
      "Epoch 68/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 0.1214 - val_accuracy: 0.9572\n",
      "Epoch 69/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 0.1729 - val_accuracy: 0.9342\n",
      "Epoch 70/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0615 - accuracy: 0.9778 - val_loss: 0.1223 - val_accuracy: 0.9569\n",
      "Epoch 71/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0710 - accuracy: 0.9759 - val_loss: 0.1292 - val_accuracy: 0.9522\n",
      "Epoch 72/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0620 - accuracy: 0.9778 - val_loss: 0.1296 - val_accuracy: 0.9518\n",
      "Epoch 73/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0923 - accuracy: 0.9693 - val_loss: 0.1984 - val_accuracy: 0.9220\n",
      "Epoch 74/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0579 - accuracy: 0.9793 - val_loss: 0.1313 - val_accuracy: 0.9494\n",
      "Epoch 75/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0605 - accuracy: 0.9816 - val_loss: 0.1330 - val_accuracy: 0.9491\n",
      "Epoch 76/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0563 - accuracy: 0.9804 - val_loss: 0.1204 - val_accuracy: 0.9555\n",
      "Epoch 77/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0524 - accuracy: 0.9833 - val_loss: 0.1786 - val_accuracy: 0.9298\n",
      "Epoch 78/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 0.1252 - val_accuracy: 0.9559\n",
      "Epoch 79/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0557 - accuracy: 0.9812 - val_loss: 0.1176 - val_accuracy: 0.9589\n",
      "Epoch 80/1000\n",
      "7352/7352 [==============================] - 1s 74us/step - loss: 0.0525 - accuracy: 0.9815 - val_loss: 0.1658 - val_accuracy: 0.9376\n",
      "Epoch 81/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0492 - accuracy: 0.9853 - val_loss: 0.1455 - val_accuracy: 0.9430\n",
      "Epoch 82/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 0.1522 - val_accuracy: 0.9447\n",
      "Epoch 83/1000\n",
      "7352/7352 [==============================] - 1s 68us/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.1144 - val_accuracy: 0.9600\n",
      "Epoch 84/1000\n",
      "7352/7352 [==============================] - 0s 61us/step - loss: 0.0632 - accuracy: 0.9765 - val_loss: 0.1281 - val_accuracy: 0.9539\n",
      "Epoch 85/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0535 - accuracy: 0.9796 - val_loss: 0.1781 - val_accuracy: 0.9311\n",
      "Epoch 86/1000\n",
      "7352/7352 [==============================] - 0s 64us/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 0.1317 - val_accuracy: 0.9518\n",
      "Epoch 87/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.1452 - val_accuracy: 0.9460\n",
      "Epoch 88/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.1499 - val_accuracy: 0.9454\n",
      "Epoch 89/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 0.1222 - val_accuracy: 0.9539\n",
      "Epoch 90/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 0.1262 - val_accuracy: 0.9539\n",
      "Epoch 91/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0547 - accuracy: 0.9816 - val_loss: 0.1294 - val_accuracy: 0.9532\n",
      "Epoch 92/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0446 - accuracy: 0.9867 - val_loss: 0.1246 - val_accuracy: 0.9545\n",
      "Epoch 93/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 0.1217 - val_accuracy: 0.9576\n",
      "Epoch 94/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0566 - accuracy: 0.9805 - val_loss: 0.1257 - val_accuracy: 0.9545\n",
      "Epoch 95/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0523 - accuracy: 0.9814 - val_loss: 0.1470 - val_accuracy: 0.9477\n",
      "Epoch 96/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0453 - accuracy: 0.9850 - val_loss: 0.1184 - val_accuracy: 0.9596\n",
      "Epoch 97/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0508 - accuracy: 0.9825 - val_loss: 0.2438 - val_accuracy: 0.9101\n",
      "Epoch 98/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 0.1456 - val_accuracy: 0.9420\n",
      "Epoch 99/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0519 - accuracy: 0.9818 - val_loss: 0.1177 - val_accuracy: 0.9589\n",
      "Epoch 100/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0624 - accuracy: 0.9774 - val_loss: 0.1181 - val_accuracy: 0.9576\n",
      "Epoch 101/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.1229 - val_accuracy: 0.9555\n",
      "Epoch 102/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0408 - accuracy: 0.9871 - val_loss: 0.1135 - val_accuracy: 0.9617\n",
      "Epoch 103/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.1201 - val_accuracy: 0.9572\n",
      "Epoch 104/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.1157 - val_accuracy: 0.9617\n",
      "Epoch 105/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0483 - accuracy: 0.9848 - val_loss: 0.1167 - val_accuracy: 0.9596\n",
      "Epoch 106/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 0.1177 - val_accuracy: 0.9572\n",
      "Epoch 107/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.98 - 1s 77us/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.1182 - val_accuracy: 0.9589\n",
      "Epoch 108/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.1175 - val_accuracy: 0.9579\n",
      "Epoch 109/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0477 - accuracy: 0.9841 - val_loss: 0.1210 - val_accuracy: 0.9579\n",
      "Epoch 110/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 0.1305 - val_accuracy: 0.9542\n",
      "Epoch 111/1000\n",
      "7352/7352 [==============================] - 0s 68us/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.1218 - val_accuracy: 0.9559\n",
      "Epoch 112/1000\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.1170 - val_accuracy: 0.9586\n",
      "Epoch 113/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0499 - accuracy: 0.9833 - val_loss: 0.1402 - val_accuracy: 0.9532\n",
      "Epoch 114/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.1237 - val_accuracy: 0.9559\n",
      "Epoch 115/1000\n",
      "7352/7352 [==============================] - 0s 68us/step - loss: 0.0383 - accuracy: 0.9876 - val_loss: 0.1971 - val_accuracy: 0.9270\n",
      "Epoch 116/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.3863 - val_accuracy: 0.8792\n",
      "Epoch 117/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 0.1633 - val_accuracy: 0.9413\n",
      "Epoch 118/1000\n",
      "7352/7352 [==============================] - 0s 66us/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.1223 - val_accuracy: 0.9583\n",
      "Epoch 119/1000\n",
      "7352/7352 [==============================] - 0s 67us/step - loss: 0.0513 - accuracy: 0.9814 - val_loss: 0.1159 - val_accuracy: 0.9606\n",
      "Epoch 120/1000\n",
      "7352/7352 [==============================] - 1s 69us/step - loss: 0.0456 - accuracy: 0.9834 - val_loss: 0.1169 - val_accuracy: 0.9579\n",
      "Epoch 121/1000\n",
      "7352/7352 [==============================] - 0s 66us/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.1191 - val_accuracy: 0.9569\n",
      "Epoch 122/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0387 - accuracy: 0.9869 - val_loss: 0.1279 - val_accuracy: 0.9535\n",
      "Epoch 123/1000\n",
      "7352/7352 [==============================] - 1s 73us/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.1616 - val_accuracy: 0.9396\n",
      "Epoch 124/1000\n",
      "7352/7352 [==============================] - 1s 68us/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 0.1208 - val_accuracy: 0.9572\n",
      "Epoch 125/1000\n",
      "7352/7352 [==============================] - 1s 69us/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.4676 - val_accuracy: 0.8660\n",
      "Epoch 126/1000\n",
      "7352/7352 [==============================] - 1s 73us/step - loss: 0.0525 - accuracy: 0.9807 - val_loss: 0.1178 - val_accuracy: 0.9603\n",
      "Epoch 127/1000\n",
      "7352/7352 [==============================] - 1s 74us/step - loss: 0.0376 - accuracy: 0.9875 - val_loss: 0.1196 - val_accuracy: 0.9572\n",
      "Epoch 128/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.1162 - val_accuracy: 0.9600\n",
      "Epoch 129/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 0.1182 - val_accuracy: 0.9583\n",
      "Epoch 130/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0444 - accuracy: 0.9842 - val_loss: 0.1909 - val_accuracy: 0.9294\n",
      "Epoch 131/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0379 - accuracy: 0.9869 - val_loss: 0.1222 - val_accuracy: 0.9569\n",
      "Epoch 132/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.1386 - val_accuracy: 0.9488\n",
      "Epoch 133/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.1269 - val_accuracy: 0.9566\n",
      "Epoch 134/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0369 - accuracy: 0.9872 - val_loss: 0.1213 - val_accuracy: 0.9579\n",
      "Epoch 135/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0435 - accuracy: 0.9860 - val_loss: 0.1153 - val_accuracy: 0.9610\n",
      "Epoch 136/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.1236 - val_accuracy: 0.9586\n",
      "Epoch 137/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.1180 - val_accuracy: 0.9596\n",
      "Epoch 138/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.1555 - val_accuracy: 0.9440\n",
      "Epoch 139/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.1322 - val_accuracy: 0.9559\n",
      "Epoch 140/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0332 - accuracy: 0.9890 - val_loss: 0.1485 - val_accuracy: 0.9498\n",
      "Epoch 141/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0390 - accuracy: 0.9880 - val_loss: 0.1268 - val_accuracy: 0.9569\n",
      "Epoch 142/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.1208 - val_accuracy: 0.9579\n",
      "Epoch 143/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.1240 - val_accuracy: 0.9569\n",
      "Epoch 144/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.1367 - val_accuracy: 0.9528\n",
      "Epoch 145/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.2027 - val_accuracy: 0.9270\n",
      "Epoch 146/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0666 - accuracy: 0.9786 - val_loss: 0.1223 - val_accuracy: 0.9576\n",
      "Epoch 147/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.1238 - val_accuracy: 0.9559\n",
      "Epoch 148/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0369 - accuracy: 0.9880 - val_loss: 0.1559 - val_accuracy: 0.9444\n",
      "Epoch 149/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 0.1785 - val_accuracy: 0.9338\n",
      "Epoch 150/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0381 - accuracy: 0.9875 - val_loss: 0.1477 - val_accuracy: 0.9494\n",
      "Epoch 151/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.1224 - val_accuracy: 0.9576\n",
      "Epoch 152/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.1204 - val_accuracy: 0.9583\n",
      "Epoch 153/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.1440 - val_accuracy: 0.9511\n",
      "Epoch 154/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0448 - accuracy: 0.9842 - val_loss: 0.1660 - val_accuracy: 0.9325\n",
      "Epoch 155/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0783 - accuracy: 0.9754 - val_loss: 0.1140 - val_accuracy: 0.9596\n",
      "Epoch 156/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0334 - accuracy: 0.9891 - val_loss: 0.1262 - val_accuracy: 0.9572\n",
      "Epoch 157/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0375 - accuracy: 0.9869 - val_loss: 0.1197 - val_accuracy: 0.9569\n",
      "Epoch 158/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 0.1608 - val_accuracy: 0.9444\n",
      "Epoch 159/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.1331 - val_accuracy: 0.9515\n",
      "Epoch 160/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.1265 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0320 - accuracy: 0.9898 - val_loss: 0.1190 - val_accuracy: 0.9562\n",
      "Epoch 162/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.1688 - val_accuracy: 0.9410\n",
      "Epoch 163/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.1236 - val_accuracy: 0.9589\n",
      "Epoch 164/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.1308 - val_accuracy: 0.9545\n",
      "Epoch 165/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.1204 - val_accuracy: 0.9572\n",
      "Epoch 166/1000\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0565 - accuracy: 0.9819 - val_loss: 0.1150 - val_accuracy: 0.9586\n",
      "Epoch 167/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0296 - accuracy: 0.9924 - val_loss: 0.1202 - val_accuracy: 0.9569\n",
      "Epoch 168/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.1193 - val_accuracy: 0.9572\n",
      "Epoch 169/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.1358 - val_accuracy: 0.9535\n",
      "Epoch 170/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.1195 - val_accuracy: 0.9579\n",
      "Epoch 171/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.1621 - val_accuracy: 0.9440\n",
      "Epoch 172/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 0.1193 - val_accuracy: 0.9569\n",
      "Epoch 173/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.4467 - val_accuracy: 0.8755\n",
      "Epoch 174/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.1237 - val_accuracy: 0.9566\n",
      "Epoch 175/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.1178 - val_accuracy: 0.9596\n",
      "Epoch 176/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.1179 - val_accuracy: 0.9593\n",
      "Epoch 177/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.1241 - val_accuracy: 0.9579\n",
      "Epoch 178/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.1171 - val_accuracy: 0.9600\n",
      "Epoch 179/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.1207 - val_accuracy: 0.9566\n",
      "Epoch 180/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.1256 - val_accuracy: 0.9566\n",
      "Epoch 181/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.1186 - val_accuracy: 0.9586\n",
      "Epoch 182/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.1452 - val_accuracy: 0.9525\n",
      "Epoch 183/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.1528 - val_accuracy: 0.9501\n",
      "Epoch 184/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.3762 - val_accuracy: 0.8880\n",
      "Epoch 185/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.1216 - val_accuracy: 0.9589\n",
      "Epoch 186/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.1789 - val_accuracy: 0.9372\n",
      "Epoch 187/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0347 - accuracy: 0.9875 - val_loss: 0.1451 - val_accuracy: 0.9525\n",
      "Epoch 188/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.1191 - val_accuracy: 0.9572\n",
      "Epoch 189/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.1305 - val_accuracy: 0.9542\n",
      "Epoch 190/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0477 - accuracy: 0.9846 - val_loss: 0.1164 - val_accuracy: 0.9583\n",
      "Epoch 191/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.1381 - val_accuracy: 0.9539\n",
      "Epoch 192/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.1576 - val_accuracy: 0.9467\n",
      "Epoch 193/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 0.1178 - val_accuracy: 0.9600\n",
      "Epoch 194/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.1161 - val_accuracy: 0.9579\n",
      "Epoch 195/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.1900 - val_accuracy: 0.9325\n",
      "Epoch 196/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.1253 - val_accuracy: 0.9586\n",
      "Epoch 197/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.1867 - val_accuracy: 0.9355\n",
      "Epoch 198/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.1364 - val_accuracy: 0.9549\n",
      "Epoch 199/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.1148 - val_accuracy: 0.9603\n",
      "Epoch 200/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.1512 - val_accuracy: 0.9508\n",
      "Epoch 201/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.1231 - val_accuracy: 0.9583\n",
      "Epoch 202/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 0.1309 - val_accuracy: 0.9569\n",
      "Epoch 203/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.1169 - val_accuracy: 0.9589\n",
      "Epoch 204/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.1457 - val_accuracy: 0.9528\n",
      "Epoch 205/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.1174 - val_accuracy: 0.9593\n",
      "Epoch 206/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.1286 - val_accuracy: 0.9572\n",
      "Epoch 207/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.1173 - val_accuracy: 0.9579\n",
      "Epoch 208/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.1418 - val_accuracy: 0.9528\n",
      "Epoch 209/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0602 - accuracy: 0.9838 - val_loss: 0.1159 - val_accuracy: 0.9610\n",
      "Epoch 210/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 0.1180 - val_accuracy: 0.9586\n",
      "Epoch 211/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.1485 - val_accuracy: 0.9515\n",
      "Epoch 212/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.1271 - val_accuracy: 0.9586\n",
      "Epoch 213/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.1284 - val_accuracy: 0.9569\n",
      "Epoch 214/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.1492 - val_accuracy: 0.9511\n",
      "Epoch 215/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.1969 - val_accuracy: 0.9311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0563 - accuracy: 0.9818 - val_loss: 0.1188 - val_accuracy: 0.9579\n",
      "Epoch 217/1000\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.1875 - val_accuracy: 0.9345\n",
      "Epoch 218/1000\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0387 - accuracy: 0.9861 - val_loss: 0.1425 - val_accuracy: 0.9525\n",
      "Epoch 219/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.1249 - val_accuracy: 0.9572\n",
      "Epoch 220/1000\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.1186 - val_accuracy: 0.9579\n",
      "Epoch 221/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.1496 - val_accuracy: 0.9440\n",
      "Epoch 222/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.1333 - val_accuracy: 0.9559\n",
      "Epoch 223/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.1912 - val_accuracy: 0.9335\n",
      "Epoch 224/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.1317 - val_accuracy: 0.9569\n",
      "Epoch 225/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.1278 - val_accuracy: 0.9579\n",
      "Epoch 226/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.1190 - val_accuracy: 0.9606\n",
      "Epoch 227/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.2022 - val_accuracy: 0.9315\n",
      "Epoch 228/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.1821 - val_accuracy: 0.9304\n",
      "Epoch 229/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 0.1330 - val_accuracy: 0.9569\n",
      "Epoch 230/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.1542 - val_accuracy: 0.9511\n",
      "Epoch 231/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 0.1219 - val_accuracy: 0.9572\n",
      "Epoch 232/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.1295 - val_accuracy: 0.9579\n",
      "Epoch 233/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.1665 - val_accuracy: 0.9457\n",
      "Epoch 234/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.1290 - val_accuracy: 0.9552\n",
      "Epoch 235/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0581 - accuracy: 0.9789 - val_loss: 0.1309 - val_accuracy: 0.9562\n",
      "Epoch 236/1000\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.2433 - val_accuracy: 0.9172\n",
      "Epoch 237/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.1257 - val_accuracy: 0.9589\n",
      "Epoch 238/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0238 - accuracy: 0.9935 - val_loss: 0.1185 - val_accuracy: 0.9596\n",
      "Epoch 239/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.1202 - val_accuracy: 0.9586\n",
      "Epoch 240/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.1170 - val_accuracy: 0.9596\n",
      "Epoch 241/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.1514 - val_accuracy: 0.9450\n",
      "Epoch 242/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.1624 - val_accuracy: 0.9474\n",
      "Epoch 243/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.1548 - val_accuracy: 0.9498\n",
      "Epoch 244/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.1382 - val_accuracy: 0.9555\n",
      "Epoch 245/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.1171 - val_accuracy: 0.9603\n",
      "Epoch 246/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.1182 - val_accuracy: 0.9600\n",
      "Epoch 247/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.1201 - val_accuracy: 0.9596\n",
      "Epoch 248/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.1291 - val_accuracy: 0.9576\n",
      "Epoch 249/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.1206 - val_accuracy: 0.9603\n",
      "Epoch 250/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.2831 - val_accuracy: 0.9111\n",
      "Epoch 251/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.1238 - val_accuracy: 0.9589\n",
      "Epoch 252/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.1213 - val_accuracy: 0.9593\n",
      "Epoch 253/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.1458 - val_accuracy: 0.9559\n",
      "Epoch 254/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.1326 - val_accuracy: 0.9569\n",
      "Epoch 255/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1195 - val_accuracy: 0.9596\n",
      "Epoch 256/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.1264 - val_accuracy: 0.9593\n",
      "Epoch 257/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.1407 - val_accuracy: 0.9545\n",
      "Epoch 258/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0200 - accuracy: 0.9944 - val_loss: 0.1188 - val_accuracy: 0.9593\n",
      "Epoch 259/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.1346 - val_accuracy: 0.9569\n",
      "Epoch 260/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.1193 - val_accuracy: 0.9586\n",
      "Epoch 261/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1749 - val_accuracy: 0.9423\n",
      "Epoch 262/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.1306 - val_accuracy: 0.9583\n",
      "Epoch 263/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.1198 - val_accuracy: 0.9603\n",
      "Epoch 264/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.3912 - val_accuracy: 0.8928\n",
      "Epoch 265/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.2196 - val_accuracy: 0.9284\n",
      "Epoch 266/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1510 - val_accuracy: 0.9518\n",
      "Epoch 267/1000\n",
      "7352/7352 [==============================] - 1s 71us/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.1395 - val_accuracy: 0.9555\n",
      "Epoch 268/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1210 - val_accuracy: 0.9600\n",
      "Epoch 269/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.1310 - val_accuracy: 0.9569\n",
      "Epoch 270/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.1167 - val_accuracy: 0.9617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.1339 - val_accuracy: 0.9562\n",
      "Epoch 272/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.1180 - val_accuracy: 0.9613\n",
      "Epoch 273/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.1513 - val_accuracy: 0.9528\n",
      "Epoch 274/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.1386 - val_accuracy: 0.9545\n",
      "Epoch 275/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.1264 - val_accuracy: 0.9572\n",
      "Epoch 276/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1890 - val_accuracy: 0.9386\n",
      "Epoch 277/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.1564 - val_accuracy: 0.9501\n",
      "Epoch 278/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.1370 - val_accuracy: 0.9559\n",
      "Epoch 279/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.1433 - val_accuracy: 0.9549\n",
      "Epoch 280/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.1347 - val_accuracy: 0.9576\n",
      "Epoch 281/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.1316 - val_accuracy: 0.9583\n",
      "Epoch 282/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 0.1207 - val_accuracy: 0.9600\n",
      "Epoch 283/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.1197 - val_accuracy: 0.9610\n",
      "Epoch 284/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.1194 - val_accuracy: 0.9613\n",
      "Epoch 285/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.1438 - val_accuracy: 0.9542\n",
      "Epoch 286/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.1193 - val_accuracy: 0.9603\n",
      "Epoch 287/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.1540 - val_accuracy: 0.9532\n",
      "Epoch 288/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1204 - val_accuracy: 0.9603\n",
      "Epoch 289/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.1205 - val_accuracy: 0.9606\n",
      "Epoch 290/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.1245 - val_accuracy: 0.9589\n",
      "Epoch 291/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1190 - val_accuracy: 0.9617\n",
      "Epoch 292/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.1927 - val_accuracy: 0.9352\n",
      "Epoch 293/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.1203 - val_accuracy: 0.9610\n",
      "Epoch 294/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.1788 - val_accuracy: 0.9427\n",
      "Epoch 295/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.1359 - val_accuracy: 0.9566\n",
      "Epoch 296/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.1437 - val_accuracy: 0.9542\n",
      "Epoch 297/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0507 - accuracy: 0.9860 - val_loss: 0.1350 - val_accuracy: 0.9559\n",
      "Epoch 298/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.1198 - val_accuracy: 0.9596\n",
      "Epoch 299/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.1297 - val_accuracy: 0.9572\n",
      "Epoch 300/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.1413 - val_accuracy: 0.9542\n",
      "Epoch 301/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.1266 - val_accuracy: 0.9586\n",
      "Epoch 302/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.1663 - val_accuracy: 0.9488\n",
      "Epoch 303/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.1405 - val_accuracy: 0.9562\n",
      "Epoch 304/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.1464 - val_accuracy: 0.9549\n",
      "Epoch 305/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.1532 - val_accuracy: 0.9532\n",
      "Epoch 306/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.1356 - val_accuracy: 0.9562\n",
      "Epoch 307/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.1687 - val_accuracy: 0.9464\n",
      "Epoch 308/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.1324 - val_accuracy: 0.9566\n",
      "Epoch 309/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.1199 - val_accuracy: 0.9606\n",
      "Epoch 310/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.1466 - val_accuracy: 0.9552\n",
      "Epoch 311/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.1316 - val_accuracy: 0.9579\n",
      "Epoch 312/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.1272 - val_accuracy: 0.9583\n",
      "Epoch 313/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.1251 - val_accuracy: 0.9589\n",
      "Epoch 314/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.1355 - val_accuracy: 0.9586\n",
      "Epoch 315/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.1322 - val_accuracy: 0.9579\n",
      "Epoch 316/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.1191 - val_accuracy: 0.9603\n",
      "Epoch 317/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.1260 - val_accuracy: 0.9579\n",
      "Epoch 318/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.1374 - val_accuracy: 0.9576\n",
      "Epoch 319/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.1553 - val_accuracy: 0.9535\n",
      "Epoch 320/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.1216 - val_accuracy: 0.9600\n",
      "Epoch 321/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.1420 - val_accuracy: 0.9542\n",
      "Epoch 322/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0185 - accuracy: 0.9931 - val_loss: 0.1371 - val_accuracy: 0.9583\n",
      "Epoch 323/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0149 - accuracy: 0.9967 - val_loss: 0.1581 - val_accuracy: 0.9525\n",
      "Epoch 324/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.1324 - val_accuracy: 0.9579\n",
      "Epoch 325/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.1560 - val_accuracy: 0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.1238 - val_accuracy: 0.9603\n",
      "Epoch 327/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1730 - val_accuracy: 0.9464\n",
      "Epoch 328/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.1358 - val_accuracy: 0.9576\n",
      "Epoch 329/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.1192 - val_accuracy: 0.9603\n",
      "Epoch 330/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.1326 - val_accuracy: 0.9572\n",
      "Epoch 331/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.1828 - val_accuracy: 0.9427\n",
      "Epoch 332/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.1429 - val_accuracy: 0.9559\n",
      "Epoch 333/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.1296 - val_accuracy: 0.9589\n",
      "Epoch 334/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.1371 - val_accuracy: 0.9576\n",
      "Epoch 335/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1247 - val_accuracy: 0.9589\n",
      "Epoch 336/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.1303 - val_accuracy: 0.9576\n",
      "Epoch 337/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.1285 - val_accuracy: 0.9593\n",
      "Epoch 338/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.1571 - val_accuracy: 0.9515\n",
      "Epoch 339/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.1216 - val_accuracy: 0.9613\n",
      "Epoch 340/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.1742 - val_accuracy: 0.9457\n",
      "Epoch 341/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.1831 - val_accuracy: 0.9427\n",
      "Epoch 342/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.1855 - val_accuracy: 0.9437\n",
      "Epoch 343/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.1698 - val_accuracy: 0.9484\n",
      "Epoch 344/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.1360 - val_accuracy: 0.9579\n",
      "Epoch 345/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.1199 - val_accuracy: 0.9617\n",
      "Epoch 346/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 0.1325 - val_accuracy: 0.9583\n",
      "Epoch 347/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.1295 - val_accuracy: 0.9572\n",
      "Epoch 348/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.1230 - val_accuracy: 0.9617\n",
      "Epoch 349/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.2317 - val_accuracy: 0.9172\n",
      "Epoch 350/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.98 - 1s 84us/step - loss: 0.0705 - accuracy: 0.9833 - val_loss: 0.1177 - val_accuracy: 0.9593\n",
      "Epoch 351/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.1245 - val_accuracy: 0.9589\n",
      "Epoch 352/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.1318 - val_accuracy: 0.9583\n",
      "Epoch 353/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.1374 - val_accuracy: 0.9569\n",
      "Epoch 354/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.1316 - val_accuracy: 0.9589\n",
      "Epoch 355/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.1225 - val_accuracy: 0.9620\n",
      "Epoch 356/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.1294 - val_accuracy: 0.9600\n",
      "Epoch 357/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.1309 - val_accuracy: 0.9579\n",
      "Epoch 358/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.1304 - val_accuracy: 0.9579\n",
      "Epoch 359/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.1232 - val_accuracy: 0.9620\n",
      "Epoch 360/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.1219 - val_accuracy: 0.9606\n",
      "Epoch 361/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1287 - val_accuracy: 0.9589\n",
      "Epoch 362/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.1526 - val_accuracy: 0.9525\n",
      "Epoch 363/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.1464 - val_accuracy: 0.9539\n",
      "Epoch 364/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.1232 - val_accuracy: 0.9613\n",
      "Epoch 365/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.2313 - val_accuracy: 0.9294\n",
      "Epoch 366/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.1265 - val_accuracy: 0.9589\n",
      "Epoch 367/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 0.1300 - val_accuracy: 0.9586\n",
      "Epoch 368/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.1433 - val_accuracy: 0.9539\n",
      "Epoch 369/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.1298 - val_accuracy: 0.9586\n",
      "Epoch 370/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.1320 - val_accuracy: 0.9586\n",
      "Epoch 371/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 372/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.1837 - val_accuracy: 0.9447\n",
      "Epoch 373/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.1541 - val_accuracy: 0.9532\n",
      "Epoch 374/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.1308 - val_accuracy: 0.9569\n",
      "Epoch 375/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1387 - val_accuracy: 0.9549\n",
      "Epoch 376/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.1376 - val_accuracy: 0.9562\n",
      "Epoch 377/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.1413 - val_accuracy: 0.9559\n",
      "Epoch 378/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.1240 - val_accuracy: 0.9600\n",
      "Epoch 379/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.1199 - val_accuracy: 0.9613\n",
      "Epoch 380/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.1297 - val_accuracy: 0.9579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.1409 - val_accuracy: 0.9555\n",
      "Epoch 382/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.1288 - val_accuracy: 0.9593\n",
      "Epoch 383/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.1425 - val_accuracy: 0.9559\n",
      "Epoch 384/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.1701 - val_accuracy: 0.9494\n",
      "Epoch 385/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.1415 - val_accuracy: 0.9549\n",
      "Epoch 386/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.1338 - val_accuracy: 0.9579\n",
      "Epoch 387/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.1246 - val_accuracy: 0.9600\n",
      "Epoch 388/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.1212 - val_accuracy: 0.9603\n",
      "Epoch 389/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.1277 - val_accuracy: 0.9579\n",
      "Epoch 390/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.1593 - val_accuracy: 0.9518\n",
      "Epoch 391/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.1281 - val_accuracy: 0.9596\n",
      "Epoch 392/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.1460 - val_accuracy: 0.9549\n",
      "Epoch 393/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.1258 - val_accuracy: 0.9600\n",
      "Epoch 394/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.1424 - val_accuracy: 0.9545\n",
      "Epoch 395/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.1184 - val_accuracy: 0.9644\n",
      "Epoch 396/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.1410 - val_accuracy: 0.9549\n",
      "Epoch 397/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.1531 - val_accuracy: 0.9532\n",
      "Epoch 398/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.1243 - val_accuracy: 0.9610\n",
      "Epoch 399/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1312 - val_accuracy: 0.9583\n",
      "Epoch 400/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.1358 - val_accuracy: 0.9583\n",
      "Epoch 401/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.1327 - val_accuracy: 0.9562\n",
      "Epoch 402/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.2484 - val_accuracy: 0.9267\n",
      "Epoch 403/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1284 - val_accuracy: 0.9596\n",
      "Epoch 404/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.1300 - val_accuracy: 0.9613\n",
      "Epoch 405/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.1333 - val_accuracy: 0.9593\n",
      "Epoch 406/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1225 - val_accuracy: 0.9637\n",
      "Epoch 407/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.99 - 1s 86us/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.1466 - val_accuracy: 0.9562\n",
      "Epoch 408/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.1761 - val_accuracy: 0.9474\n",
      "Epoch 409/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 0.1578 - val_accuracy: 0.9522\n",
      "Epoch 410/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.1248 - val_accuracy: 0.9613\n",
      "Epoch 411/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.1385 - val_accuracy: 0.9572\n",
      "Epoch 412/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.1285 - val_accuracy: 0.9600\n",
      "Epoch 413/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1392 - val_accuracy: 0.9572\n",
      "Epoch 414/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.1261 - val_accuracy: 0.9610\n",
      "Epoch 415/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.1452 - val_accuracy: 0.9552\n",
      "Epoch 416/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.1309 - val_accuracy: 0.9589\n",
      "Epoch 417/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.1310 - val_accuracy: 0.9596\n",
      "Epoch 418/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.1265 - val_accuracy: 0.9610\n",
      "Epoch 419/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.1538 - val_accuracy: 0.9535\n",
      "Epoch 420/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.1415 - val_accuracy: 0.9562\n",
      "Epoch 421/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.1303 - val_accuracy: 0.9600\n",
      "Epoch 422/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.1556 - val_accuracy: 0.9528\n",
      "Epoch 423/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.1486 - val_accuracy: 0.9545\n",
      "Epoch 424/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.1392 - val_accuracy: 0.9576\n",
      "Epoch 425/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1649 - val_accuracy: 0.9501\n",
      "Epoch 426/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.1602 - val_accuracy: 0.9511\n",
      "Epoch 427/1000\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.1401 - val_accuracy: 0.9572\n",
      "Epoch 428/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.1319 - val_accuracy: 0.9593\n",
      "Epoch 429/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1241 - val_accuracy: 0.9623\n",
      "Epoch 430/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.1239 - val_accuracy: 0.9617\n",
      "Epoch 431/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.1502 - val_accuracy: 0.9559\n",
      "Epoch 432/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.1299 - val_accuracy: 0.9613\n",
      "Epoch 433/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0092 - accuracy: 0.9986 - val_loss: 0.1309 - val_accuracy: 0.9596\n",
      "Epoch 434/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.1358 - val_accuracy: 0.9579\n",
      "Epoch 435/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.1273 - val_accuracy: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.1422 - val_accuracy: 0.9559\n",
      "Epoch 437/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.1252 - val_accuracy: 0.9613\n",
      "Epoch 438/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.1324 - val_accuracy: 0.9603\n",
      "Epoch 439/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.1232 - val_accuracy: 0.9623\n",
      "Epoch 440/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.1450 - val_accuracy: 0.9569\n",
      "Epoch 441/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.1438 - val_accuracy: 0.9562\n",
      "Epoch 442/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.1267 - val_accuracy: 0.9613\n",
      "Epoch 443/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.1519 - val_accuracy: 0.9555\n",
      "Epoch 444/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.1685 - val_accuracy: 0.9501\n",
      "Epoch 445/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.1337 - val_accuracy: 0.9589\n",
      "Epoch 446/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.1599 - val_accuracy: 0.9515\n",
      "Epoch 447/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.1304 - val_accuracy: 0.9610\n",
      "Epoch 448/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.1530 - val_accuracy: 0.9559\n",
      "Epoch 449/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.1675 - val_accuracy: 0.9501\n",
      "Epoch 450/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.1418 - val_accuracy: 0.9562\n",
      "Epoch 451/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.1300 - val_accuracy: 0.9610\n",
      "Epoch 452/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.1610 - val_accuracy: 0.9518\n",
      "Epoch 453/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 0.1312 - val_accuracy: 0.9593\n",
      "Epoch 454/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.1416 - val_accuracy: 0.9559\n",
      "Epoch 455/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.1210 - val_accuracy: 0.9637\n",
      "Epoch 456/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.1309 - val_accuracy: 0.9593\n",
      "Epoch 457/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.1865 - val_accuracy: 0.9460\n",
      "Epoch 458/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.1652 - val_accuracy: 0.9501\n",
      "Epoch 459/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0647 - accuracy: 0.9878 - val_loss: 0.1095 - val_accuracy: 0.9606\n",
      "Epoch 460/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1379 - val_accuracy: 0.9552\n",
      "Epoch 461/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.1450 - val_accuracy: 0.9549\n",
      "Epoch 462/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0084 - accuracy: 0.9989 - val_loss: 0.1464 - val_accuracy: 0.9559\n",
      "Epoch 463/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.1397 - val_accuracy: 0.9576\n",
      "Epoch 464/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.1309 - val_accuracy: 0.9593\n",
      "Epoch 465/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.1384 - val_accuracy: 0.9589\n",
      "Epoch 466/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.1432 - val_accuracy: 0.9562\n",
      "Epoch 467/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.1419 - val_accuracy: 0.9572\n",
      "Epoch 468/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.1342 - val_accuracy: 0.9603\n",
      "Epoch 469/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.1554 - val_accuracy: 0.9542\n",
      "Epoch 470/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.2058 - val_accuracy: 0.9403\n",
      "Epoch 471/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.1223 - val_accuracy: 0.9627\n",
      "Epoch 472/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.1376 - val_accuracy: 0.9596\n",
      "Epoch 473/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.1247 - val_accuracy: 0.9627\n",
      "Epoch 474/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1327 - val_accuracy: 0.9600\n",
      "Epoch 475/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.1393 - val_accuracy: 0.9576\n",
      "Epoch 476/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.1542 - val_accuracy: 0.9559\n",
      "Epoch 477/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.1402 - val_accuracy: 0.9576\n",
      "Epoch 478/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.1517 - val_accuracy: 0.9562\n",
      "Epoch 479/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.1395 - val_accuracy: 0.9576\n",
      "Epoch 480/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.1332 - val_accuracy: 0.9603\n",
      "Epoch 481/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.1379 - val_accuracy: 0.9583\n",
      "Epoch 482/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1411 - val_accuracy: 0.9572\n",
      "Epoch 483/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.1444 - val_accuracy: 0.9566\n",
      "Epoch 484/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.1380 - val_accuracy: 0.9593\n",
      "Epoch 485/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.1933 - val_accuracy: 0.9454\n",
      "Epoch 486/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.1372 - val_accuracy: 0.9603\n",
      "Epoch 487/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1524 - val_accuracy: 0.9559\n",
      "Epoch 488/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.2034 - val_accuracy: 0.9433\n",
      "Epoch 489/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.1330 - val_accuracy: 0.9596\n",
      "Epoch 490/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1818 - val_accuracy: 0.9477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.1276 - val_accuracy: 0.9617\n",
      "Epoch 492/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.1443 - val_accuracy: 0.9566\n",
      "Epoch 493/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.1458 - val_accuracy: 0.9569\n",
      "Epoch 494/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.1767 - val_accuracy: 0.9491\n",
      "Epoch 495/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1364 - val_accuracy: 0.9596\n",
      "Epoch 496/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.1408 - val_accuracy: 0.9576\n",
      "Epoch 497/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.1409 - val_accuracy: 0.9569\n",
      "Epoch 498/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1284 - val_accuracy: 0.9606\n",
      "Epoch 499/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1503 - val_accuracy: 0.9555\n",
      "Epoch 500/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.1407 - val_accuracy: 0.9583\n",
      "Epoch 501/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.1351 - val_accuracy: 0.9600\n",
      "Epoch 502/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1307 - val_accuracy: 0.9610\n",
      "Epoch 503/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.1391 - val_accuracy: 0.9589\n",
      "Epoch 504/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.1454 - val_accuracy: 0.9562\n",
      "Epoch 505/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.1478 - val_accuracy: 0.9566\n",
      "Epoch 506/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.1824 - val_accuracy: 0.9494\n",
      "Epoch 507/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1406 - val_accuracy: 0.9579\n",
      "Epoch 508/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.1609 - val_accuracy: 0.9528\n",
      "Epoch 509/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.1517 - val_accuracy: 0.9555\n",
      "Epoch 510/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.1421 - val_accuracy: 0.9572\n",
      "Epoch 511/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0069 - accuracy: 0.9990 - val_loss: 0.1489 - val_accuracy: 0.9566\n",
      "Epoch 512/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.1424 - val_accuracy: 0.9579\n",
      "Epoch 513/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.1762 - val_accuracy: 0.9498\n",
      "Epoch 514/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.1586 - val_accuracy: 0.9518\n",
      "Epoch 515/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.1451 - val_accuracy: 0.9566\n",
      "Epoch 516/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.1464 - val_accuracy: 0.9566\n",
      "Epoch 517/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.1419 - val_accuracy: 0.9586\n",
      "Epoch 518/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.1435 - val_accuracy: 0.9579\n",
      "Epoch 519/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.1284 - val_accuracy: 0.9613\n",
      "Epoch 520/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 0.1411 - val_accuracy: 0.9589\n",
      "Epoch 521/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.1919 - val_accuracy: 0.9464\n",
      "Epoch 522/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 0.1278 - val_accuracy: 0.9617\n",
      "Epoch 523/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.1350 - val_accuracy: 0.9596\n",
      "Epoch 524/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.1853 - val_accuracy: 0.9467\n",
      "Epoch 525/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.1606 - val_accuracy: 0.9528\n",
      "Epoch 526/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.1391 - val_accuracy: 0.9593\n",
      "Epoch 527/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0060 - accuracy: 0.9993 - val_loss: 0.1603 - val_accuracy: 0.9528\n",
      "Epoch 528/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.1371 - val_accuracy: 0.9603\n",
      "Epoch 529/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.1506 - val_accuracy: 0.9555\n",
      "Epoch 530/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 0.1889 - val_accuracy: 0.9484\n",
      "Epoch 531/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.1322 - val_accuracy: 0.9613\n",
      "Epoch 532/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.1493 - val_accuracy: 0.9569\n",
      "Epoch 533/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.1428 - val_accuracy: 0.9576\n",
      "Epoch 534/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1477 - val_accuracy: 0.9562\n",
      "Epoch 535/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.1383 - val_accuracy: 0.9596\n",
      "Epoch 536/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.1510 - val_accuracy: 0.9552\n",
      "Epoch 537/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.1456 - val_accuracy: 0.9576\n",
      "Epoch 538/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.1397 - val_accuracy: 0.9600\n",
      "Epoch 539/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.1615 - val_accuracy: 0.9542\n",
      "Epoch 540/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.1358 - val_accuracy: 0.9603\n",
      "Epoch 541/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.1360 - val_accuracy: 0.9606\n",
      "Epoch 542/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.1334 - val_accuracy: 0.9610\n",
      "Epoch 543/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1487 - val_accuracy: 0.9576\n",
      "Epoch 544/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.1335 - val_accuracy: 0.9603\n",
      "Epoch 545/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.1363 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.1630 - val_accuracy: 0.9532\n",
      "Epoch 547/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.1513 - val_accuracy: 0.9555\n",
      "Epoch 548/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.1314 - val_accuracy: 0.9610\n",
      "Epoch 549/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 0.1514 - val_accuracy: 0.9562\n",
      "Epoch 550/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.1413 - val_accuracy: 0.9583\n",
      "Epoch 551/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.2617 - val_accuracy: 0.9301\n",
      "Epoch 552/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0992 - accuracy: 0.9845 - val_loss: 0.1390 - val_accuracy: 0.9569\n",
      "Epoch 553/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.1357 - val_accuracy: 0.9596\n",
      "Epoch 554/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.1701 - val_accuracy: 0.9515\n",
      "Epoch 555/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1565 - val_accuracy: 0.9552\n",
      "Epoch 556/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.1420 - val_accuracy: 0.9589\n",
      "Epoch 557/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0055 - accuracy: 0.9995 - val_loss: 0.1267 - val_accuracy: 0.9630\n",
      "Epoch 558/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.1499 - val_accuracy: 0.9569\n",
      "Epoch 559/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.1388 - val_accuracy: 0.9596\n",
      "Epoch 560/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.1328 - val_accuracy: 0.9617\n",
      "Epoch 561/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.1453 - val_accuracy: 0.9569\n",
      "Epoch 562/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.1351 - val_accuracy: 0.9606\n",
      "Epoch 563/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.1317 - val_accuracy: 0.9620\n",
      "Epoch 564/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.1391 - val_accuracy: 0.9606\n",
      "Epoch 565/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.1469 - val_accuracy: 0.9579\n",
      "Epoch 566/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.1425 - val_accuracy: 0.9593\n",
      "Epoch 567/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.1543 - val_accuracy: 0.9555\n",
      "Epoch 568/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.1424 - val_accuracy: 0.9589\n",
      "Epoch 569/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.1407 - val_accuracy: 0.9589\n",
      "Epoch 570/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.1380 - val_accuracy: 0.9603\n",
      "Epoch 571/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.1396 - val_accuracy: 0.9606\n",
      "Epoch 572/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.1358 - val_accuracy: 0.9603\n",
      "Epoch 573/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1362 - val_accuracy: 0.9610\n",
      "Epoch 574/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.1520 - val_accuracy: 0.9552\n",
      "Epoch 575/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.1424 - val_accuracy: 0.9610\n",
      "Epoch 576/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.1303 - val_accuracy: 0.9620\n",
      "Epoch 577/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9603\n",
      "Epoch 578/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9610\n",
      "Epoch 579/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.1636 - val_accuracy: 0.9532\n",
      "Epoch 580/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.1359 - val_accuracy: 0.9610\n",
      "Epoch 581/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1503 - val_accuracy: 0.9569\n",
      "Epoch 582/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.1409 - val_accuracy: 0.9600\n",
      "Epoch 583/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.1445 - val_accuracy: 0.9589\n",
      "Epoch 584/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.2344 - val_accuracy: 0.9362\n",
      "Epoch 585/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.1353 - val_accuracy: 0.9603\n",
      "Epoch 586/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.1447 - val_accuracy: 0.9589\n",
      "Epoch 587/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.1413 - val_accuracy: 0.9596\n",
      "Epoch 588/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.1397 - val_accuracy: 0.9606\n",
      "Epoch 589/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.1603 - val_accuracy: 0.9552\n",
      "Epoch 590/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.1534 - val_accuracy: 0.9559\n",
      "Epoch 591/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.1476 - val_accuracy: 0.9583\n",
      "Epoch 592/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.1417 - val_accuracy: 0.9603\n",
      "Epoch 593/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.2387 - val_accuracy: 0.9359\n",
      "Epoch 594/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.1637 - val_accuracy: 0.9549\n",
      "Epoch 595/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.1500 - val_accuracy: 0.9572\n",
      "Epoch 596/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9586\n",
      "Epoch 597/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1492 - val_accuracy: 0.9569\n",
      "Epoch 598/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.1546 - val_accuracy: 0.9562\n",
      "Epoch 599/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9600\n",
      "Epoch 600/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.1620 - val_accuracy: 0.9549\n",
      "Epoch 602/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.1628 - val_accuracy: 0.9545\n",
      "Epoch 603/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1633 - val_accuracy: 0.9549\n",
      "Epoch 604/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.1475 - val_accuracy: 0.9583\n",
      "Epoch 605/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.1374 - val_accuracy: 0.9606\n",
      "Epoch 606/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9603\n",
      "Epoch 607/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9494\n",
      "Epoch 608/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.99 - 1s 86us/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.1506 - val_accuracy: 0.9576\n",
      "Epoch 609/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9549\n",
      "Epoch 610/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1842 - val_accuracy: 0.9491\n",
      "Epoch 611/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1448 - val_accuracy: 0.9586\n",
      "Epoch 612/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.1364 - val_accuracy: 0.9610\n",
      "Epoch 613/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.1698 - val_accuracy: 0.9532\n",
      "Epoch 614/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.1577 - val_accuracy: 0.9559\n",
      "Epoch 615/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1464 - val_accuracy: 0.9586\n",
      "Epoch 616/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9511\n",
      "Epoch 617/1000\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9610\n",
      "Epoch 618/1000\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.1546 - val_accuracy: 0.9569\n",
      "Epoch 619/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.1411 - val_accuracy: 0.9606\n",
      "Epoch 620/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.1530 - val_accuracy: 0.9566\n",
      "Epoch 621/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9627\n",
      "Epoch 622/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.1477 - val_accuracy: 0.9576\n",
      "Epoch 623/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9481\n",
      "Epoch 624/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9596\n",
      "Epoch 625/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.1479 - val_accuracy: 0.9579\n",
      "Epoch 626/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9549\n",
      "Epoch 627/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.1574 - val_accuracy: 0.9552\n",
      "Epoch 628/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9542\n",
      "Epoch 629/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.1564 - val_accuracy: 0.9562\n",
      "Epoch 630/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.1568 - val_accuracy: 0.9562\n",
      "Epoch 631/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9606\n",
      "Epoch 632/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9545\n",
      "Epoch 633/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9539\n",
      "Epoch 634/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9562\n",
      "Epoch 635/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9583\n",
      "Epoch 636/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.1474 - val_accuracy: 0.9579\n",
      "Epoch 637/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.1501 - val_accuracy: 0.9576\n",
      "Epoch 638/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.1387 - val_accuracy: 0.9603\n",
      "Epoch 639/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9610\n",
      "Epoch 640/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9613\n",
      "Epoch 641/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9572\n",
      "Epoch 642/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.1574 - val_accuracy: 0.9566\n",
      "Epoch 643/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9576\n",
      "Epoch 644/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9606\n",
      "Epoch 645/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9593\n",
      "Epoch 646/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9583\n",
      "Epoch 647/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.1424 - val_accuracy: 0.9610\n",
      "Epoch 648/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9606\n",
      "Epoch 649/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9552\n",
      "Epoch 650/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.1459 - val_accuracy: 0.9606\n",
      "Epoch 651/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.2658 - val_accuracy: 0.9315\n",
      "Epoch 652/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.1440 - val_accuracy: 0.9606\n",
      "Epoch 653/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9518\n",
      "Epoch 654/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9583\n",
      "Epoch 655/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9603\n",
      "Epoch 657/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.1558 - val_accuracy: 0.9562\n",
      "Epoch 658/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9569\n",
      "Epoch 659/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9572\n",
      "Epoch 660/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9552\n",
      "Epoch 661/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9552\n",
      "Epoch 662/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.1377 - val_accuracy: 0.9603\n",
      "Epoch 663/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.1483 - val_accuracy: 0.9583\n",
      "Epoch 664/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9603\n",
      "Epoch 665/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9501\n",
      "Epoch 666/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9552\n",
      "Epoch 667/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9559\n",
      "Epoch 668/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9586\n",
      "Epoch 669/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9532\n",
      "Epoch 670/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9566\n",
      "Epoch 671/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.1461 - val_accuracy: 0.9603\n",
      "Epoch 672/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9569\n",
      "Epoch 673/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.1541 - val_accuracy: 0.9576\n",
      "Epoch 674/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9572\n",
      "Epoch 675/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.1672 - val_accuracy: 0.9549\n",
      "Epoch 676/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9488\n",
      "Epoch 677/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9555\n",
      "Epoch 678/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1457 - val_accuracy: 0.9606\n",
      "Epoch 679/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9559\n",
      "Epoch 680/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9600\n",
      "Epoch 681/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9522\n",
      "Epoch 682/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9569\n",
      "Epoch 683/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9549\n",
      "Epoch 684/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9610\n",
      "Epoch 685/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9549\n",
      "Epoch 686/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9610\n",
      "Epoch 687/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9566\n",
      "Epoch 688/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9606\n",
      "Epoch 689/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.1462 - val_accuracy: 0.9617\n",
      "Epoch 690/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.1545 - val_accuracy: 0.9572\n",
      "Epoch 691/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9610\n",
      "Epoch 692/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9505\n",
      "Epoch 693/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9606\n",
      "Epoch 694/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9566\n",
      "Epoch 695/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9566\n",
      "Epoch 696/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9474\n",
      "Epoch 697/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.1515 - val_accuracy: 0.9579\n",
      "Epoch 698/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9569\n",
      "Epoch 699/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9617\n",
      "Epoch 700/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9505\n",
      "Epoch 701/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9559\n",
      "Epoch 702/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9583\n",
      "Epoch 703/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.1614 - val_accuracy: 0.9569\n",
      "Epoch 704/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.1557 - val_accuracy: 0.9579\n",
      "Epoch 705/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9603\n",
      "Epoch 706/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9559\n",
      "Epoch 707/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9484\n",
      "Epoch 708/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.1518 - val_accuracy: 0.9596\n",
      "Epoch 709/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9583\n",
      "Epoch 710/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 711/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9606\n",
      "Epoch 712/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9569\n",
      "Epoch 713/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9515\n",
      "Epoch 714/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9589\n",
      "Epoch 715/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.1592 - val_accuracy: 0.9562\n",
      "Epoch 716/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9583\n",
      "Epoch 717/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9606\n",
      "Epoch 718/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.1528 - val_accuracy: 0.9579\n",
      "Epoch 719/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9586\n",
      "Epoch 720/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9562\n",
      "Epoch 721/1000\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9572\n",
      "Epoch 722/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9606\n",
      "Epoch 723/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9603\n",
      "Epoch 724/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9566\n",
      "Epoch 725/1000\n",
      "7352/7352 [==============================] - 1s 74us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9613\n",
      "Epoch 726/1000\n",
      "7352/7352 [==============================] - 1s 73us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9603\n",
      "Epoch 727/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9603\n",
      "Epoch 728/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9576\n",
      "Epoch 729/1000\n",
      "7352/7352 [==============================] - 1s 71us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9559\n",
      "Epoch 730/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9569\n",
      "Epoch 731/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9572\n",
      "Epoch 732/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9603\n",
      "Epoch 733/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 0.9583\n",
      "Epoch 734/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9606\n",
      "Epoch 735/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9566\n",
      "Epoch 736/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9589\n",
      "Epoch 737/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9562\n",
      "Epoch 738/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9583\n",
      "Epoch 739/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9535\n",
      "Epoch 740/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9596\n",
      "Epoch 741/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9566\n",
      "Epoch 742/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9600\n",
      "Epoch 743/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9562\n",
      "Epoch 744/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9606\n",
      "Epoch 745/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9579\n",
      "Epoch 746/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9559\n",
      "Epoch 747/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9566\n",
      "Epoch 748/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9586\n",
      "Epoch 749/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9576\n",
      "Epoch 750/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9566\n",
      "Epoch 751/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9552\n",
      "Epoch 752/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9589\n",
      "Epoch 753/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9610\n",
      "Epoch 754/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9569\n",
      "Epoch 755/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9610\n",
      "Epoch 756/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9606\n",
      "Epoch 757/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9576\n",
      "Epoch 758/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9610\n",
      "Epoch 759/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9545\n",
      "Epoch 760/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9610\n",
      "Epoch 761/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9572\n",
      "Epoch 762/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9606\n",
      "Epoch 763/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9572\n",
      "Epoch 764/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9569\n",
      "Epoch 765/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 766/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9617\n",
      "Epoch 767/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9586\n",
      "Epoch 768/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9562\n",
      "Epoch 769/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9606\n",
      "Epoch 770/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9586\n",
      "Epoch 771/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9562\n",
      "Epoch 772/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9562\n",
      "Epoch 773/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9593\n",
      "Epoch 774/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9576\n",
      "Epoch 775/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9569\n",
      "Epoch 776/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9562\n",
      "Epoch 777/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9576\n",
      "Epoch 778/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9596\n",
      "Epoch 779/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9549\n",
      "Epoch 780/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9549\n",
      "Epoch 781/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9569\n",
      "Epoch 782/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9576\n",
      "Epoch 783/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9572\n",
      "Epoch 784/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9610\n",
      "Epoch 785/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9606\n",
      "Epoch 786/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9583\n",
      "Epoch 787/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9566\n",
      "Epoch 788/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9569\n",
      "Epoch 789/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9572\n",
      "Epoch 790/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9569\n",
      "Epoch 791/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9593\n",
      "Epoch 792/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9549\n",
      "Epoch 793/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9586\n",
      "Epoch 794/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9566\n",
      "Epoch 795/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9566\n",
      "Epoch 796/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9589\n",
      "Epoch 797/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9572\n",
      "Epoch 798/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9566\n",
      "Epoch 799/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9562\n",
      "Epoch 800/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9600\n",
      "Epoch 801/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9610\n",
      "Epoch 802/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9569\n",
      "Epoch 803/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9542\n",
      "Epoch 804/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9606\n",
      "Epoch 805/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9539\n",
      "Epoch 806/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9579\n",
      "Epoch 807/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9566\n",
      "Epoch 808/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9552\n",
      "Epoch 809/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9566\n",
      "Epoch 810/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9583\n",
      "Epoch 811/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9572\n",
      "Epoch 812/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9569\n",
      "Epoch 813/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 1s 79us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9569\n",
      "Epoch 814/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1781 - val_accuracy: 0.9542\n",
      "Epoch 815/1000\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9613\n",
      "Epoch 816/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9576\n",
      "Epoch 817/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9593\n",
      "Epoch 818/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9583\n",
      "Epoch 819/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 1s 78us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9620\n",
      "Epoch 820/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9572\n",
      "Epoch 821/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1591 - val_accuracy: 0.9589\n",
      "Epoch 822/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9572\n",
      "Epoch 823/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9569\n",
      "Epoch 824/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1747 - val_accuracy: 0.9552\n",
      "Epoch 825/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9583\n",
      "Epoch 826/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9600\n",
      "Epoch 827/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9572\n",
      "Epoch 828/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9613\n",
      "Epoch 829/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9569\n",
      "Epoch 830/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9566\n",
      "Epoch 831/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9576\n",
      "Epoch 832/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9589\n",
      "Epoch 833/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9569\n",
      "Epoch 834/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9600\n",
      "Epoch 835/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9613\n",
      "Epoch 836/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9569\n",
      "Epoch 837/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9569\n",
      "Epoch 838/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9535\n",
      "Epoch 839/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9562\n",
      "Epoch 840/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9596\n",
      "Epoch 841/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9572\n",
      "Epoch 842/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9610\n",
      "Epoch 843/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9569\n",
      "Epoch 844/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9566\n",
      "Epoch 845/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9613\n",
      "Epoch 846/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9617\n",
      "Epoch 847/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9586\n",
      "Epoch 848/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9583\n",
      "Epoch 849/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9586\n",
      "Epoch 850/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9572\n",
      "Epoch 851/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9606\n",
      "Epoch 852/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9589\n",
      "Epoch 853/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9593\n",
      "Epoch 854/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9613\n",
      "Epoch 855/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9569\n",
      "Epoch 856/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9600\n",
      "Epoch 857/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1673 - val_accuracy: 0.9572\n",
      "Epoch 858/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9596\n",
      "Epoch 859/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9613\n",
      "Epoch 860/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9600\n",
      "Epoch 861/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9572\n",
      "Epoch 862/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9603\n",
      "Epoch 863/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9569\n",
      "Epoch 864/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9566\n",
      "Epoch 865/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 1s 83us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9593\n",
      "Epoch 866/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9552\n",
      "Epoch 867/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9589\n",
      "Epoch 868/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9603\n",
      "Epoch 869/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 0.9566\n",
      "Epoch 870/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9613\n",
      "Epoch 871/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9566\n",
      "Epoch 872/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9569\n",
      "Epoch 873/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9589\n",
      "Epoch 874/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 875/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9606\n",
      "Epoch 876/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9572\n",
      "Epoch 877/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9569\n",
      "Epoch 878/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9600\n",
      "Epoch 879/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9606\n",
      "Epoch 880/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9572\n",
      "Epoch 881/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9603\n",
      "Epoch 882/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9603\n",
      "Epoch 883/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9593\n",
      "Epoch 884/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1581 - val_accuracy: 0.9600\n",
      "Epoch 885/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9576\n",
      "Epoch 886/1000\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 1s 86us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9528\n",
      "Epoch 887/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9606\n",
      "Epoch 888/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9569\n",
      "Epoch 889/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9613\n",
      "Epoch 890/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9576\n",
      "Epoch 891/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9593\n",
      "Epoch 892/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9606\n",
      "Epoch 893/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9562\n",
      "Epoch 894/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9600\n",
      "Epoch 895/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9549\n",
      "Epoch 896/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9603\n",
      "Epoch 897/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9593\n",
      "Epoch 898/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9572\n",
      "Epoch 899/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9566\n",
      "Epoch 900/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9593\n",
      "Epoch 901/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9593\n",
      "Epoch 902/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9613\n",
      "Epoch 903/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9589\n",
      "Epoch 904/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9566\n",
      "Epoch 905/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9576\n",
      "Epoch 906/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9606\n",
      "Epoch 907/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9583\n",
      "Epoch 908/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9593\n",
      "Epoch 909/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9596\n",
      "Epoch 910/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9586\n",
      "Epoch 911/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9593\n",
      "Epoch 912/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9566\n",
      "Epoch 913/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9566\n",
      "Epoch 914/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9566\n",
      "Epoch 915/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9613\n",
      "Epoch 916/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9569\n",
      "Epoch 917/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9572\n",
      "Epoch 918/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 0.9569\n",
      "Epoch 919/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9596\n",
      "Epoch 920/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9579\n",
      "Epoch 921/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9569\n",
      "Epoch 922/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9569\n",
      "Epoch 923/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9569\n",
      "Epoch 924/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9579\n",
      "Epoch 925/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9596\n",
      "Epoch 926/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9617\n",
      "Epoch 927/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9586\n",
      "Epoch 928/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9566\n",
      "Epoch 929/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 930/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9569\n",
      "Epoch 931/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9593\n",
      "Epoch 932/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9572\n",
      "Epoch 933/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9603\n",
      "Epoch 934/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9596\n",
      "Epoch 935/1000\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9572\n",
      "Epoch 936/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9596\n",
      "Epoch 937/1000\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9583\n",
      "Epoch 938/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9569\n",
      "Epoch 939/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9589\n",
      "Epoch 940/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9596\n",
      "Epoch 941/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1648 - val_accuracy: 0.9583\n",
      "Epoch 942/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 0.9596\n",
      "Epoch 943/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9593\n",
      "Epoch 944/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9606\n",
      "Epoch 945/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9572\n",
      "Epoch 946/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9576\n",
      "Epoch 947/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9579\n",
      "Epoch 948/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9596\n",
      "Epoch 949/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1615 - val_accuracy: 0.9596\n",
      "Epoch 950/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9535\n",
      "Epoch 951/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9586\n",
      "Epoch 952/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9583\n",
      "Epoch 953/1000\n",
      "7352/7352 [==============================] - 1s 74us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9593\n",
      "Epoch 954/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9596\n",
      "Epoch 955/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9606\n",
      "Epoch 956/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9583\n",
      "Epoch 957/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9613\n",
      "Epoch 958/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9586\n",
      "Epoch 959/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9569\n",
      "Epoch 960/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9589\n",
      "Epoch 961/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9569\n",
      "Epoch 962/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9579\n",
      "Epoch 963/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9572\n",
      "Epoch 964/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9569\n",
      "Epoch 965/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9603\n",
      "Epoch 966/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 0.9606\n",
      "Epoch 967/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9610\n",
      "Epoch 968/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9569\n",
      "Epoch 969/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9603\n",
      "Epoch 970/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 0.9569\n",
      "Epoch 971/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9572\n",
      "Epoch 972/1000\n",
      "7352/7352 [==============================] - 1s 73us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 0.9596\n",
      "Epoch 973/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9572\n",
      "Epoch 974/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9569\n",
      "Epoch 975/1000\n",
      "7352/7352 [==============================] - 1s 75us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9583\n",
      "Epoch 976/1000\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9572\n",
      "Epoch 977/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9596\n",
      "Epoch 978/1000\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9566\n",
      "Epoch 979/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9589\n",
      "Epoch 980/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9610\n",
      "Epoch 981/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9572\n",
      "Epoch 982/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9586\n",
      "Epoch 983/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 0.9572\n",
      "Epoch 984/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1000\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9542\n",
      "Epoch 986/1000\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9620\n",
      "Epoch 987/1000\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9552\n",
      "Epoch 988/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 0.9569\n",
      "Epoch 989/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9589\n",
      "Epoch 990/1000\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9610\n",
      "Epoch 991/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9606\n",
      "Epoch 992/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1602 - val_accuracy: 0.9603\n",
      "Epoch 993/1000\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9589\n",
      "Epoch 994/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9596\n",
      "Epoch 995/1000\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9589\n",
      "Epoch 996/1000\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1632 - val_accuracy: 0.9593\n",
      "Epoch 997/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9596\n",
      "Epoch 998/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9579\n",
      "Epoch 999/1000\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9603\n",
      "Epoch 1000/1000\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9569\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_relu.summary()\n",
    "\n",
    "model_relu.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=1000, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + Adam + ReLu + 500(512-128-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 354,182\n",
      "Trainable params: 354,182\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/500\n",
      "7352/7352 [==============================] - 2s 219us/step - loss: 0.5668 - accuracy: 0.7965 - val_loss: 0.2699 - val_accuracy: 0.8951\n",
      "Epoch 2/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.1754 - accuracy: 0.9294 - val_loss: 0.2628 - val_accuracy: 0.8772\n",
      "Epoch 3/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.1076 - accuracy: 0.9641 - val_loss: 0.2548 - val_accuracy: 0.8955\n",
      "Epoch 4/500\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0865 - accuracy: 0.9678 - val_loss: 0.1920 - val_accuracy: 0.9169\n",
      "Epoch 5/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0785 - accuracy: 0.9694 - val_loss: 0.1437 - val_accuracy: 0.9450\n",
      "Epoch 6/500\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0773 - accuracy: 0.9709 - val_loss: 0.2820 - val_accuracy: 0.8901\n",
      "Epoch 7/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0833 - accuracy: 0.9667 - val_loss: 0.1755 - val_accuracy: 0.9335\n",
      "Epoch 8/500\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0542 - accuracy: 0.9793 - val_loss: 0.1809 - val_accuracy: 0.9345\n",
      "Epoch 9/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0617 - accuracy: 0.9765 - val_loss: 0.1670 - val_accuracy: 0.9389\n",
      "Epoch 10/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0510 - accuracy: 0.9800 - val_loss: 0.1580 - val_accuracy: 0.9437\n",
      "Epoch 11/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0583 - accuracy: 0.9765 - val_loss: 0.2295 - val_accuracy: 0.9209\n",
      "Epoch 12/500\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0430 - accuracy: 0.9830 - val_loss: 0.1723 - val_accuracy: 0.9406\n",
      "Epoch 13/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 0.0447 - accuracy: 0.9838 - val_loss: 0.1663 - val_accuracy: 0.9396\n",
      "Epoch 14/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.1680 - val_accuracy: 0.9450\n",
      "Epoch 15/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.1848 - val_accuracy: 0.9386\n",
      "Epoch 16/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0381 - accuracy: 0.9845 - val_loss: 0.2256 - val_accuracy: 0.9264\n",
      "Epoch 17/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0400 - accuracy: 0.9833 - val_loss: 0.1903 - val_accuracy: 0.9447\n",
      "Epoch 18/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0564 - accuracy: 0.9793 - val_loss: 0.1640 - val_accuracy: 0.9430\n",
      "Epoch 19/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0853 - accuracy: 0.9679 - val_loss: 0.2154 - val_accuracy: 0.9270\n",
      "Epoch 20/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.2377 - val_accuracy: 0.9209\n",
      "Epoch 21/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.2005 - val_accuracy: 0.9403\n",
      "Epoch 22/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0422 - accuracy: 0.9849 - val_loss: 0.1579 - val_accuracy: 0.9484\n",
      "Epoch 23/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0365 - accuracy: 0.9867 - val_loss: 0.1820 - val_accuracy: 0.9420\n",
      "Epoch 24/500\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.3524 - val_accuracy: 0.8979\n",
      "Epoch 25/500\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0508 - accuracy: 0.9774 - val_loss: 0.2164 - val_accuracy: 0.9328\n",
      "Epoch 26/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.2753 - val_accuracy: 0.9155\n",
      "Epoch 27/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0376 - accuracy: 0.9850 - val_loss: 0.1952 - val_accuracy: 0.9359\n",
      "Epoch 28/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.1790 - val_accuracy: 0.9488\n",
      "Epoch 29/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.1926 - val_accuracy: 0.9467\n",
      "Epoch 30/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.1790 - val_accuracy: 0.9488\n",
      "Epoch 31/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.2053 - val_accuracy: 0.9345\n",
      "Epoch 32/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.2225 - val_accuracy: 0.9420\n",
      "Epoch 33/500\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0410 - accuracy: 0.9820 - val_loss: 0.1942 - val_accuracy: 0.9484\n",
      "Epoch 34/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0367 - accuracy: 0.9853 - val_loss: 0.1923 - val_accuracy: 0.9450\n",
      "Epoch 35/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0461 - accuracy: 0.9807 - val_loss: 0.3506 - val_accuracy: 0.8941\n",
      "Epoch 36/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0610 - accuracy: 0.9774 - val_loss: 0.2861 - val_accuracy: 0.9209\n",
      "Epoch 37/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0404 - accuracy: 0.9845 - val_loss: 0.1689 - val_accuracy: 0.9457\n",
      "Epoch 38/500\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.1702 - val_accuracy: 0.9437\n",
      "Epoch 39/500\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.2470 - val_accuracy: 0.9365\n",
      "Epoch 40/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.1891 - val_accuracy: 0.9433\n",
      "Epoch 41/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.2399 - val_accuracy: 0.9362\n",
      "Epoch 42/500\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.2617 - val_accuracy: 0.9362\n",
      "Epoch 43/500\n",
      "7352/7352 [==============================] - 1s 78us/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.2242 - val_accuracy: 0.9437\n",
      "Epoch 44/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0217 - accuracy: 0.9908 - val_loss: 0.2088 - val_accuracy: 0.9433\n",
      "Epoch 45/500\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0186 - accuracy: 0.9929 - val_loss: 0.2749 - val_accuracy: 0.9315\n",
      "Epoch 46/500\n",
      "7352/7352 [==============================] - 1s 81us/step - loss: 0.0201 - accuracy: 0.9920 - val_loss: 0.2225 - val_accuracy: 0.9447\n",
      "Epoch 47/500\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.1824 - val_accuracy: 0.9450\n",
      "Epoch 48/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0123 - accuracy: 0.9948 - val_loss: 0.2041 - val_accuracy: 0.9464\n",
      "Epoch 49/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.1927 - val_accuracy: 0.9477\n",
      "Epoch 50/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.2241 - val_accuracy: 0.9444\n",
      "Epoch 51/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.2269 - val_accuracy: 0.9477\n",
      "Epoch 52/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.2096 - val_accuracy: 0.9416\n",
      "Epoch 53/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.2046 - val_accuracy: 0.9460\n",
      "Epoch 54/500\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.2252 - val_accuracy: 0.9389\n",
      "Epoch 55/500\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.2967 - val_accuracy: 0.9233\n",
      "Epoch 56/500\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0239 - accuracy: 0.9906 - val_loss: 0.2036 - val_accuracy: 0.9447\n",
      "Epoch 57/500\n",
      "7352/7352 [==============================] - 1s 73us/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 0.3084 - val_accuracy: 0.9274\n",
      "Epoch 58/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0217 - accuracy: 0.9921 - val_loss: 0.2455 - val_accuracy: 0.9396\n",
      "Epoch 59/500\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.2420 - val_accuracy: 0.9413\n",
      "Epoch 60/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.2495 - val_accuracy: 0.9440\n",
      "Epoch 61/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.3329 - val_accuracy: 0.9216\n",
      "Epoch 62/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.2021 - val_accuracy: 0.9474\n",
      "Epoch 63/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.2138 - val_accuracy: 0.9471\n",
      "Epoch 64/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.2802 - val_accuracy: 0.9420\n",
      "Epoch 65/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.2815 - val_accuracy: 0.9386\n",
      "Epoch 66/500\n",
      "7352/7352 [==============================] - 1s 80us/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.2486 - val_accuracy: 0.9433\n",
      "Epoch 67/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.2433 - val_accuracy: 0.9484\n",
      "Epoch 68/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.2405 - val_accuracy: 0.9457\n",
      "Epoch 69/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.2778 - val_accuracy: 0.9416\n",
      "Epoch 70/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.2762 - val_accuracy: 0.9420\n",
      "Epoch 71/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 0.0274 - accuracy: 0.9893 - val_loss: 0.2585 - val_accuracy: 0.9416\n",
      "Epoch 72/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.2345 - val_accuracy: 0.9437\n",
      "Epoch 73/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.2500 - val_accuracy: 0.9437\n",
      "Epoch 74/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.2260 - val_accuracy: 0.9488\n",
      "Epoch 75/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 0.2153 - val_accuracy: 0.9444\n",
      "Epoch 76/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0426 - accuracy: 0.9845 - val_loss: 0.2807 - val_accuracy: 0.9318\n",
      "Epoch 77/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.2252 - val_accuracy: 0.9403\n",
      "Epoch 78/500\n",
      "7352/7352 [==============================] - 1s 76us/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.3086 - val_accuracy: 0.9298\n",
      "Epoch 79/500\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.2239 - val_accuracy: 0.9471\n",
      "Epoch 80/500\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0232 - accuracy: 0.9899 - val_loss: 0.2234 - val_accuracy: 0.9464\n",
      "Epoch 81/500\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.2400 - val_accuracy: 0.9444\n",
      "Epoch 82/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.2032 - val_accuracy: 0.9511\n",
      "Epoch 83/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.2246 - val_accuracy: 0.9481\n",
      "Epoch 84/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2237 - val_accuracy: 0.9515\n",
      "Epoch 85/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2212 - val_accuracy: 0.9481\n",
      "Epoch 86/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.2641 - val_accuracy: 0.9444\n",
      "Epoch 87/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0523 - accuracy: 0.9887 - val_loss: 0.3241 - val_accuracy: 0.9264\n",
      "Epoch 88/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0584 - accuracy: 0.9850 - val_loss: 0.1848 - val_accuracy: 0.9522\n",
      "Epoch 89/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.2205 - val_accuracy: 0.9488\n",
      "Epoch 90/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.2151 - val_accuracy: 0.9518\n",
      "Epoch 91/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2334 - val_accuracy: 0.9511\n",
      "Epoch 92/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9508\n",
      "Epoch 93/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9501\n",
      "Epoch 94/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.2250 - val_accuracy: 0.9501\n",
      "Epoch 95/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.2151 - val_accuracy: 0.9518\n",
      "Epoch 96/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2486 - val_accuracy: 0.9511\n",
      "Epoch 97/500\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 9.6554e-04 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9498\n",
      "Epoch 98/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 9.8636e-04 - accuracy: 0.9999 - val_loss: 0.2386 - val_accuracy: 0.9522\n",
      "Epoch 99/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4118 - val_accuracy: 0.9223\n",
      "Epoch 100/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2267 - val_accuracy: 0.9498\n",
      "Epoch 101/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.2377 - val_accuracy: 0.9498\n",
      "Epoch 102/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.2460 - val_accuracy: 0.9481\n",
      "Epoch 103/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.2260 - val_accuracy: 0.9498\n",
      "Epoch 104/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.2380 - val_accuracy: 0.9423\n",
      "Epoch 105/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0248 - accuracy: 0.9901 - val_loss: 0.2601 - val_accuracy: 0.9430\n",
      "Epoch 106/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.2206 - val_accuracy: 0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.2801 - val_accuracy: 0.9393\n",
      "Epoch 108/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2614 - val_accuracy: 0.9488\n",
      "Epoch 109/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 6.6739e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9501\n",
      "Epoch 110/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 9.6595e-04 - accuracy: 0.9999 - val_loss: 0.2610 - val_accuracy: 0.9491\n",
      "Epoch 111/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.2663 - val_accuracy: 0.9484\n",
      "Epoch 112/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 7.9966e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9491\n",
      "Epoch 113/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.9221 - val_accuracy: 0.8592\n",
      "Epoch 114/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.0629 - accuracy: 0.9848 - val_loss: 0.2449 - val_accuracy: 0.9420\n",
      "Epoch 115/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.2372 - val_accuracy: 0.9471\n",
      "Epoch 116/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.2303 - val_accuracy: 0.9471\n",
      "Epoch 117/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.2238 - val_accuracy: 0.9518\n",
      "Epoch 118/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.2851 - val_accuracy: 0.9460\n",
      "Epoch 119/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.2629 - val_accuracy: 0.9471\n",
      "Epoch 120/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.2429 - val_accuracy: 0.9515\n",
      "Epoch 121/500\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.2498 - val_accuracy: 0.9528\n",
      "Epoch 122/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.2437 - val_accuracy: 0.9518\n",
      "Epoch 123/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.2356 - val_accuracy: 0.9505\n",
      "Epoch 124/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.2573 - val_accuracy: 0.9525\n",
      "Epoch 125/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9501\n",
      "Epoch 126/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 6.2365e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9522\n",
      "Epoch 127/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 5.2903e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9525\n",
      "Epoch 128/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 4.5883e-04 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9511\n",
      "Epoch 129/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 3.9016e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9515\n",
      "Epoch 130/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 4.0883e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9508\n",
      "Epoch 131/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 4.3149e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9508\n",
      "Epoch 132/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 4.3464e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9515\n",
      "Epoch 133/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 3.2508e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9525\n",
      "Epoch 134/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.5645e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9515\n",
      "Epoch 135/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.5510e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9508\n",
      "Epoch 136/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.5603e-04 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9528\n",
      "Epoch 137/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 2.3976e-04 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9515\n",
      "Epoch 138/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 2.1370e-04 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9511\n",
      "Epoch 139/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 2.2980e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9511\n",
      "Epoch 140/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.8076e-04 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9511\n",
      "Epoch 141/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.1991e-04 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9518\n",
      "Epoch 142/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 1.7089e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9508\n",
      "Epoch 143/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.5790e-04 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9508\n",
      "Epoch 144/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.3968e-04 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9511\n",
      "Epoch 145/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.4522e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9508\n",
      "Epoch 146/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.0224e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9511\n",
      "Epoch 147/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.7339e-04 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9494\n",
      "Epoch 148/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.2765e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9511\n",
      "Epoch 149/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.0766e-04 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9505\n",
      "Epoch 150/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 2.0871e-04 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9508\n",
      "Epoch 151/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.1596e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9511\n",
      "Epoch 152/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 9.6711e-05 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9511\n",
      "Epoch 153/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.0244e-04 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9505\n",
      "Epoch 154/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 8.7762e-05 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9511\n",
      "Epoch 155/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 7.5554e-05 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9508\n",
      "Epoch 156/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 7.1579e-05 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9508\n",
      "Epoch 157/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 6.8278e-05 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9515\n",
      "Epoch 158/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 7.7213e-05 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9505\n",
      "Epoch 159/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 6.2366e-05 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9518\n",
      "Epoch 160/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 7.8661e-05 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9501\n",
      "Epoch 161/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 6.3420e-05 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9508\n",
      "Epoch 162/500\n",
      "7352/7352 [==============================] - 1s 102us/step - loss: 6.0566e-05 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9511\n",
      "Epoch 163/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 7.8626e-05 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9511\n",
      "Epoch 164/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 5.8251e-05 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9508\n",
      "Epoch 165/500\n",
      "7352/7352 [==============================] - 1s 101us/step - loss: 5.4649e-05 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9508\n",
      "Epoch 166/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 5.4350e-05 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9501\n",
      "Epoch 167/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 5.0998e-05 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9501\n",
      "Epoch 168/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 4.4343e-05 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9501\n",
      "Epoch 169/500\n",
      "7352/7352 [==============================] - 1s 101us/step - loss: 4.2186e-05 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9501\n",
      "Epoch 170/500\n",
      "7352/7352 [==============================] - 1s 101us/step - loss: 4.2480e-05 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9501\n",
      "Epoch 171/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 3.7864e-05 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9501\n",
      "Epoch 172/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 3.7471e-05 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9501\n",
      "Epoch 173/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 3.5116e-05 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9508\n",
      "Epoch 174/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 2.9656e-05 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9508\n",
      "Epoch 175/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 3.5321e-05 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9501\n",
      "Epoch 176/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.8216e-05 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9494\n",
      "Epoch 177/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.7790e-05 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9501\n",
      "Epoch 178/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 3.8544e-05 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9498\n",
      "Epoch 179/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.1305 - accuracy: 0.9723 - val_loss: 0.3072 - val_accuracy: 0.9179\n",
      "Epoch 180/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0686 - accuracy: 0.9746 - val_loss: 0.2105 - val_accuracy: 0.9437\n",
      "Epoch 181/500\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.2332 - val_accuracy: 0.9355\n",
      "Epoch 182/500\n",
      "7352/7352 [==============================] - 1s 72us/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.1930 - val_accuracy: 0.9477\n",
      "Epoch 183/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.2146 - val_accuracy: 0.9474\n",
      "Epoch 184/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.2256 - val_accuracy: 0.9477\n",
      "Epoch 185/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.2299 - val_accuracy: 0.9467\n",
      "Epoch 186/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.2260 - val_accuracy: 0.9481\n",
      "Epoch 187/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.2291 - val_accuracy: 0.9460\n",
      "Epoch 188/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.2355 - val_accuracy: 0.9444\n",
      "Epoch 189/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2669 - val_accuracy: 0.9437\n",
      "Epoch 190/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.2375 - val_accuracy: 0.9457\n",
      "Epoch 191/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.2629 - val_accuracy: 0.9413\n",
      "Epoch 192/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.2528 - val_accuracy: 0.9464\n",
      "Epoch 193/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.2908 - val_accuracy: 0.9460\n",
      "Epoch 194/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.2606 - val_accuracy: 0.9460\n",
      "Epoch 195/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9457\n",
      "Epoch 196/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.2955 - val_accuracy: 0.9450\n",
      "Epoch 197/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9450\n",
      "Epoch 198/500\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.3138 - val_accuracy: 0.9399\n",
      "Epoch 199/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.3055 - val_accuracy: 0.9423\n",
      "Epoch 200/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 6.4099e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9467\n",
      "Epoch 201/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9467\n",
      "Epoch 202/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 5.1906e-04 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9460\n",
      "Epoch 203/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 9.8876e-04 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9467\n",
      "Epoch 204/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.2576 - val_accuracy: 0.9430\n",
      "Epoch 205/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.2562 - val_accuracy: 0.9481\n",
      "Epoch 206/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.3064 - val_accuracy: 0.9389\n",
      "Epoch 207/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.2997 - val_accuracy: 0.9450\n",
      "Epoch 208/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 9.6643e-04 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9494\n",
      "Epoch 209/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 9.7430e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9494\n",
      "Epoch 210/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9474\n",
      "Epoch 211/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.2740 - val_accuracy: 0.9488\n",
      "Epoch 212/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 7.5835e-04 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9477\n",
      "Epoch 213/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 4.4702e-04 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9498\n",
      "Epoch 214/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 4.0678e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9488\n",
      "Epoch 215/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 96us/step - loss: 3.6139e-04 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9477\n",
      "Epoch 216/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 3.8423e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9488\n",
      "Epoch 217/500\n",
      "7352/7352 [==============================] - 1s 101us/step - loss: 3.4678e-04 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9505\n",
      "Epoch 218/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.3786 - val_accuracy: 0.9416\n",
      "Epoch 219/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.3479 - val_accuracy: 0.9338\n",
      "Epoch 220/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 0.0186 - accuracy: 0.9920 - val_loss: 0.2534 - val_accuracy: 0.9423\n",
      "Epoch 221/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.2819 - val_accuracy: 0.9376\n",
      "Epoch 222/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.3132 - val_accuracy: 0.9369\n",
      "Epoch 223/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.3067 - val_accuracy: 0.9406\n",
      "Epoch 224/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 7.0154e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9464\n",
      "Epoch 225/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 5.6239e-04 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9477\n",
      "Epoch 226/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 4.0093e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9481\n",
      "Epoch 227/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 4.0036e-04 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9467\n",
      "Epoch 228/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 2.7439e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9474\n",
      "Epoch 229/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.4934e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9474\n",
      "Epoch 230/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.9041e-04 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9471\n",
      "Epoch 231/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.2172e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9474\n",
      "Epoch 232/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.0670e-04 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9474\n",
      "Epoch 233/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.1496e-04 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9467\n",
      "Epoch 234/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.8547e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9467\n",
      "Epoch 235/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.0285e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9464\n",
      "Epoch 236/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.7117e-04 - accuracy: 1.0000 - val_loss: 0.3036 - val_accuracy: 0.9464\n",
      "Epoch 237/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.5087e-04 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9471\n",
      "Epoch 238/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.6553e-04 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9467\n",
      "Epoch 239/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 1.6854e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9467\n",
      "Epoch 240/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.3073e-04 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9467\n",
      "Epoch 241/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 1.2386e-04 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9467\n",
      "Epoch 242/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.1830e-04 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9467\n",
      "Epoch 243/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 1.1695e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9467\n",
      "Epoch 244/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.1994e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9464\n",
      "Epoch 245/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.1128e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9460\n",
      "Epoch 246/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 1.0723e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9464\n",
      "Epoch 247/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.0062e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9467\n",
      "Epoch 248/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 9.5812e-05 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9464\n",
      "Epoch 249/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 8.9690e-05 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9457\n",
      "Epoch 250/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 8.6870e-05 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9460\n",
      "Epoch 251/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 8.5988e-05 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9454\n",
      "Epoch 252/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 7.7546e-05 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9464\n",
      "Epoch 253/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 7.7616e-05 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9460\n",
      "Epoch 254/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 7.4819e-05 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9467\n",
      "Epoch 255/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 7.5713e-05 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9460\n",
      "Epoch 256/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 6.7952e-05 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9454\n",
      "Epoch 257/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 7.4789e-05 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.9454\n",
      "Epoch 258/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 7.0850e-05 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9460\n",
      "Epoch 259/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 6.1246e-05 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9454\n",
      "Epoch 260/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 7.0279e-05 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9467\n",
      "Epoch 261/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 8.4095e-05 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9460\n",
      "Epoch 262/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 6.1962e-05 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9464\n",
      "Epoch 263/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 4.9575e-05 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9457\n",
      "Epoch 264/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 5.1511e-05 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9460\n",
      "Epoch 265/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 5.0003e-05 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9460\n",
      "Epoch 266/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 4.3722e-05 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9460\n",
      "Epoch 267/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 4.2964e-05 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9460\n",
      "Epoch 268/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 4.2080e-05 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9464\n",
      "Epoch 269/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 4.2677e-05 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9457\n",
      "Epoch 270/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 3.9191e-05 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9464\n",
      "Epoch 271/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 4.2751e-05 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9460\n",
      "Epoch 272/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 3.7978e-05 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9454\n",
      "Epoch 273/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 3.9268e-05 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9467\n",
      "Epoch 274/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 3.9392e-05 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9457\n",
      "Epoch 275/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 3.2073e-05 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9454\n",
      "Epoch 276/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 3.0436e-05 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9460\n",
      "Epoch 277/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 3.0611e-05 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9457\n",
      "Epoch 278/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 3.4822e-05 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9460\n",
      "Epoch 279/500\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 4.5430e-05 - accuracy: 1.00 - 1s 86us/step - loss: 4.4124e-05 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9457\n",
      "Epoch 280/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 2.5328e-05 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9457\n",
      "Epoch 281/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.4941e-05 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9464\n",
      "Epoch 282/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.4951e-05 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9460\n",
      "Epoch 283/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.4630e-05 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9450\n",
      "Epoch 284/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.3398e-05 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9464\n",
      "Epoch 285/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 2.2499e-05 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9454\n",
      "Epoch 286/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 2.3341e-05 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.9460\n",
      "Epoch 287/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 1.8787e-05 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9457\n",
      "Epoch 288/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 2.0197e-05 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9460\n",
      "Epoch 289/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.8435e-05 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9457\n",
      "Epoch 290/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.9397e-05 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9457\n",
      "Epoch 291/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 1.6958e-05 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9467\n",
      "Epoch 292/500\n",
      "7352/7352 [==============================] - 1s 105us/step - loss: 1.8265e-05 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9460\n",
      "Epoch 293/500\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 1.5921e-05 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9457\n",
      "Epoch 294/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.5581e-05 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9460\n",
      "Epoch 295/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.6095e-05 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9457\n",
      "Epoch 296/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.7855e-05 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9467\n",
      "Epoch 297/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.6059e-05 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9477\n",
      "Epoch 298/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 1.3724e-05 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9464\n",
      "Epoch 299/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.2666e-05 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9471\n",
      "Epoch 300/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.3080e-05 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9474\n",
      "Epoch 301/500\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 1.3095e-05 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9464\n",
      "Epoch 302/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 1.1829e-05 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9460\n",
      "Epoch 303/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 1.3019e-05 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9474\n",
      "Epoch 304/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.1695e-05 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9467\n",
      "Epoch 305/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 1.1293e-05 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9464\n",
      "Epoch 306/500\n",
      "7352/7352 [==============================] - 1s 82us/step - loss: 1.1475e-05 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9467\n",
      "Epoch 307/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 1.0324e-05 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9471\n",
      "Epoch 308/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 1.0804e-05 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9460\n",
      "Epoch 309/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 9.5548e-06 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9467\n",
      "Epoch 310/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 9.3191e-06 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9467\n",
      "Epoch 311/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 8.7717e-06 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9471\n",
      "Epoch 312/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.0848e-05 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9450\n",
      "Epoch 313/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 8.7824e-06 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9467\n",
      "Epoch 314/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 9.0771e-06 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9457\n",
      "Epoch 315/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 7.6427e-06 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9460\n",
      "Epoch 316/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 7.0263e-06 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.9454\n",
      "Epoch 317/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 8.2990e-06 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9450\n",
      "Epoch 318/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 8.4927e-06 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9464\n",
      "Epoch 319/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 8.4645e-06 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9457\n",
      "Epoch 320/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 6.3027e-06 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9460\n",
      "Epoch 321/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 6.2486e-06 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9460\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 95us/step - loss: 5.8783e-06 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9464\n",
      "Epoch 323/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 5.9700e-06 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9464\n",
      "Epoch 324/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 5.4101e-06 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9460\n",
      "Epoch 325/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 6.0500e-06 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9450\n",
      "Epoch 326/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 5.4634e-06 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9464\n",
      "Epoch 327/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 5.0753e-06 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9467\n",
      "Epoch 328/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 5.1554e-06 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9450\n",
      "Epoch 329/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 4.9536e-06 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9454\n",
      "Epoch 330/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 4.7733e-06 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9454\n",
      "Epoch 331/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 4.2156e-06 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9457\n",
      "Epoch 332/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 4.5622e-06 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9454\n",
      "Epoch 333/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 4.0594e-06 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9440\n",
      "Epoch 334/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 3.8630e-06 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9454\n",
      "Epoch 335/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 3.7393e-06 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9440\n",
      "Epoch 336/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 3.4452e-06 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9440\n",
      "Epoch 337/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 3.4685e-06 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9450\n",
      "Epoch 338/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 3.0593e-06 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9447\n",
      "Epoch 339/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.9728e-06 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9440\n",
      "Epoch 340/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 3.5558e-06 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9440\n",
      "Epoch 341/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 2.8424e-06 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9447\n",
      "Epoch 342/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.6040e-06 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9447\n",
      "Epoch 343/500\n",
      "7352/7352 [==============================] - 1s 101us/step - loss: 2.5658e-06 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9454\n",
      "Epoch 344/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 3.0348e-06 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9447\n",
      "Epoch 345/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.4314e-06 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9450\n",
      "Epoch 346/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 2.2296e-06 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9444\n",
      "Epoch 347/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 2.1413e-06 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9447\n",
      "Epoch 348/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.1008e-06 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9444\n",
      "Epoch 349/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 2.1528e-06 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9447\n",
      "Epoch 350/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.0320e-06 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9440\n",
      "Epoch 351/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.8608e-06 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.9440\n",
      "Epoch 352/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 2.0607e-06 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9444\n",
      "Epoch 353/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.6321e-06 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9440\n",
      "Epoch 354/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.6812e-06 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9450\n",
      "Epoch 355/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.6616e-06 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9447\n",
      "Epoch 356/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.6422e-06 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9444\n",
      "Epoch 357/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.4559e-06 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9444\n",
      "Epoch 358/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.6831e-06 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9433\n",
      "Epoch 359/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.5809e-06 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.9440\n",
      "Epoch 360/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.7726e-06 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9444\n",
      "Epoch 361/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.3984e-06 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9440\n",
      "Epoch 362/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.5229e-06 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9447\n",
      "Epoch 363/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.4654e-06 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9440\n",
      "Epoch 364/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.2144e-06 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9440\n",
      "Epoch 365/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.2708e-06 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9440\n",
      "Epoch 366/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.0765e-06 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9437\n",
      "Epoch 367/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.0758e-06 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9444\n",
      "Epoch 368/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 9.7513e-07 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.9437\n",
      "Epoch 369/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 8.7219e-07 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9447\n",
      "Epoch 370/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 7.9913e-07 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.9450\n",
      "Epoch 371/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 7.3903e-07 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9447\n",
      "Epoch 372/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 7.6153e-07 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9454\n",
      "Epoch 373/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 7.8041e-07 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9444\n",
      "Epoch 374/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 7.7012e-07 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.9447\n",
      "Epoch 375/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 6.7235e-07 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9450\n",
      "Epoch 376/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 6.0756e-07 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9447\n",
      "Epoch 377/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 6.5184e-07 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9450\n",
      "Epoch 378/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 5.8989e-07 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9447\n",
      "Epoch 379/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 5.7476e-07 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9454\n",
      "Epoch 380/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 5.8039e-07 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9447\n",
      "Epoch 381/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 6.4670e-07 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9450\n",
      "Epoch 382/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 5.4615e-07 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9447\n",
      "Epoch 383/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 5.2844e-07 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9447\n",
      "Epoch 384/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 5.6472e-07 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.9447\n",
      "Epoch 385/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 5.3732e-07 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9447\n",
      "Epoch 386/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 5.3066e-07 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9450\n",
      "Epoch 387/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 4.6520e-07 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9450\n",
      "Epoch 388/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 5.3288e-07 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9444\n",
      "Epoch 389/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 4.8083e-07 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9447\n",
      "Epoch 390/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 4.2553e-07 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.9447\n",
      "Epoch 391/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 4.7047e-07 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.9457\n",
      "Epoch 392/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 4.7629e-07 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9440\n",
      "Epoch 393/500\n",
      "7352/7352 [==============================] - 1s 84us/step - loss: 4.4824e-07 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.9447\n",
      "Epoch 394/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 3.9214e-07 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9437\n",
      "Epoch 395/500\n",
      "7352/7352 [==============================] - 1s 85us/step - loss: 3.9349e-07 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.9437\n",
      "Epoch 396/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 3.9490e-07 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9447\n",
      "Epoch 397/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 3.5869e-07 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.9447\n",
      "Epoch 398/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 3.6664e-07 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9440\n",
      "Epoch 399/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 3.6133e-07 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9437\n",
      "Epoch 400/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 3.5587e-07 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.9447\n",
      "Epoch 401/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 3.7601e-07 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.9444\n",
      "Epoch 402/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.9351e-07 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.9437\n",
      "Epoch 403/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 3.0165e-07 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.9440\n",
      "Epoch 404/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.9499e-07 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.9437\n",
      "Epoch 405/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 4.7388e-07 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.9437\n",
      "Epoch 406/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 3.3320e-07 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.9440\n",
      "Epoch 407/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.6194e-07 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9437\n",
      "Epoch 408/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 2.5294e-07 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9444\n",
      "Epoch 409/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 2.4385e-07 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.9447\n",
      "Epoch 410/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.5395e-07 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.9437\n",
      "Epoch 411/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 2.3324e-07 - accuracy: 1.0000 - val_loss: 0.5344 - val_accuracy: 0.9437\n",
      "Epoch 412/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 2.2770e-07 - accuracy: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.9433\n",
      "Epoch 413/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.3320e-07 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.9437\n",
      "Epoch 414/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 2.2032e-07 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9444\n",
      "Epoch 415/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 2.2102e-07 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9440\n",
      "Epoch 416/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.1609e-07 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9437\n",
      "Epoch 417/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.2836e-07 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.9437\n",
      "Epoch 418/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 2.2577e-07 - accuracy: 1.0000 - val_loss: 0.5471 - val_accuracy: 0.9444\n",
      "Epoch 419/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 1.9838e-07 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.9444\n",
      "Epoch 420/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 2.0553e-07 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.9437\n",
      "Epoch 421/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 1.7993e-07 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9437\n",
      "Epoch 422/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 1.6103e-07 - accuracy: 1.0000 - val_loss: 0.5445 - val_accuracy: 0.9433\n",
      "Epoch 423/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.7048e-07 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.9444\n",
      "Epoch 424/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 1.7826e-07 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.9437\n",
      "Epoch 425/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 1.4082e-07 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.9447\n",
      "Epoch 426/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 1.4685e-07 - accuracy: 1.0000 - val_loss: 0.5506 - val_accuracy: 0.9437\n",
      "Epoch 427/500\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 1.3045e-07 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9437\n",
      "Epoch 428/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 1.3625e-07 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 1.2651e-07 - accuracy: 1.0000 - val_loss: 0.5506 - val_accuracy: 0.9437\n",
      "Epoch 430/500\n",
      "7352/7352 [==============================] - 1s 100us/step - loss: 1.3625e-07 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.9440\n",
      "Epoch 431/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 1.2013e-07 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.9437\n",
      "Epoch 432/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 1.1814e-07 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9433\n",
      "Epoch 433/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 1.1146e-07 - accuracy: 1.0000 - val_loss: 0.5563 - val_accuracy: 0.9437\n",
      "Epoch 434/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.0914e-07 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9437\n",
      "Epoch 435/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.0676e-07 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.9447\n",
      "Epoch 436/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 1.1553e-07 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.9447\n",
      "Epoch 437/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.0740e-07 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.9440\n",
      "Epoch 438/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 1.0222e-07 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.9437\n",
      "Epoch 439/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 9.3947e-08 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.9433\n",
      "Epoch 440/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 8.8272e-08 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.9440\n",
      "Epoch 441/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.0762e-07 - accuracy: 1.0000 - val_loss: 0.5688 - val_accuracy: 0.9437\n",
      "Epoch 442/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 8.9001e-08 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.9440\n",
      "Epoch 443/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 8.6731e-08 - accuracy: 1.0000 - val_loss: 0.5651 - val_accuracy: 0.9437\n",
      "Epoch 444/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 9.8941e-08 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.9437\n",
      "Epoch 445/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 8.6310e-08 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.9437\n",
      "Epoch 446/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 8.1510e-08 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 0.9440\n",
      "Epoch 447/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 7.9678e-08 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.9437\n",
      "Epoch 448/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 7.4668e-08 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.9437\n",
      "Epoch 449/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 6.7777e-08 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.9437\n",
      "Epoch 450/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 6.5766e-08 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.9440\n",
      "Epoch 451/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 7.1425e-08 - accuracy: 1.0000 - val_loss: 0.5632 - val_accuracy: 0.9440\n",
      "Epoch 452/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 8.8417e-08 - accuracy: 1.0000 - val_loss: 0.5710 - val_accuracy: 0.9437\n",
      "Epoch 453/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 6.8733e-08 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.9444\n",
      "Epoch 454/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 6.5847e-08 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.9440\n",
      "Epoch 455/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 5.9621e-08 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.9437\n",
      "Epoch 456/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 5.6037e-08 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9440\n",
      "Epoch 457/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 6.8004e-08 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.9440\n",
      "Epoch 458/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 6.3350e-08 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9433\n",
      "Epoch 459/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 5.6394e-08 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 0.9440\n",
      "Epoch 460/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 4.8984e-08 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9437\n",
      "Epoch 461/500\n",
      "7352/7352 [==============================] - 1s 92us/step - loss: 5.7367e-08 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.9433\n",
      "Epoch 462/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 4.6568e-08 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9440\n",
      "Epoch 463/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 4.5579e-08 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9437\n",
      "Epoch 464/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 4.7898e-08 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.9440\n",
      "Epoch 465/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 4.2871e-08 - accuracy: 1.0000 - val_loss: 0.5860 - val_accuracy: 0.9437\n",
      "Epoch 466/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 4.3520e-08 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.9437\n",
      "Epoch 467/500\n",
      "7352/7352 [==============================] - 1s 110us/step - loss: 4.0731e-08 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.9437\n",
      "Epoch 468/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 4.4849e-08 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.9437\n",
      "Epoch 469/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 4.0277e-08 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.9437\n",
      "Epoch 470/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 4.2725e-08 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 0.9440\n",
      "Epoch 471/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 3.6548e-08 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.9437\n",
      "Epoch 472/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 3.9336e-08 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.9440\n",
      "Epoch 473/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 3.4602e-08 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.9437\n",
      "Epoch 474/500\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 3.6418e-08 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 0.9437\n",
      "Epoch 475/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 3.2380e-08 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9437\n",
      "Epoch 476/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 3.2429e-08 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 0.9437\n",
      "Epoch 477/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 3.1213e-08 - accuracy: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.9440\n",
      "Epoch 478/500\n",
      "7352/7352 [==============================] - 1s 89us/step - loss: 3.2591e-08 - accuracy: 1.0000 - val_loss: 0.5945 - val_accuracy: 0.9433\n",
      "Epoch 479/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 3.2299e-08 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.9437\n",
      "Epoch 480/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 3.1326e-08 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9437\n",
      "Epoch 481/500\n",
      "7352/7352 [==============================] - 1s 86us/step - loss: 2.8911e-08 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.9437\n",
      "Epoch 482/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 2.8197e-08 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.8538e-08 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.9437\n",
      "Epoch 484/500\n",
      "7352/7352 [==============================] - 1s 96us/step - loss: 2.6835e-08 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.9437\n",
      "Epoch 485/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.6722e-08 - accuracy: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.9437\n",
      "Epoch 486/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 2.4500e-08 - accuracy: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.9444\n",
      "Epoch 487/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.7646e-08 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.9437\n",
      "Epoch 488/500\n",
      "7352/7352 [==============================] - 1s 95us/step - loss: 2.3219e-08 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.9437\n",
      "Epoch 489/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.2652e-08 - accuracy: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.9437\n",
      "Epoch 490/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.1760e-08 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 0.9437\n",
      "Epoch 491/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 2.2538e-08 - accuracy: 1.0000 - val_loss: 0.6164 - val_accuracy: 0.9437\n",
      "Epoch 492/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 2.2765e-08 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.9437\n",
      "Epoch 493/500\n",
      "7352/7352 [==============================] - 1s 98us/step - loss: 3.0451e-08 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9447\n",
      "Epoch 494/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 2.7824e-08 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.9437\n",
      "Epoch 495/500\n",
      "7352/7352 [==============================] - 1s 90us/step - loss: 1.9279e-08 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 0.9437\n",
      "Epoch 496/500\n",
      "7352/7352 [==============================] - 1s 91us/step - loss: 1.9944e-08 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.9444\n",
      "Epoch 497/500\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 1.9701e-08 - accuracy: 1.0000 - val_loss: 0.6168 - val_accuracy: 0.9437\n",
      "Epoch 498/500\n",
      "7352/7352 [==============================] - 1s 87us/step - loss: 1.7787e-08 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.9444\n",
      "Epoch 499/500\n",
      "7352/7352 [==============================] - 1s 97us/step - loss: 1.6814e-08 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 0.9437\n",
      "Epoch 500/500\n",
      "7352/7352 [==============================] - 1s 94us/step - loss: 1.6944e-08 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.9440\n",
      "Test score: 0.6210258876959831\n",
      "Test accuracy: 0.944010853767395\n"
     ]
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "print(model_relu.summary())\n",
    "\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=500, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "score = model_relu.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test score:', score[0]) \n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + Sigmoid + Adam + 250 + BatchNormalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 356,742\n",
      "Trainable params: 355,462\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/250\n",
      "7352/7352 [==============================] - 3s 447us/step - loss: 0.2727 - accuracy: 0.8950 - val_loss: 1.4585 - val_accuracy: 0.3729\n",
      "Epoch 2/250\n",
      "7352/7352 [==============================] - 1s 109us/step - loss: 0.0935 - accuracy: 0.9691 - val_loss: 0.8448 - val_accuracy: 0.6573\n",
      "Epoch 3/250\n",
      "7352/7352 [==============================] - 1s 113us/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.3688 - val_accuracy: 0.9216\n",
      "Epoch 4/250\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.0548 - accuracy: 0.9830 - val_loss: 0.2696 - val_accuracy: 0.9026\n",
      "Epoch 5/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.3139 - val_accuracy: 0.8853\n",
      "Epoch 6/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 0.3650 - val_accuracy: 0.8470\n",
      "Epoch 7/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.2749 - val_accuracy: 0.9009\n",
      "Epoch 8/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0353 - accuracy: 0.9871 - val_loss: 0.2732 - val_accuracy: 0.9230\n",
      "Epoch 9/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.3473 - val_accuracy: 0.8731\n",
      "Epoch 10/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.3447 - val_accuracy: 0.8700\n",
      "Epoch 11/250\n",
      "7352/7352 [==============================] - 1s 121us/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.2099 - val_accuracy: 0.9226\n",
      "Epoch 12/250\n",
      "7352/7352 [==============================] - 1s 108us/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.6278 - val_accuracy: 0.8219\n",
      "Epoch 13/250\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.5393 - val_accuracy: 0.8378\n",
      "Epoch 14/250\n",
      "7352/7352 [==============================] - 1s 120us/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.2098 - val_accuracy: 0.9284\n",
      "Epoch 15/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.4456 - val_accuracy: 0.8487\n",
      "Epoch 16/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.1995 - val_accuracy: 0.9369\n",
      "Epoch 17/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.2681 - val_accuracy: 0.9080\n",
      "Epoch 18/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.6686 - val_accuracy: 0.7611\n",
      "Epoch 19/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.3887 - val_accuracy: 0.8361\n",
      "Epoch 20/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.3589 - val_accuracy: 0.8697\n",
      "Epoch 21/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.3129 - val_accuracy: 0.9016\n",
      "Epoch 22/250\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.2214 - val_accuracy: 0.9267\n",
      "Epoch 23/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.2208 - val_accuracy: 0.9080\n",
      "Epoch 24/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.3204 - val_accuracy: 0.8968\n",
      "Epoch 25/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.5444 - val_accuracy: 0.7995\n",
      "Epoch 26/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 0.4505 - val_accuracy: 0.8409\n",
      "Epoch 27/250\n",
      "7352/7352 [==============================] - 1s 116us/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.6248 - val_accuracy: 0.8307\n",
      "Epoch 28/250\n",
      "7352/7352 [==============================] - 1s 107us/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.4225 - val_accuracy: 0.8687\n",
      "Epoch 29/250\n",
      "7352/7352 [==============================] - 1s 123us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.3439 - val_accuracy: 0.8863\n",
      "Epoch 30/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.2995 - val_accuracy: 0.9175\n",
      "Epoch 31/250\n",
      "7352/7352 [==============================] - 1s 117us/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.5292 - val_accuracy: 0.8320\n",
      "Epoch 32/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.3078 - val_accuracy: 0.9019\n",
      "Epoch 33/250\n",
      "7352/7352 [==============================] - 1s 123us/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.2989 - val_accuracy: 0.9046\n",
      "Epoch 34/250\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
      "Epoch 35/250\n",
      "7352/7352 [==============================] - 1s 122us/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.1985 - val_accuracy: 0.9369\n",
      "Epoch 36/250\n",
      "7352/7352 [==============================] - 1s 123us/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.1874 - val_accuracy: 0.9379\n",
      "Epoch 37/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.2423 - val_accuracy: 0.9158\n",
      "Epoch 38/250\n",
      "7352/7352 [==============================] - 1s 122us/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.3803 - val_accuracy: 0.8721\n",
      "Epoch 39/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.2272 - val_accuracy: 0.9308\n",
      "Epoch 40/250\n",
      "7352/7352 [==============================] - 1s 122us/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.5597 - val_accuracy: 0.7801\n",
      "Epoch 41/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.2465 - val_accuracy: 0.9162\n",
      "Epoch 42/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 1.1513 - val_accuracy: 0.6926\n",
      "Epoch 43/250\n",
      "7352/7352 [==============================] - 1s 123us/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.7304 - val_accuracy: 0.7774\n",
      "Epoch 44/250\n",
      "7352/7352 [==============================] - 1s 120us/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.3475 - val_accuracy: 0.8979\n",
      "Epoch 45/250\n",
      "7352/7352 [==============================] - 1s 117us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.4227 - val_accuracy: 0.8955\n",
      "Epoch 46/250\n",
      "7352/7352 [==============================] - 1s 121us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.5750 - val_accuracy: 0.8870\n",
      "Epoch 47/250\n",
      "7352/7352 [==============================] - 1s 122us/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.2266 - val_accuracy: 0.9413\n",
      "Epoch 48/250\n",
      "7352/7352 [==============================] - 1s 123us/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.3319 - val_accuracy: 0.8887\n",
      "Epoch 49/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.2299 - val_accuracy: 0.9189\n",
      "Epoch 50/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2191 - val_accuracy: 0.9318\n",
      "Epoch 51/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.4049 - val_accuracy: 0.8534\n",
      "Epoch 52/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.2512 - val_accuracy: 0.9253\n",
      "Epoch 53/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.2347 - val_accuracy: 0.9247\n",
      "Epoch 54/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.2907 - val_accuracy: 0.9070\n",
      "Epoch 55/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.4748 - val_accuracy: 0.8541\n",
      "Epoch 56/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0163 - accuracy: 0.9929 - val_loss: 0.3137 - val_accuracy: 0.8931\n",
      "Epoch 57/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 1.0313 - val_accuracy: 0.7075\n",
      "Epoch 58/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.6025 - val_accuracy: 0.8225\n",
      "Epoch 59/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.4470 - val_accuracy: 0.9002\n",
      "Epoch 60/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1989 - val_accuracy: 0.9555\n",
      "Epoch 61/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.6703 - val_accuracy: 0.8256\n",
      "Epoch 62/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.3443 - val_accuracy: 0.9209\n",
      "Epoch 63/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.2064 - val_accuracy: 0.9491\n",
      "Epoch 64/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.5312 - val_accuracy: 0.8921\n",
      "Epoch 65/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.2188 - val_accuracy: 0.9430\n",
      "Epoch 66/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2618 - val_accuracy: 0.9348\n",
      "Epoch 67/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.2903 - val_accuracy: 0.9257\n",
      "Epoch 68/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.3342 - val_accuracy: 0.9325\n",
      "Epoch 69/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.4733 - val_accuracy: 0.9053\n",
      "Epoch 70/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.2421 - val_accuracy: 0.9471\n",
      "Epoch 71/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.3043 - val_accuracy: 0.9440\n",
      "Epoch 72/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0214 - accuracy: 0.9914 - val_loss: 0.4367 - val_accuracy: 0.8531\n",
      "Epoch 73/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 0.2769 - val_accuracy: 0.9135\n",
      "Epoch 74/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0217 - accuracy: 0.9917 - val_loss: 1.0057 - val_accuracy: 0.6837\n",
      "Epoch 75/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.3791 - val_accuracy: 0.8724\n",
      "Epoch 76/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0147 - accuracy: 0.9937 - val_loss: 0.3806 - val_accuracy: 0.8711\n",
      "Epoch 77/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3532 - val_accuracy: 0.9087\n",
      "Epoch 78/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.8124 - val_accuracy: 0.8069\n",
      "Epoch 79/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 1.1402 - val_accuracy: 0.8052\n",
      "Epoch 80/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.3001 - val_accuracy: 0.9138\n",
      "Epoch 81/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.2547 - val_accuracy: 0.9365\n",
      "Epoch 82/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.2516 - val_accuracy: 0.9410\n",
      "Epoch 83/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.4059 - val_accuracy: 0.9138\n",
      "Epoch 84/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.3318 - val_accuracy: 0.8975\n",
      "Epoch 85/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.3599 - val_accuracy: 0.9060\n",
      "Epoch 86/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.3209 - val_accuracy: 0.9080\n",
      "Epoch 87/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.2253 - val_accuracy: 0.9382\n",
      "Epoch 88/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.2246 - val_accuracy: 0.9508\n",
      "Epoch 89/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.2090 - val_accuracy: 0.9511\n",
      "Epoch 90/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.2363 - val_accuracy: 0.9403\n",
      "Epoch 91/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.2371 - val_accuracy: 0.9450\n",
      "Epoch 92/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.4336 - val_accuracy: 0.9002\n",
      "Epoch 93/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.2719 - val_accuracy: 0.9440\n",
      "Epoch 94/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 7.0638e-04 - accuracy: 0.9999 - val_loss: 0.2754 - val_accuracy: 0.9498\n",
      "Epoch 95/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 3.1138e-04 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9437\n",
      "Epoch 96/250\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 8.9078e-04 - accuracy: 0.9997 - val_loss: 0.3001 - val_accuracy: 0.9308\n",
      "Epoch 97/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.4270 - val_accuracy: 0.8975\n",
      "Epoch 98/250\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.5773 - val_accuracy: 0.7682\n",
      "Epoch 99/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 0.0170 - accuracy: 0.9935 - val_loss: 1.6294 - val_accuracy: 0.5209\n",
      "Epoch 100/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 1.3984 - val_accuracy: 0.6250\n",
      "Epoch 101/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0171 - accuracy: 0.9936 - val_loss: 2.6192 - val_accuracy: 0.5589\n",
      "Epoch 102/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.6314 - val_accuracy: 0.8303\n",
      "Epoch 103/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.7622 - val_accuracy: 0.7828\n",
      "Epoch 104/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.5903 - val_accuracy: 0.8320\n",
      "Epoch 105/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.3234 - val_accuracy: 0.9165\n",
      "Epoch 106/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.2726 - val_accuracy: 0.9518\n",
      "Epoch 107/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3779 - val_accuracy: 0.9175\n",
      "Epoch 108/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 6.0650e-04 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9481\n",
      "Epoch 109/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.6087 - val_accuracy: 0.8863\n",
      "Epoch 110/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.6054 - val_accuracy: 0.8629\n",
      "Epoch 111/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 0.6034 - val_accuracy: 0.88330 - accuracy: 0.99\n",
      "Epoch 112/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 1.0053 - val_accuracy: 0.7825\n",
      "Epoch 113/250\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 2.8269 - val_accuracy: 0.5650\n",
      "Epoch 114/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 1.6664 - val_accuracy: 0.7218\n",
      "Epoch 115/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.5338 - val_accuracy: 0.8687\n",
      "Epoch 116/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.3046 - val_accuracy: 0.9308\n",
      "Epoch 117/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.4572 - val_accuracy: 0.8958\n",
      "Epoch 118/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5328 - val_accuracy: 0.9203\n",
      "Epoch 119/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2362 - val_accuracy: 0.9586\n",
      "Epoch 120/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.4154 - val_accuracy: 0.9108\n",
      "Epoch 121/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.4975 - val_accuracy: 0.8816\n",
      "Epoch 122/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.3775 - val_accuracy: 0.9365\n",
      "Epoch 123/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 5.3073e-04 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9569\n",
      "Epoch 124/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 2.7358e-04 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9596\n",
      "Epoch 125/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 2.5617e-04 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9559\n",
      "Epoch 126/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.8291 - val_accuracy: 0.8517\n",
      "Epoch 127/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.6691 - val_accuracy: 0.8738\n",
      "Epoch 128/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0072 - accuracy: 0.9970 - val_loss: 0.3909 - val_accuracy: 0.9250\n",
      "Epoch 129/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.3513 - val_accuracy: 0.9114\n",
      "Epoch 130/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 1.0077 - val_accuracy: 0.8395\n",
      "Epoch 131/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0116 - accuracy: 0.9951 - val_loss: 2.2116 - val_accuracy: 0.6542\n",
      "Epoch 132/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0219 - accuracy: 0.9922 - val_loss: 2.7016 - val_accuracy: 0.5789\n",
      "Epoch 133/250\n",
      "7352/7352 [==============================] - 1s 124us/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.4231 - val_accuracy: 0.9046\n",
      "Epoch 134/250\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.5455 - val_accuracy: 0.8734\n",
      "Epoch 135/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.3922 - val_accuracy: 0.9033\n",
      "Epoch 136/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.3163 - val_accuracy: 0.9338\n",
      "Epoch 137/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.2704 - val_accuracy: 0.9535\n",
      "Epoch 138/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.2457 - val_accuracy: 0.9311\n",
      "Epoch 139/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.9769 - val_accuracy: 0.7126\n",
      "Epoch 140/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 1.5614 - val_accuracy: 0.5942\n",
      "Epoch 141/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.6050 - val_accuracy: 0.8235\n",
      "Epoch 142/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.3660 - val_accuracy: 0.9199\n",
      "Epoch 143/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.4741 - val_accuracy: 0.7391\n",
      "Epoch 144/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4671 - val_accuracy: 0.9158\n",
      "Epoch 145/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.7029 - val_accuracy: 0.8782\n",
      "Epoch 146/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 7.4626e-04 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9572\n",
      "Epoch 147/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2491 - val_accuracy: 0.9454\n",
      "Epoch 148/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.9468 - val_accuracy: 0.8483\n",
      "Epoch 149/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.3662 - val_accuracy: 0.9220\n",
      "Epoch 150/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.2990 - val_accuracy: 0.9430\n",
      "Epoch 151/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2196 - val_accuracy: 0.9566\n",
      "Epoch 152/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 4.4573e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9566\n",
      "Epoch 153/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 4.9134e-04 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9549\n",
      "Epoch 154/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 2.5653e-04 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9569\n",
      "Epoch 155/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 3.2237e-04 - accuracy: 1.0000 - val_loss: 0.2315 - val_accuracy: 0.9586\n",
      "Epoch 156/250\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 1.8476e-04 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9613\n",
      "Epoch 157/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 1.7408e-04 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9634\n",
      "Epoch 158/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 1.3450e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9610\n",
      "Epoch 159/250\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 2.3044e-04 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9634\n",
      "Epoch 160/250\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.8635 - val_accuracy: 0.8171\n",
      "Epoch 161/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0051 - accuracy: 0.9978 - val_loss: 0.7478 - val_accuracy: 0.8235\n",
      "Epoch 162/250\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.6377 - val_accuracy: 0.7458\n",
      "Epoch 163/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.9288 - val_accuracy: 0.7177\n",
      "Epoch 164/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.2833 - val_accuracy: 0.9131\n",
      "Epoch 165/250\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.4172 - val_accuracy: 0.8884\n",
      "Epoch 166/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.3003 - val_accuracy: 0.9359\n",
      "Epoch 167/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 9.1248e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9369\n",
      "Epoch 168/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.2413 - val_accuracy: 0.9481\n",
      "Epoch 169/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.2378 - val_accuracy: 0.9610\n",
      "Epoch 170/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 2.9755e-04 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9528\n",
      "Epoch 171/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 7.8732e-04 - accuracy: 0.9999 - val_loss: 0.3679 - val_accuracy: 0.9169\n",
      "Epoch 172/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 4.2495e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9281\n",
      "Epoch 173/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 3.5655e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9532\n",
      "Epoch 174/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 1.8801e-04 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9413\n",
      "Epoch 175/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 1.1646e-04 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9606\n",
      "Epoch 176/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 1.3930e-04 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9515\n",
      "Epoch 177/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 7.9331e-05 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9579\n",
      "Epoch 178/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 1.1227e-04 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 0.9522\n",
      "Epoch 179/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 1.1921e-04 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9586\n",
      "Epoch 180/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 7.5211e-05 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9555\n",
      "Epoch 181/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 2.3215e-04 - accuracy: 1.0000 - val_loss: 0.7356 - val_accuracy: 0.9101\n",
      "Epoch 182/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 4.7509e-04 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9311\n",
      "Epoch 183/250\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.99 - 1s 133us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4795 - val_accuracy: 0.9043\n",
      "Epoch 184/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.4236 - val_accuracy: 0.8843\n",
      "Epoch 185/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 3.6306 - val_accuracy: 0.5867\n",
      "Epoch 186/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 2.0491 - val_accuracy: 0.5606\n",
      "Epoch 187/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0167 - accuracy: 0.9929 - val_loss: 1.4101 - val_accuracy: 0.7730\n",
      "Epoch 188/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 2.6059 - val_accuracy: 0.6145\n",
      "Epoch 189/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 2.0143 - val_accuracy: 0.7129\n",
      "Epoch 190/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.2917 - val_accuracy: 0.9325\n",
      "Epoch 191/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3596 - val_accuracy: 0.9186\n",
      "Epoch 192/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.5810 - val_accuracy: 0.9179\n",
      "Epoch 193/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.2896 - val_accuracy: 0.9477\n",
      "Epoch 194/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.3703 - val_accuracy: 0.9270\n",
      "Epoch 195/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2698 - val_accuracy: 0.9528\n",
      "Epoch 196/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2380 - val_accuracy: 0.9627\n",
      "Epoch 197/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.3010 - val_accuracy: 0.9359\n",
      "Epoch 198/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2802 - val_accuracy: 0.9494\n",
      "Epoch 199/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4236 - val_accuracy: 0.9057\n",
      "Epoch 200/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.3974 - val_accuracy: 0.9260\n",
      "Epoch 201/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.5873 - val_accuracy: 0.8514\n",
      "Epoch 202/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.2290 - val_accuracy: 0.9494\n",
      "Epoch 203/250\n",
      "7352/7352 [==============================] - 1s 129us/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5076 - val_accuracy: 0.9077\n",
      "Epoch 204/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.2896 - val_accuracy: 0.9491\n",
      "Epoch 205/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.5397 - val_accuracy: 0.9179\n",
      "Epoch 206/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 5.1424e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9522\n",
      "Epoch 207/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 3.9330e-04 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9505\n",
      "Epoch 208/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 2.4984e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9566\n",
      "Epoch 209/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 3.5722e-04 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9471\n",
      "Epoch 210/250\n",
      "7352/7352 [==============================] - 1s 127us/step - loss: 5.4283e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9474\n",
      "Epoch 211/250\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.9206 - val_accuracy: 0.8215\n",
      "Epoch 212/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.6486 - val_accuracy: 0.7967\n",
      "Epoch 213/250\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0085 - accuracy: 0.9966 - val_loss: 1.6605 - val_accuracy: 0.7248\n",
      "Epoch 214/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.8878 - val_accuracy: 0.8320\n",
      "Epoch 215/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.6847 - val_accuracy: 0.8517\n",
      "Epoch 216/250\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 0.1921 - val_accuracy: 0.9559\n",
      "Epoch 217/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.3504 - val_accuracy: 0.9308\n",
      "Epoch 218/250\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.3254 - val_accuracy: 0.9491\n",
      "Epoch 219/250\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.1698 - val_accuracy: 0.8521\n",
      "Epoch 220/250\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.2922 - val_accuracy: 0.9522\n",
      "Epoch 221/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 5.2719e-04 - accuracy: 0.9999 - val_loss: 0.2955 - val_accuracy: 0.9525\n",
      "Epoch 222/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 3.2816e-04 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9545\n",
      "Epoch 223/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 2.4575e-04 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9623\n",
      "Epoch 224/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 1.7568e-04 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9620\n",
      "Epoch 225/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 4.1992e-04 - accuracy: 0.9999 - val_loss: 0.2742 - val_accuracy: 0.9620\n",
      "Epoch 226/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2534 - val_accuracy: 0.9477\n",
      "Epoch 227/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 1.2983 - val_accuracy: 0.8012\n",
      "Epoch 228/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 1.2494 - val_accuracy: 0.7988\n",
      "Epoch 229/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.2789 - val_accuracy: 0.9440\n",
      "Epoch 230/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.3294 - val_accuracy: 0.9403\n",
      "Epoch 231/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.2632 - val_accuracy: 0.9481\n",
      "Epoch 232/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.7797 - val_accuracy: 0.8290\n",
      "Epoch 233/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0091 - accuracy: 0.9962 - val_loss: 0.3520 - val_accuracy: 0.9253\n",
      "Epoch 234/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0096 - accuracy: 0.9959 - val_loss: 0.4245 - val_accuracy: 0.9046\n",
      "Epoch 235/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.7237 - val_accuracy: 0.8768082 - accuracy: 0.99\n",
      "Epoch 236/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.3815 - val_accuracy: 0.9332\n",
      "Epoch 237/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 2.0477 - val_accuracy: 0.6987\n",
      "Epoch 238/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.5654 - val_accuracy: 0.8890\n",
      "Epoch 239/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 1.5761 - val_accuracy: 0.6261\n",
      "Epoch 240/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 0.9991 - val_accuracy: 0.7988\n",
      "Epoch 241/250\n",
      "7352/7352 [==============================] - 1s 133us/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.4073 - val_accuracy: 0.9359\n",
      "Epoch 242/250\n",
      "7352/7352 [==============================] - 1s 134us/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.7951 - val_accuracy: 0.9026\n",
      "Epoch 243/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.2434 - val_accuracy: 0.9440\n",
      "Epoch 244/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2351 - val_accuracy: 0.9505\n",
      "Epoch 245/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 6.5537e-04 - accuracy: 0.9999 - val_loss: 0.2833 - val_accuracy: 0.9515\n",
      "Epoch 246/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 3.5431e-04 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.95760s - loss: 3.9752e-04 - accuracy:  - ETA: 0s - loss: 3.4843e-04 - accuracy: \n",
      "Epoch 247/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 2.3452e-04 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9657\n",
      "Epoch 248/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 2.4880e-04 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9627\n",
      "Epoch 249/250\n",
      "7352/7352 [==============================] - 1s 132us/step - loss: 1.2945e-04 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9654\n",
      "Epoch 250/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 2.0418e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model_batch = Sequential()\n",
    "\n",
    "model_batch.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_batch.add(BatchNormalization())\n",
    "\n",
    "model_batch.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_batch.add(BatchNormalization())\n",
    "\n",
    "model_batch.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_batch.summary()\n",
    "\n",
    "model_batch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_batch.fit(X_train, Y_train, batch_size=batch_size, epochs=250, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP + Sigmoid + dropout + BatchNormalisation + adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 356,742\n",
      "Trainable params: 355,462\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/250\n",
      "7352/7352 [==============================] - 4s 535us/step - loss: 0.8070 - accuracy: 0.7072 - val_loss: 1.4100 - val_accuracy: 0.3617\n",
      "Epoch 2/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.3717 - accuracy: 0.8585 - val_loss: 1.0655 - val_accuracy: 0.4523\n",
      "Epoch 3/250\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.2804 - accuracy: 0.8930 - val_loss: 0.5898 - val_accuracy: 0.8409\n",
      "Epoch 4/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.2267 - accuracy: 0.9110 - val_loss: 0.5133 - val_accuracy: 0.7628\n",
      "Epoch 5/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.1992 - accuracy: 0.9223 - val_loss: 0.2207 - val_accuracy: 0.9301 - loss: 0.2020 - accura\n",
      "Epoch 6/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.1939 - accuracy: 0.9208 - val_loss: 0.2063 - val_accuracy: 0.9413\n",
      "Epoch 7/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.1581 - accuracy: 0.9400 - val_loss: 0.1886 - val_accuracy: 0.9338\n",
      "Epoch 8/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.1453 - accuracy: 0.9437 - val_loss: 0.4507 - val_accuracy: 0.8239\n",
      "Epoch 9/250\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.1430 - accuracy: 0.9459 - val_loss: 0.2346 - val_accuracy: 0.9257\n",
      "Epoch 10/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.1375 - accuracy: 0.9480 - val_loss: 0.2116 - val_accuracy: 0.9365\n",
      "Epoch 11/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.1248 - accuracy: 0.9521 - val_loss: 0.3299 - val_accuracy: 0.8918\n",
      "Epoch 12/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.1176 - accuracy: 0.9566 - val_loss: 0.2656 - val_accuracy: 0.8731\n",
      "Epoch 13/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.1197 - accuracy: 0.9555 - val_loss: 0.2240 - val_accuracy: 0.8982\n",
      "Epoch 14/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.1018 - accuracy: 0.9622 - val_loss: 0.1654 - val_accuracy: 0.9454\n",
      "Epoch 15/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.1177 - accuracy: 0.9533 - val_loss: 0.1869 - val_accuracy: 0.9454\n",
      "Epoch 16/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0988 - accuracy: 0.9633 - val_loss: 0.1607 - val_accuracy: 0.9423\n",
      "Epoch 17/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0900 - accuracy: 0.9653 - val_loss: 0.2524 - val_accuracy: 0.9060\n",
      "Epoch 18/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0924 - accuracy: 0.9655 - val_loss: 0.1930 - val_accuracy: 0.9335\n",
      "Epoch 19/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0928 - accuracy: 0.9657 - val_loss: 0.2049 - val_accuracy: 0.9213\n",
      "Epoch 20/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0872 - accuracy: 0.9678 - val_loss: 0.2533 - val_accuracy: 0.9002\n",
      "Epoch 21/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0808 - accuracy: 0.9703 - val_loss: 0.1797 - val_accuracy: 0.9277\n",
      "Epoch 22/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0854 - accuracy: 0.9687 - val_loss: 0.4529 - val_accuracy: 0.8344\n",
      "Epoch 23/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0794 - accuracy: 0.9717 - val_loss: 0.1926 - val_accuracy: 0.9294\n",
      "Epoch 24/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0762 - accuracy: 0.9709 - val_loss: 0.3057 - val_accuracy: 0.8548\n",
      "Epoch 25/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0830 - accuracy: 0.9708 - val_loss: 0.1836 - val_accuracy: 0.9308.0816 - accuracy\n",
      "Epoch 26/250\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0797 - accuracy: 0.9728 - val_loss: 0.2599 - val_accuracy: 0.9030\n",
      "Epoch 27/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0760 - accuracy: 0.9733 - val_loss: 0.5585 - val_accuracy: 0.8212\n",
      "Epoch 28/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0747 - accuracy: 0.9693 - val_loss: 0.1580 - val_accuracy: 0.9427\n",
      "Epoch 29/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0751 - accuracy: 0.9698 - val_loss: 0.1606 - val_accuracy: 0.9467\n",
      "Epoch 30/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0720 - accuracy: 0.9740 - val_loss: 0.1551 - val_accuracy: 0.9518\n",
      "Epoch 31/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0695 - accuracy: 0.9751 - val_loss: 0.3974 - val_accuracy: 0.8439\n",
      "Epoch 32/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0723 - accuracy: 0.9724 - val_loss: 0.5063 - val_accuracy: 0.8181\n",
      "Epoch 33/250\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.0699 - accuracy: 0.9731 - val_loss: 0.1736 - val_accuracy: 0.9304\n",
      "Epoch 34/250\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0725 - accuracy: 0.9731 - val_loss: 0.4057 - val_accuracy: 0.8378\n",
      "Epoch 35/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.2560 - val_accuracy: 0.9141\n",
      "Epoch 36/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0619 - accuracy: 0.9769 - val_loss: 0.2642 - val_accuracy: 0.9070\n",
      "Epoch 37/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0667 - accuracy: 0.9759 - val_loss: 0.2268 - val_accuracy: 0.9128\n",
      "Epoch 38/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0607 - accuracy: 0.9791 - val_loss: 0.1249 - val_accuracy: 0.9603\n",
      "Epoch 39/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0667 - accuracy: 0.9757 - val_loss: 0.1589 - val_accuracy: 0.9498\n",
      "Epoch 40/250\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0628 - accuracy: 0.9765 - val_loss: 0.2313 - val_accuracy: 0.9145\n",
      "Epoch 41/250\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0599 - accuracy: 0.9786 - val_loss: 0.2536 - val_accuracy: 0.9145\n",
      "Epoch 42/250\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0618 - accuracy: 0.9780 - val_loss: 0.3036 - val_accuracy: 0.8887\n",
      "Epoch 43/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0618 - accuracy: 0.9788 - val_loss: 0.1711 - val_accuracy: 0.9498\n",
      "Epoch 44/250\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0539 - accuracy: 0.9814 - val_loss: 0.2737 - val_accuracy: 0.9097\n",
      "Epoch 45/250\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0544 - accuracy: 0.9801 - val_loss: 0.1218 - val_accuracy: 0.9596\n",
      "Epoch 46/250\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.1477 - val_accuracy: 0.9518\n",
      "Epoch 47/250\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0555 - accuracy: 0.9791 - val_loss: 0.1563 - val_accuracy: 0.9488\n",
      "Epoch 48/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0619 - accuracy: 0.9769 - val_loss: 0.1796 - val_accuracy: 0.9365\n",
      "Epoch 49/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0521 - accuracy: 0.9838 - val_loss: 0.1439 - val_accuracy: 0.9545\n",
      "Epoch 50/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0508 - accuracy: 0.9822 - val_loss: 0.1885 - val_accuracy: 0.9372\n",
      "Epoch 51/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0606 - accuracy: 0.9771 - val_loss: 0.1658 - val_accuracy: 0.9457\n",
      "Epoch 52/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0586 - accuracy: 0.9789 - val_loss: 0.1630 - val_accuracy: 0.9416\n",
      "Epoch 53/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0623 - accuracy: 0.9767 - val_loss: 0.2133 - val_accuracy: 0.9114\n",
      "Epoch 54/250\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 0.0617 - accuracy: 0.9777 - val_loss: 0.4631 - val_accuracy: 0.8283\n",
      "Epoch 55/250\n",
      "7352/7352 [==============================] - 1s 130us/step - loss: 0.0552 - accuracy: 0.9782 - val_loss: 0.1733 - val_accuracy: 0.9437\n",
      "Epoch 56/250\n",
      "7352/7352 [==============================] - 1s 128us/step - loss: 0.0532 - accuracy: 0.9808 - val_loss: 0.5160 - val_accuracy: 0.8096\n",
      "Epoch 57/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0627 - accuracy: 0.9752 - val_loss: 0.2169 - val_accuracy: 0.9206\n",
      "Epoch 58/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0558 - accuracy: 0.9793 - val_loss: 0.2060 - val_accuracy: 0.9332\n",
      "Epoch 59/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0546 - accuracy: 0.9803 - val_loss: 0.2022 - val_accuracy: 0.9216\n",
      "Epoch 60/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0557 - accuracy: 0.9808 - val_loss: 0.2876 - val_accuracy: 0.9206\n",
      "Epoch 61/250\n",
      "7352/7352 [==============================] - 1s 161us/step - loss: 0.0554 - accuracy: 0.9801 - val_loss: 0.1589 - val_accuracy: 0.9539\n",
      "Epoch 62/250\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0569 - accuracy: 0.9774 - val_loss: 0.1956 - val_accuracy: 0.9101\n",
      "Epoch 63/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0517 - accuracy: 0.9811 - val_loss: 0.1971 - val_accuracy: 0.9393\n",
      "Epoch 64/250\n",
      "7352/7352 [==============================] - 1s 164us/step - loss: 0.0599 - accuracy: 0.9778 - val_loss: 0.1643 - val_accuracy: 0.9535 loss: 0.0598 - ac\n",
      "Epoch 65/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0543 - accuracy: 0.9797 - val_loss: 0.4478 - val_accuracy: 0.8249\n",
      "Epoch 66/250\n",
      "7352/7352 [==============================] - 1s 164us/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.1316 - val_accuracy: 0.9576\n",
      "Epoch 67/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0495 - accuracy: 0.9820 - val_loss: 0.2174 - val_accuracy: 0.9399\n",
      "Epoch 68/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0529 - accuracy: 0.9804 - val_loss: 0.2004 - val_accuracy: 0.9270\n",
      "Epoch 69/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.3701 - val_accuracy: 0.8649\n",
      "Epoch 70/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.4280 - val_accuracy: 0.8592\n",
      "Epoch 71/250\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0564 - accuracy: 0.9786 - val_loss: 0.5450 - val_accuracy: 0.8731\n",
      "Epoch 72/250\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.1595 - val_accuracy: 0.9511\n",
      "Epoch 73/250\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0505 - accuracy: 0.9810 - val_loss: 0.1454 - val_accuracy: 0.9508\n",
      "Epoch 74/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0520 - accuracy: 0.9811 - val_loss: 0.1248 - val_accuracy: 0.9613\n",
      "Epoch 75/250\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0547 - accuracy: 0.9808 - val_loss: 0.1362 - val_accuracy: 0.9572\n",
      "Epoch 76/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0518 - accuracy: 0.9801 - val_loss: 0.1180 - val_accuracy: 0.9620\n",
      "Epoch 77/250\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.1432 - val_accuracy: 0.9559\n",
      "Epoch 78/250\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.2396 - val_accuracy: 0.9281\n",
      "Epoch 79/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0490 - accuracy: 0.9822 - val_loss: 0.1999 - val_accuracy: 0.9274\n",
      "Epoch 80/250\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.1306 - val_accuracy: 0.9522\n",
      "Epoch 81/250\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0495 - accuracy: 0.9815 - val_loss: 0.2708 - val_accuracy: 0.9152\n",
      "Epoch 82/250\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0456 - accuracy: 0.9833 - val_loss: 0.1362 - val_accuracy: 0.9596\n",
      "Epoch 83/250\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.0544 - accuracy: 0.9788 - val_loss: 0.2282 - val_accuracy: 0.9070\n",
      "Epoch 84/250\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0609 - accuracy: 0.9773 - val_loss: 0.1961 - val_accuracy: 0.9277\n",
      "Epoch 85/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 0.2437 - val_accuracy: 0.9128\n",
      "Epoch 86/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0414 - accuracy: 0.9859 - val_loss: 0.1628 - val_accuracy: 0.9457\n",
      "Epoch 87/250\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.1471 - val_accuracy: 0.9460\n",
      "Epoch 88/250\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.2062 - val_accuracy: 0.9196\n",
      "Epoch 89/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.3908 - val_accuracy: 0.8578\n",
      "Epoch 90/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0483 - accuracy: 0.9831 - val_loss: 0.1429 - val_accuracy: 0.9474\n",
      "Epoch 91/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 0.2568 - val_accuracy: 0.9135\n",
      "Epoch 92/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 0.2412 - val_accuracy: 0.9382\n",
      "Epoch 93/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 0.2169 - val_accuracy: 0.9311\n",
      "Epoch 94/250\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.2855 - val_accuracy: 0.9257\n",
      "Epoch 95/250\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0479 - accuracy: 0.9830 - val_loss: 0.1095 - val_accuracy: 0.9657\n",
      "Epoch 96/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0456 - accuracy: 0.9838 - val_loss: 0.1308 - val_accuracy: 0.9572\n",
      "Epoch 97/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0478 - accuracy: 0.9831 - val_loss: 0.1450 - val_accuracy: 0.9528\n",
      "Epoch 98/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0451 - accuracy: 0.9841 - val_loss: 0.4983 - val_accuracy: 0.8795\n",
      "Epoch 99/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.2415 - val_accuracy: 0.8992\n",
      "Epoch 100/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0479 - accuracy: 0.9823 - val_loss: 0.1173 - val_accuracy: 0.9617\n",
      "Epoch 101/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0441 - accuracy: 0.9830 - val_loss: 0.1852 - val_accuracy: 0.9348\n",
      "Epoch 102/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0414 - accuracy: 0.9852 - val_loss: 0.3292 - val_accuracy: 0.9070\n",
      "Epoch 103/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.2258 - val_accuracy: 0.9135\n",
      "Epoch 104/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0408 - accuracy: 0.9853 - val_loss: 0.2072 - val_accuracy: 0.9396\n",
      "Epoch 105/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.1467 - val_accuracy: 0.9450\n",
      "Epoch 106/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0515 - accuracy: 0.9814 - val_loss: 0.1718 - val_accuracy: 0.9413\n",
      "Epoch 107/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 0.1749 - val_accuracy: 0.9433\n",
      "Epoch 108/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0416 - accuracy: 0.9854 - val_loss: 0.1603 - val_accuracy: 0.9474\n",
      "Epoch 109/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0378 - accuracy: 0.9852 - val_loss: 0.1493 - val_accuracy: 0.9508\n",
      "Epoch 110/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0437 - accuracy: 0.9849 - val_loss: 0.1678 - val_accuracy: 0.9471\n",
      "Epoch 111/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0445 - accuracy: 0.9850 - val_loss: 0.1481 - val_accuracy: 0.9555\n",
      "Epoch 112/250\n",
      "7352/7352 [==============================] - 1s 165us/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.2987 - val_accuracy: 0.9192\n",
      "Epoch 113/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0426 - accuracy: 0.9837 - val_loss: 0.3272 - val_accuracy: 0.9203\n",
      "Epoch 114/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0441 - accuracy: 0.9835 - val_loss: 0.1279 - val_accuracy: 0.9579\n",
      "Epoch 115/250\n",
      "7352/7352 [==============================] - 1s 176us/step - loss: 0.0428 - accuracy: 0.9849 - val_loss: 0.1730 - val_accuracy: 0.9474\n",
      "Epoch 116/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 0.3762 - val_accuracy: 0.8911\n",
      "Epoch 117/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0405 - accuracy: 0.9852 - val_loss: 0.1580 - val_accuracy: 0.9528\n",
      "Epoch 118/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 0.4545 - val_accuracy: 0.8751\n",
      "Epoch 119/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0437 - accuracy: 0.9849 - val_loss: 0.4475 - val_accuracy: 0.8548\n",
      "Epoch 120/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0430 - accuracy: 0.9844 - val_loss: 0.2765 - val_accuracy: 0.9128\n",
      "Epoch 121/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0459 - accuracy: 0.9837 - val_loss: 0.3726 - val_accuracy: 0.8741\n",
      "Epoch 122/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.1645 - val_accuracy: 0.9525\n",
      "Epoch 123/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0393 - accuracy: 0.9850 - val_loss: 0.2521 - val_accuracy: 0.9291\n",
      "Epoch 124/250\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 0.1802 - val_accuracy: 0.9369\n",
      "Epoch 125/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0392 - accuracy: 0.9845 - val_loss: 0.2381 - val_accuracy: 0.9189\n",
      "Epoch 126/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0390 - accuracy: 0.9856 - val_loss: 0.2778 - val_accuracy: 0.9274\n",
      "Epoch 127/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0468 - accuracy: 0.9845 - val_loss: 0.2026 - val_accuracy: 0.9237\n",
      "Epoch 128/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 0.1929 - val_accuracy: 0.9444\n",
      "Epoch 129/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0460 - accuracy: 0.9838 - val_loss: 0.2030 - val_accuracy: 0.9335\n",
      "Epoch 130/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0402 - accuracy: 0.9857 - val_loss: 0.1849 - val_accuracy: 0.9423\n",
      "Epoch 131/250\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0404 - accuracy: 0.9864 - val_loss: 0.1131 - val_accuracy: 0.9637\n",
      "Epoch 132/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0396 - accuracy: 0.9852 - val_loss: 0.1512 - val_accuracy: 0.9471\n",
      "Epoch 133/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0397 - accuracy: 0.9853 - val_loss: 0.1160 - val_accuracy: 0.9637\n",
      "Epoch 134/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0370 - accuracy: 0.9863 - val_loss: 0.2338 - val_accuracy: 0.9315\n",
      "Epoch 135/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0406 - accuracy: 0.9846 - val_loss: 0.1906 - val_accuracy: 0.9389\n",
      "Epoch 136/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.1877 - val_accuracy: 0.9379\n",
      "Epoch 137/250\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.2243 - val_accuracy: 0.9308\n",
      "Epoch 138/250\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.1550 - val_accuracy: 0.9522\n",
      "Epoch 139/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.3244 - val_accuracy: 0.8911\n",
      "Epoch 140/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.3179 - val_accuracy: 0.9165\n",
      "Epoch 141/250\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0463 - accuracy: 0.9829 - val_loss: 0.2533 - val_accuracy: 0.9158\n",
      "Epoch 142/250\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0375 - accuracy: 0.9868 - val_loss: 0.2833 - val_accuracy: 0.9243\n",
      "Epoch 143/250\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0404 - accuracy: 0.9857 - val_loss: 0.1434 - val_accuracy: 0.9488\n",
      "Epoch 144/250\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.1476 - val_accuracy: 0.9532\n",
      "Epoch 145/250\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0369 - accuracy: 0.9865 - val_loss: 0.1663 - val_accuracy: 0.9528\n",
      "Epoch 146/250\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.2485 - val_accuracy: 0.9155\n",
      "Epoch 147/250\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 0.0433 - accuracy: 0.9841 - val_loss: 0.1643 - val_accuracy: 0.9447\n",
      "Epoch 148/250\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.1925 - val_accuracy: 0.9454\n",
      "Epoch 149/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.1620 - val_accuracy: 0.9488\n",
      "Epoch 150/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0329 - accuracy: 0.9878 - val_loss: 0.1597 - val_accuracy: 0.9464\n",
      "Epoch 151/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.4328 - val_accuracy: 0.8599\n",
      "Epoch 152/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 0.2249 - val_accuracy: 0.9379\n",
      "Epoch 153/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0386 - accuracy: 0.9845 - val_loss: 0.4238 - val_accuracy: 0.8500\n",
      "Epoch 154/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.2189 - val_accuracy: 0.9325\n",
      "Epoch 155/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0392 - accuracy: 0.9854 - val_loss: 0.2191 - val_accuracy: 0.9338\n",
      "Epoch 156/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.1279 - val_accuracy: 0.9640\n",
      "Epoch 157/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0412 - accuracy: 0.9857 - val_loss: 0.6040 - val_accuracy: 0.8575\n",
      "Epoch 158/250\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0378 - accuracy: 0.9854 - val_loss: 0.1806 - val_accuracy: 0.9413\n",
      "Epoch 159/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 0.2413 - val_accuracy: 0.9253\n",
      "Epoch 160/250\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 0.4344 - val_accuracy: 0.8911\n",
      "Epoch 161/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0355 - accuracy: 0.9865 - val_loss: 0.8385 - val_accuracy: 0.8320\n",
      "Epoch 162/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0345 - accuracy: 0.9860 - val_loss: 0.2205 - val_accuracy: 0.9416\n",
      "Epoch 163/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0374 - accuracy: 0.9850 - val_loss: 0.1664 - val_accuracy: 0.9545\n",
      "Epoch 164/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.1659 - val_accuracy: 0.9508\n",
      "Epoch 165/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 0.3740 - val_accuracy: 0.8951\n",
      "Epoch 166/250\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.2420 - val_accuracy: 0.9393\n",
      "Epoch 167/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.2162 - val_accuracy: 0.9355\n",
      "Epoch 168/250\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0313 - accuracy: 0.9894 - val_loss: 0.1304 - val_accuracy: 0.9637\n",
      "Epoch 169/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0311 - accuracy: 0.9880 - val_loss: 0.1554 - val_accuracy: 0.9559 - loss: 0.0310 - accura\n",
      "Epoch 170/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.2825 - val_accuracy: 0.9175\n",
      "Epoch 171/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0310 - accuracy: 0.9883 - val_loss: 0.1509 - val_accuracy: 0.9589\n",
      "Epoch 172/250\n",
      "7352/7352 [==============================] - 1s 170us/step - loss: 0.0337 - accuracy: 0.9872 - val_loss: 0.1517 - val_accuracy: 0.9579\n",
      "Epoch 173/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.1495 - val_accuracy: 0.9423\n",
      "Epoch 174/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.2575 - val_accuracy: 0.9308\n",
      "Epoch 175/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0372 - accuracy: 0.9857 - val_loss: 0.4113 - val_accuracy: 0.8744\n",
      "Epoch 176/250\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 0.0342 - accuracy: 0.9872 - val_loss: 0.1235 - val_accuracy: 0.9620\n",
      "Epoch 177/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.1465 - val_accuracy: 0.9579\n",
      "Epoch 178/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0282 - accuracy: 0.9894 - val_loss: 0.1959 - val_accuracy: 0.9403\n",
      "Epoch 179/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.1526 - val_accuracy: 0.9549\n",
      "Epoch 180/250\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0325 - accuracy: 0.9880 - val_loss: 0.2143 - val_accuracy: 0.9260\n",
      "Epoch 181/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.2578 - val_accuracy: 0.9304\n",
      "Epoch 182/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.1544 - val_accuracy: 0.9600\n",
      "Epoch 183/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.4064 - val_accuracy: 0.9016\n",
      "Epoch 184/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0415 - accuracy: 0.9859 - val_loss: 0.4192 - val_accuracy: 0.8894\n",
      "Epoch 185/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0354 - accuracy: 0.9872 - val_loss: 0.3063 - val_accuracy: 0.9186\n",
      "Epoch 186/250\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0312 - accuracy: 0.9883 - val_loss: 0.2499 - val_accuracy: 0.9328\n",
      "Epoch 187/250\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0424 - accuracy: 0.9854 - val_loss: 0.5558 - val_accuracy: 0.8697\n",
      "Epoch 188/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.3680 - val_accuracy: 0.9043\n",
      "Epoch 189/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0308 - accuracy: 0.9890 - val_loss: 0.1409 - val_accuracy: 0.9630\n",
      "Epoch 190/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0289 - accuracy: 0.9894 - val_loss: 0.1403 - val_accuracy: 0.9634\n",
      "Epoch 191/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0334 - accuracy: 0.9861 - val_loss: 0.1719 - val_accuracy: 0.9539\n",
      "Epoch 192/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.3532 - val_accuracy: 0.8996\n",
      "Epoch 193/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.3614 - val_accuracy: 0.9080\n",
      "Epoch 194/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0425 - accuracy: 0.9844 - val_loss: 0.1724 - val_accuracy: 0.9416\n",
      "Epoch 195/250\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0317 - accuracy: 0.9888 - val_loss: 0.1249 - val_accuracy: 0.9600\n",
      "Epoch 196/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0319 - accuracy: 0.9880 - val_loss: 0.2199 - val_accuracy: 0.9301\n",
      "Epoch 197/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.1524 - val_accuracy: 0.9555\n",
      "Epoch 198/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.1582 - val_accuracy: 0.9552\n",
      "Epoch 199/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.1970 - val_accuracy: 0.9522\n",
      "Epoch 200/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0362 - accuracy: 0.9863 - val_loss: 0.4073 - val_accuracy: 0.9002\n",
      "Epoch 201/250\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 0.2182 - val_accuracy: 0.9522\n",
      "Epoch 202/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.1494 - val_accuracy: 0.9569\n",
      "Epoch 203/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0284 - accuracy: 0.9898 - val_loss: 0.1489 - val_accuracy: 0.9572\n",
      "Epoch 204/250\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.2710 - val_accuracy: 0.9335\n",
      "Epoch 205/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0291 - accuracy: 0.9899 - val_loss: 0.1840 - val_accuracy: 0.9535\n",
      "Epoch 206/250\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.1152 - val_accuracy: 0.9640\n",
      "Epoch 207/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0274 - accuracy: 0.9899 - val_loss: 0.1733 - val_accuracy: 0.9447\n",
      "Epoch 208/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0328 - accuracy: 0.9875 - val_loss: 0.2203 - val_accuracy: 0.9348\n",
      "Epoch 209/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0277 - accuracy: 0.9895 - val_loss: 0.2096 - val_accuracy: 0.9494\n",
      "Epoch 210/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.2084 - val_accuracy: 0.9389\n",
      "Epoch 211/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0324 - accuracy: 0.9875 - val_loss: 0.4726 - val_accuracy: 0.8941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.5420 - val_accuracy: 0.8833\n",
      "Epoch 213/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0379 - accuracy: 0.9868 - val_loss: 0.2256 - val_accuracy: 0.9386\n",
      "Epoch 214/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0315 - accuracy: 0.9882 - val_loss: 0.2373 - val_accuracy: 0.9345\n",
      "Epoch 215/250\n",
      "7352/7352 [==============================] - 1s 166us/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.2061 - val_accuracy: 0.9410\n",
      "Epoch 216/250\n",
      "7352/7352 [==============================] - 1s 171us/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 0.1472 - val_accuracy: 0.9586\n",
      "Epoch 217/250\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.1843 - val_accuracy: 0.9511\n",
      "Epoch 218/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0292 - accuracy: 0.9876 - val_loss: 0.1579 - val_accuracy: 0.9376\n",
      "Epoch 219/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0312 - accuracy: 0.9880 - val_loss: 0.1516 - val_accuracy: 0.9518\n",
      "Epoch 220/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.1670 - val_accuracy: 0.9555\n",
      "Epoch 221/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.1391 - val_accuracy: 0.9596\n",
      "Epoch 222/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.1460 - val_accuracy: 0.9606\n",
      "Epoch 223/250\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0276 - accuracy: 0.9897 - val_loss: 0.1290 - val_accuracy: 0.9678\n",
      "Epoch 224/250\n",
      "7352/7352 [==============================] - 1s 166us/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.2062 - val_accuracy: 0.9389\n",
      "Epoch 225/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0229 - accuracy: 0.9905 - val_loss: 0.3059 - val_accuracy: 0.9270\n",
      "Epoch 226/250\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0296 - accuracy: 0.9890 - val_loss: 0.1875 - val_accuracy: 0.9474\n",
      "Epoch 227/250\n",
      "7352/7352 [==============================] - 1s 168us/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 0.2609 - val_accuracy: 0.9410\n",
      "Epoch 228/250\n",
      "7352/7352 [==============================] - 1s 166us/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 0.2247 - val_accuracy: 0.9389\n",
      "Epoch 229/250\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0265 - accuracy: 0.9903 - val_loss: 0.3303 - val_accuracy: 0.9220\n",
      "Epoch 230/250\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.3175 - val_accuracy: 0.9165\n",
      "Epoch 231/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 0.2566 - val_accuracy: 0.9471\n",
      "Epoch 232/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0316 - accuracy: 0.9882 - val_loss: 0.2827 - val_accuracy: 0.9240\n",
      "Epoch 233/250\n",
      "7352/7352 [==============================] - 1s 167us/step - loss: 0.0324 - accuracy: 0.9875 - val_loss: 0.2170 - val_accuracy: 0.9342\n",
      "Epoch 234/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.1550 - val_accuracy: 0.9522\n",
      "Epoch 235/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.2230 - val_accuracy: 0.9355\n",
      "Epoch 236/250\n",
      "7352/7352 [==============================] - 1s 169us/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.1341 - val_accuracy: 0.9644\n",
      "Epoch 237/250\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0271 - accuracy: 0.9897 - val_loss: 0.3029 - val_accuracy: 0.9087\n",
      "Epoch 238/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.4336 - val_accuracy: 0.9145\n",
      "Epoch 239/250\n",
      "7352/7352 [==============================] - 1s 163us/step - loss: 0.0347 - accuracy: 0.9868 - val_loss: 0.2192 - val_accuracy: 0.9535\n",
      "Epoch 240/250\n",
      "7352/7352 [==============================] - 1s 161us/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.1964 - val_accuracy: 0.9505\n",
      "Epoch 241/250\n",
      "7352/7352 [==============================] - 1s 166us/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.1427 - val_accuracy: 0.9606\n",
      "Epoch 242/250\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 0.3537 - val_accuracy: 0.9074\n",
      "Epoch 243/250\n",
      "7352/7352 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.99 - 1s 154us/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.1330 - val_accuracy: 0.9654\n",
      "Epoch 244/250\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.3501 - val_accuracy: 0.9223\n",
      "Epoch 245/250\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.1695 - val_accuracy: 0.9583\n",
      "Epoch 246/250\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0282 - accuracy: 0.9883 - val_loss: 0.1693 - val_accuracy: 0.9640\n",
      "Epoch 247/250\n",
      "7352/7352 [==============================] - 1s 164us/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 0.1567 - val_accuracy: 0.9545\n",
      "Epoch 248/250\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0298 - accuracy: 0.9888 - val_loss: 0.1598 - val_accuracy: 0.9511\n",
      "Epoch 249/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0267 - accuracy: 0.9895 - val_loss: 0.4239 - val_accuracy: 0.9070\n",
      "Epoch 250/250\n",
      "7352/7352 [==============================] - 1s 162us/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.2387 - val_accuracy: 0.9427\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_drop.summary()\n",
    "\n",
    "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=250, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning of Keras model using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "def best_hyperparameters(activ):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activ, input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "    model.add(Dense(128, activation=activ, kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "activ = ['sigmoid','relu']\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=best_hyperparameters, epochs=nb_epoch, batch_size=batch_size, verbose=0)\n",
    "param_grid = dict(activ=activ)\n",
    "\n",
    "# if you are using CPU\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# if you are using GPU dont use the n_jobs parameter\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.938792 using {'activ': 'sigmoid'}\n",
      "0.938792 (0.006378) with: {'activ': 'sigmoid'}\n",
      "0.922742 (0.028326) with: {'activ': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
