{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .  Getting the data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T01:25:50.682198Z",
     "start_time": "2020-04-16T01:25:49.486364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train and y_train : ((7352, 561),(7352,))\n",
      "X_test  and y_test  : ((2947, 561),(2947,))\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils \n",
    "from keras.datasets import mnist \n",
    "import seaborn as sns\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_train = train.Activity\n",
    "\n",
    "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
    "y_test = test.Activity\n",
    "\n",
    "print('X_train and y_train : ({},{})'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  and y_test  : ({},{})'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T01:25:51.733576Z",
     "start_time": "2020-04-16T01:25:51.729589Z"
    }
   },
   "outputs": [],
   "source": [
    "train['Activity']=train.Activity-1\n",
    "test['Activity']=test.Activity-1\n",
    "\n",
    "X_train=X_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "\n",
    "X_test=X_test.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T01:25:57.383371Z",
     "start_time": "2020-04-16T01:25:57.377383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train,6) \n",
    "Y_test = np_utils.to_categorical(y_test, 6)\n",
    "\n",
    "# A sample output\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T07:02:48.416401Z",
     "start_time": "2020-04-13T07:02:48.412383Z"
    }
   },
   "source": [
    "# . Setting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T20:59:24.590821Z",
     "start_time": "2020-04-15T20:59:24.585832Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "\n",
    "output_dim = 6\n",
    "input_dim =561\n",
    "batch_size = 128 \n",
    "nb_epoch = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T06:59:39.548342Z",
     "start_time": "2020-04-16T06:59:39.540444Z"
    }
   },
   "source": [
    "#  Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our First Model - Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:44:51.641185Z",
     "start_time": "2020-04-16T02:44:43.384247Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:44:51.641185Z",
     "start_time": "2020-04-16T02:44:43.384247Z"
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(output_dim,input_dim=input_dim, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:44:51.641185Z",
     "start_time": "2020-04-16T02:44:43.384247Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:44:51.641185Z",
     "start_time": "2020-04-16T02:44:43.384247Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:44:51.641185Z",
     "start_time": "2020-04-16T02:44:43.384247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 6)                 3372      \n",
      "=================================================================\n",
      "Total params: 3,372\n",
      "Trainable params: 3,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/15\n",
      "7352/7352 [==============================] - 1s 110us/step - loss: 1.3072 - accuracy: 0.4678 - val_loss: 1.0696 - val_accuracy: 0.6132\n",
      "Epoch 2/15\n",
      "7352/7352 [==============================] - 0s 63us/step - loss: 0.9102 - accuracy: 0.7401 - val_loss: 0.8433 - val_accuracy: 0.7710\n",
      "Epoch 3/15\n",
      "7352/7352 [==============================] - 0s 49us/step - loss: 0.7447 - accuracy: 0.8233 - val_loss: 0.7309 - val_accuracy: 0.7788\n",
      "Epoch 4/15\n",
      "7352/7352 [==============================] - 0s 64us/step - loss: 0.6478 - accuracy: 0.8452 - val_loss: 0.6485 - val_accuracy: 0.8310\n",
      "Epoch 5/15\n",
      "7352/7352 [==============================] - 0s 62us/step - loss: 0.5822 - accuracy: 0.8647 - val_loss: 0.5985 - val_accuracy: 0.8531\n",
      "Epoch 6/15\n",
      "7352/7352 [==============================] - 0s 44us/step - loss: 0.5341 - accuracy: 0.8682 - val_loss: 0.5587 - val_accuracy: 0.8310\n",
      "Epoch 7/15\n",
      "7352/7352 [==============================] - 0s 59us/step - loss: 0.4972 - accuracy: 0.8758 - val_loss: 0.5176 - val_accuracy: 0.8809\n",
      "Epoch 8/15\n",
      "7352/7352 [==============================] - 0s 58us/step - loss: 0.4667 - accuracy: 0.8859 - val_loss: 0.4879 - val_accuracy: 0.8772\n",
      "Epoch 9/15\n",
      "7352/7352 [==============================] - 1s 69us/step - loss: 0.4422 - accuracy: 0.8897 - val_loss: 0.4698 - val_accuracy: 0.8761\n",
      "Epoch 10/15\n",
      "7352/7352 [==============================] - 0s 60us/step - loss: 0.4219 - accuracy: 0.8890 - val_loss: 0.4540 - val_accuracy: 0.8728\n",
      "Epoch 11/15\n",
      "7352/7352 [==============================] - 1s 71us/step - loss: 0.4055 - accuracy: 0.8925 - val_loss: 0.4355 - val_accuracy: 0.8887\n",
      "Epoch 12/15\n",
      "7352/7352 [==============================] - 0s 65us/step - loss: 0.3897 - accuracy: 0.8947 - val_loss: 0.4198 - val_accuracy: 0.8945\n",
      "Epoch 13/15\n",
      "7352/7352 [==============================] - 0s 66us/step - loss: 0.3758 - accuracy: 0.8989 - val_loss: 0.4115 - val_accuracy: 0.8789\n",
      "Epoch 14/15\n",
      "7352/7352 [==============================] - 0s 64us/step - loss: 0.3652 - accuracy: 0.8993 - val_loss: 0.3967 - val_accuracy: 0.8890\n",
      "Epoch 15/15\n",
      "7352/7352 [==============================] - 0s 63us/step - loss: 0.3532 - accuracy: 0.9014 - val_loss: 0.3876 - val_accuracy: 0.8948\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=15, verbose=1, validation_data=(X_test, Y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:46:29.073593Z",
     "start_time": "2020-04-16T02:46:28.888345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.4808292388916 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test accuracy:', score[1]*100,'%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building a Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T02:40:22.759021Z",
     "start_time": "2020-04-16T02:40:12.442367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128)               71936     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 72,710\n",
      "Trainable params: 72,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/15\n",
      "7352/7352 [==============================] - 1s 117us/step - loss: 0.0477 - accuracy: 0.9831 - val_loss: 0.1338 - val_accuracy: 0.9522\n",
      "Epoch 2/15\n",
      "7352/7352 [==============================] - 0s 62us/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.1435 - val_accuracy: 0.9505\n",
      "Epoch 3/15\n",
      "7352/7352 [==============================] - 0s 67us/step - loss: 0.0462 - accuracy: 0.9854 - val_loss: 0.1311 - val_accuracy: 0.9528\n",
      "Epoch 4/15\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0460 - accuracy: 0.9842 - val_loss: 0.1383 - val_accuracy: 0.9528\n",
      "Epoch 5/15\n",
      "7352/7352 [==============================] - 0s 66us/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.1414 - val_accuracy: 0.9505\n",
      "Epoch 6/15\n",
      "7352/7352 [==============================] - 1s 83us/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.1355 - val_accuracy: 0.9515\n",
      "Epoch 7/15\n",
      "7352/7352 [==============================] - 1s 101us/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.1344 - val_accuracy: 0.9525\n",
      "Epoch 8/15\n",
      "7352/7352 [==============================] - 0s 67us/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 0.1330 - val_accuracy: 0.9525\n",
      "Epoch 9/15\n",
      "7352/7352 [==============================] - 1s 88us/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 0.1476 - val_accuracy: 0.9460\n",
      "Epoch 10/15\n",
      "7352/7352 [==============================] - 1s 79us/step - loss: 0.0438 - accuracy: 0.9852 - val_loss: 0.1425 - val_accuracy: 0.9522\n",
      "Epoch 11/15\n",
      "7352/7352 [==============================] - 1s 93us/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 0.1359 - val_accuracy: 0.9542\n",
      "Epoch 12/15\n",
      "7352/7352 [==============================] - 1s 77us/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.1431 - val_accuracy: 0.9525\n",
      "Epoch 13/15\n",
      "7352/7352 [==============================] - 1s 68us/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.1357 - val_accuracy: 0.9525\n",
      "Epoch 14/15\n",
      "7352/7352 [==============================] - 1s 69us/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.1334 - val_accuracy: 0.9539\n",
      "Epoch 15/15\n",
      "7352/7352 [==============================] - 0s 65us/step - loss: 0.0435 - accuracy: 0.9856 - val_loss: 0.1361 - val_accuracy: 0.9532\n",
      "Test accuracy: 95.31727433204651 %\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = Sequential()\n",
    "\n",
    "model_sigmoid.add(Dense(128,activation='relu',input_shape=(input_dim,)))\n",
    "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model_sigmoid.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\\n",
    "\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) \n",
    "\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test accuracy:', score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a MLP with dropout and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T05:46:30.480332Z",
     "start_time": "2020-04-16T05:45:56.518007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 512)               287744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 356,742\n",
      "Trainable params: 355,462\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/15\n",
      "7352/7352 [==============================] - 4s 562us/step - loss: 0.4806 - accuracy: 0.8181 - val_loss: 1.4880 - val_accuracy: 0.2711\n",
      "Epoch 2/15\n",
      "7352/7352 [==============================] - 2s 274us/step - loss: 0.1868 - accuracy: 0.9324 - val_loss: 1.0919 - val_accuracy: 0.7072\n",
      "Epoch 3/15\n",
      "7352/7352 [==============================] - 2s 280us/step - loss: 0.1443 - accuracy: 0.9470 - val_loss: 0.7630 - val_accuracy: 0.8476\n",
      "Epoch 4/15\n",
      "7352/7352 [==============================] - 2s 292us/step - loss: 0.1277 - accuracy: 0.9551 - val_loss: 0.4954 - val_accuracy: 0.8558\n",
      "Epoch 5/15\n",
      "7352/7352 [==============================] - 2s 237us/step - loss: 0.1024 - accuracy: 0.9611 - val_loss: 0.5692 - val_accuracy: 0.7794\n",
      "Epoch 6/15\n",
      "7352/7352 [==============================] - 2s 289us/step - loss: 0.0992 - accuracy: 0.9642 - val_loss: 0.2284 - val_accuracy: 0.9359\n",
      "Epoch 7/15\n",
      "7352/7352 [==============================] - 2s 256us/step - loss: 0.0864 - accuracy: 0.9687 - val_loss: 0.2335 - val_accuracy: 0.9006\n",
      "Epoch 8/15\n",
      "7352/7352 [==============================] - 2s 234us/step - loss: 0.0763 - accuracy: 0.9717 - val_loss: 0.2056 - val_accuracy: 0.9481\n",
      "Epoch 9/15\n",
      "7352/7352 [==============================] - 2s 226us/step - loss: 0.0754 - accuracy: 0.9718 - val_loss: 0.1391 - val_accuracy: 0.9477\n",
      "Epoch 10/15\n",
      "7352/7352 [==============================] - 2s 226us/step - loss: 0.0777 - accuracy: 0.9695 - val_loss: 0.1476 - val_accuracy: 0.9518\n",
      "Epoch 11/15\n",
      "7352/7352 [==============================] - 2s 216us/step - loss: 0.0668 - accuracy: 0.9743 - val_loss: 0.4017 - val_accuracy: 0.8660\n",
      "Epoch 12/15\n",
      "7352/7352 [==============================] - 2s 242us/step - loss: 0.0604 - accuracy: 0.9767 - val_loss: 0.2585 - val_accuracy: 0.9087\n",
      "Epoch 13/15\n",
      "7352/7352 [==============================] - 2s 238us/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 0.1871 - val_accuracy: 0.9382\n",
      "Epoch 14/15\n",
      "7352/7352 [==============================] - 2s 231us/step - loss: 0.0634 - accuracy: 0.9763 - val_loss: 0.1526 - val_accuracy: 0.9515\n",
      "Epoch 15/15\n",
      "7352/7352 [==============================] - 2s 244us/step - loss: 0.0583 - accuracy: 0.9766 - val_loss: 0.2534 - val_accuracy: 0.9080\n",
      "Test accuracy: 89.4808292388916 %\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(128, activation='sigmoid') )\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_drop.summary()\n",
    "\n",
    "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test accuracy:', score[1]*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
